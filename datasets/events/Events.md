The Events dataset
==================

The Events dataset is currently generated by `src/main/scala/com/mozilla/telemetry/views/MainEventsView.scala` for events in the main ping, but separate jobs for other ping types are planned for the near future. It contains a record for every event sent via a main ping (note: this means a single ping may produce multiple event records) plus select data from the associated main ping. The fields for [ClientCount](ClientCount.md) served as the basis for choosing the initial fields included in the Events dataset.

Like the Main Summary dataset, No attempt is made to de-duplicate submissions by `documentId`.

Generating the dataset
======================

The dataset is generated in the same way that [Addons](Addons.md) is generated, with the addition of a "sampleid" argument that may be useful for testing.

```bash
spark-submit \
    --master yarn \
    --deploy-mode client \
    --class com.mozilla.telemetry.views.MainEventsView \
    telemetry-batch-view-1.1.jar \
    --bucket example_bucket \
    --inbucket another_bucket \
    --from 20170120 \
    --to 20170124
```

Notes:

* This dataset is updated daily via the [telemetry-airflow](https://github.com/mozilla/telemetry-airflow) infrastructure.
* The job DAG runs every day after the Main Summary data has been generated.
* The job saves the resulting data to S3 as [Parquet](https://parquet.apache.org/)-serialized [DataFrames](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrame.html), under prefixes of the form `events/vX/submission_date_s3=(YYYYMMDD SUBMISSION DATE)/doc_type=(PING DOCTYPE STRING)` in the `telemetry-parquet` bucket.
* Each of these prefixes is a partition. There is a partition for each `submissionDate` + `docType`.
* The Events data can be accessed from Spark via clusters launched at [analysis.telemetry.mozilla.org](https://analysis.telemetry.mozilla.org/).
* Currently the dataset is available from 2017-01-05 on

Schemas and Making Queries
--------------------------

As of 2017-01-26, the current version of the `events` dataset is `v1`, and has a schema as follows:
```
root
 |-- document_id: string (nullable = true)
 |-- client_id: string (nullable = true)
 |-- normalized_channel: string (nullable = true)
 |-- country: string (nullable = true)
 |-- locale: string (nullable = true)
 |-- app_name: string (nullable = true)
 |-- app_version: string (nullable = true)
 |-- os: string (nullable = true)
 |-- os_version: string (nullable = true)
 |-- subsession_start_date: string (nullable = true)
 |-- subsession_length: long (nullable = true)
 |-- sync_configured: boolean (nullable = true)
 |-- sync_count_desktop: integer (nullable = true)
 |-- sync_count_mobile: integer (nullable = true)
 |-- timestamp: long (nullable = true)
 |-- sample_id: string (nullable = true)
 |-- event_timestamp: long (nullable = false)
 |-- event_category: string (nullable = false)
 |-- event_method: string (nullable = false)
 |-- event_object: string (nullable = false)
 |-- event_string_value: string (nullable = true)
 |-- event_map_values: map (nullable = true)
 |    |-- key: string
 |    |-- value: string
 |-- submission_date_s3: string (nullable = true)
 |-- doc_type: string (nullable = true)
```

Currently, client-side event telemetry is undocumented -- this doc will link to those once they're published.
