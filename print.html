<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Firefox Data Documentation</title>
        
        <meta name="robots" content="noindex" />
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        
        <link rel="stylesheet" href="dtmo.css">
        
        <link rel="stylesheet" href="mermaid.css">
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "light" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div id="sidebar-scrollbox" class="sidebar-scrollbox">
                <ol class="chapter"><li class="expanded affix "><a href="introduction.html">Firefox Data Documentation</a></li><li class="expanded "><a href="concepts/reporting_a_problem.html"><strong aria-hidden="true">1.</strong> Reporting a problem</a></li><li class="expanded "><a href="concepts/terminology.html"><strong aria-hidden="true">2.</strong> Terminology</a></li><li class="expanded "><a href="concepts/getting_started.html"><strong aria-hidden="true">3.</strong> Getting Started</a></li><li><ol class="section"><li class="expanded "><a href="concepts/analysis_intro.html"><strong aria-hidden="true">3.1.</strong> Analysis Quick Start</a></li><li class="expanded "><a href="concepts/choosing_a_dataset.html"><strong aria-hidden="true">3.2.</strong> Choosing a Desktop Dataset</a></li><li class="expanded "><a href="concepts/choosing_a_dataset_mobile.html"><strong aria-hidden="true">3.3.</strong> Choosing a Mobile Dataset</a></li><li class="expanded "><a href="tools/stmo.html"><strong aria-hidden="true">3.4.</strong> Intro to STMO</a></li><li class="expanded "><a href="concepts/analysis_gotchas.html"><strong aria-hidden="true">3.5.</strong> Common Analysis Gotchas</a></li><li class="expanded "><a href="concepts/sql_optimization.html"><strong aria-hidden="true">3.6.</strong> Optimizing Queries</a></li><li class="expanded "><a href="concepts/getting_help.html"><strong aria-hidden="true">3.7.</strong> Getting Help</a></li></ol></li><li class="expanded "><a href="tools/index.html"><strong aria-hidden="true">4.</strong> Tools</a></li><li><ol class="section"><li class="expanded "><a href="tools/projects.html"><strong aria-hidden="true">4.1.</strong> Project Glossary</a></li><li class="expanded "><a href="concepts/pipeline/gcp_data_pipeline.html"><strong aria-hidden="true">4.2.</strong> Overview of Mozilla's Data Pipeline</a></li><li><ol class="section"><li class="expanded "><a href="concepts/pipeline/http_edge_spec.html"><strong aria-hidden="true">4.2.1.</strong> HTTP Edge Server Specification</a></li><li class="expanded "><a href="concepts/pipeline/event_pipeline.html"><strong aria-hidden="true">4.2.2.</strong> Event Pipeline Detail</a></li><li class="expanded "><a href="concepts/pipeline/data_pipeline.html"><strong aria-hidden="true">4.2.3.</strong> Previous AWS Pipeline Overview</a></li><li class="expanded "><a href="concepts/pipeline/data_pipeline_detail.html"><strong aria-hidden="true">4.2.4.</strong> In-depth AWS Data Pipeline Detail</a></li></ol></li><li class="expanded "><a href="tools/interfaces.html"><strong aria-hidden="true">4.3.</strong> Analysis Interfaces</a></li><li class="expanded "><a href="tools/spark.html"><strong aria-hidden="true">4.4.</strong> Custom analysis with Spark</a></li><li class="expanded "><a href="concepts/sql_style.html"><strong aria-hidden="true">4.5.</strong> SQL Style Guide</a></li><li class="expanded "><a href="concepts/glean/glean.html"><strong aria-hidden="true">4.6.</strong> Glean overview</a></li><li><ol class="section"><li class="expanded "><a href="concepts/glean/debug_ping_view.html"><strong aria-hidden="true">4.6.1.</strong> Glean Debug ping viewer</a></li></ol></li><li class="expanded "><a href="tools/alerts.html"><strong aria-hidden="true">4.7.</strong> Alerts</a></li></ol></li><li class="expanded "><a href="cookbooks/index.html"><strong aria-hidden="true">5.</strong> Analysis cookbooks</a></li><li><ol class="section"><li class="expanded "><a href="cookbooks/bigquery.html"><strong aria-hidden="true">5.1.</strong> Accessing and working with BigQuery</a></li><li><ol class="section"><li class="expanded "><a href="cookbooks/bigquery-airflow.html"><strong aria-hidden="true">5.1.1.</strong> Scheduling BigQuery Queries in Airflow</a></li></ol></li><li class="expanded "><a href="cookbooks/dataset_specific.html"><strong aria-hidden="true">5.2.</strong> Dataset Specific</a></li><li><ol class="section"><li class="expanded "><a href="cookbooks/normandy_events.html"><strong aria-hidden="true">5.2.1.</strong> Working with Normandy events</a></li></ol></li><li class="expanded "><a href="cookbooks/realtime.html"><strong aria-hidden="true">5.3.</strong> Real-time</a></li><li><ol class="section"><li class="expanded "><a href="cookbooks/realtime_analysis_plugin.html"><strong aria-hidden="true">5.3.1.</strong> Creating a Real-time Analysis Plugin</a></li><li class="expanded "><a href="cookbooks/view_pings_cep.html"><strong aria-hidden="true">5.3.2.</strong> Seeing Your Own Pings</a></li><li class="expanded "><a href="tools/cep_matcher.html"><strong aria-hidden="true">5.3.3.</strong> CEP Matcher</a></li></ol></li><li class="expanded "><a href="cookbooks/metrics.html"><strong aria-hidden="true">5.4.</strong> Metrics</a></li><li><ol class="section"><li class="expanded "><a href="cookbooks/dau.html"><strong aria-hidden="true">5.4.1.</strong> Daily Active Users (DAU)</a></li><li class="expanded "><a href="cookbooks/active_dau.html"><strong aria-hidden="true">5.4.2.</strong> Active DAU (aDAU)</a></li><li class="expanded "><a href="cookbooks/retention.html"><strong aria-hidden="true">5.4.3.</strong> Retention</a></li></ol></li></ol></li><li class="expanded "><a href="datasets/new_data.html"><strong aria-hidden="true">6.</strong> Sending telemetry</a></li><li><ol class="section"><li class="expanded "><a href="cookbooks/client_guidelines.html"><strong aria-hidden="true">6.1.</strong> Implementing Experiments</a></li><li class="expanded "><a href="cookbooks/events_best_practices.html"><strong aria-hidden="true">6.2.</strong> Sending Events</a></li><li class="expanded "><a href="cookbooks/new_ping.html"><strong aria-hidden="true">6.3.</strong> Sending a Custom Ping</a></li><li class="spacer"></li></ol></li><li class="expanded "><a href="datasets/reference.html"><strong aria-hidden="true">7.</strong> Dataset Reference</a></li><li><ol class="section"><li class="expanded "><a href="datasets/pings.html"><strong aria-hidden="true">7.1.</strong> Pings</a></li><li class="expanded "><a href="datasets/derived.html"><strong aria-hidden="true">7.2.</strong> Derived Datasets</a></li><li><ol class="section"><li class="expanded "><a href="datasets/active_profiles.html"><strong aria-hidden="true">7.2.1.</strong> Active Profiles</a></li><li class="expanded "><a href="datasets/batch_view/addons/reference.html"><strong aria-hidden="true">7.2.2.</strong> Addons</a></li><li class="expanded "><a href="datasets/other/addons_daily/reference.html"><strong aria-hidden="true">7.2.3.</strong> Addons Daily</a></li><li class="expanded "><a href="datasets/batch_view/clients_daily/reference.html"><strong aria-hidden="true">7.2.4.</strong> Clients Daily</a></li><li class="expanded "><a href="datasets/bigquery/clients_last_seen/reference.html"><strong aria-hidden="true">7.2.5.</strong> Clients Last Seen</a></li><li class="expanded "><a href="datasets/batch_view/events/reference.html"><strong aria-hidden="true">7.2.6.</strong> Events</a></li><li class="expanded "><a href="datasets/bigquery/exact_mau/reference.html"><strong aria-hidden="true">7.2.7.</strong> Exact MAU</a></li><li class="expanded "><a href="datasets/batch_view/first_shutdown_summary/reference.html"><strong aria-hidden="true">7.2.8.</strong> First Shutdown Summary</a></li><li class="expanded "><a href="datasets/batch_view/main_summary/reference.html"><strong aria-hidden="true">7.2.9.</strong> Main Summary</a></li><li class="expanded "><a href="datasets/batch_view/new_profile/reference.html"><strong aria-hidden="true">7.2.10.</strong> New Profile</a></li><li class="expanded "><a href="datasets/other/socorro_crash/reference.html"><strong aria-hidden="true">7.2.11.</strong> Socorro Crash Reports</a></li><li class="expanded "><a href="datasets/other/ssl/reference.html"><strong aria-hidden="true">7.2.12.</strong> SSL Ratios (public)</a></li><li class="expanded "><a href="datasets/batch_view/telemetry_aggregates/reference.html"><strong aria-hidden="true">7.2.13.</strong> Telemetry Aggregates</a></li><li class="expanded "><a href="datasets/batch_view/update/reference.html"><strong aria-hidden="true">7.2.14.</strong> Update</a></li></ol></li><li class="expanded "><a href="tools/experiments.html"><strong aria-hidden="true">7.3.</strong> Experimental Datasets</a></li><li><ol class="section"><li class="expanded "><a href="datasets/heartbeat.html"><strong aria-hidden="true">7.3.1.</strong> Accessing Heartbeat data</a></li><li class="expanded "><a href="datasets/shield.html"><strong aria-hidden="true">7.3.2.</strong> Accessing Shield Study data</a></li></ol></li><li class="expanded "><a href="datasets/search.html"><strong aria-hidden="true">7.4.</strong> Search Datasets</a></li><li><ol class="section"><li class="expanded "><a href="datasets/mozetl/search_aggregates/reference.html"><strong aria-hidden="true">7.4.1.</strong> Search Aggregates</a></li><li class="expanded "><a href="datasets/mozetl/search_clients_daily/reference.html"><strong aria-hidden="true">7.4.2.</strong> Search Clients Daily</a></li></ol></li><li class="expanded "><a href="datasets/other.html"><strong aria-hidden="true">7.5.</strong> Other Datasets</a></li><li><ol class="section"><li class="expanded "><a href="datasets/other/hgpush/reference.html"><strong aria-hidden="true">7.5.1.</strong> hgpush</a></li><li class="expanded "><a href="datasets/other/stub_installer/reference.html"><strong aria-hidden="true">7.5.2.</strong> Stub installer ping</a></li><li class="expanded "><a href="datasets/other/activity-stream/reference.html"><strong aria-hidden="true">7.5.3.</strong> Activity Stream</a></li></ol></li><li class="expanded "><a href="datasets/obsolete.html"><strong aria-hidden="true">7.6.</strong> Obsolete Datasets</a></li><li><ol class="section"><li class="expanded "><a href="datasets/obsolete/churn/reference.html"><strong aria-hidden="true">7.6.1.</strong> Churn</a></li><li class="expanded "><a href="datasets/obsolete/client_count/reference.html"><strong aria-hidden="true">7.6.2.</strong> Client Count</a></li><li class="expanded "><a href="datasets/obsolete/client_count_daily/reference.html"><strong aria-hidden="true">7.6.3.</strong> Client Count Daily</a></li><li class="expanded "><a href="datasets/obsolete/crash_aggregates/reference.html"><strong aria-hidden="true">7.6.4.</strong> Crash Aggregates</a></li><li class="expanded "><a href="datasets/obsolete/crash_summary/reference.html"><strong aria-hidden="true">7.6.5.</strong> Crash Summary</a></li><li class="expanded "><a href="datasets/obsolete/error_aggregates/reference.html"><strong aria-hidden="true">7.6.6.</strong> Error Aggregates</a></li><li class="expanded "><a href="datasets/obsolete/heavy_users/reference.html"><strong aria-hidden="true">7.6.7.</strong> Heavy Users</a></li><li class="expanded "><a href="datasets/obsolete/longitudinal/reference.html"><strong aria-hidden="true">7.6.8.</strong> Longitudinal</a></li><li class="expanded "><a href="datasets/obsolete/retention/reference.html"><strong aria-hidden="true">7.6.9.</strong> Retention</a></li><li class="expanded "><a href="datasets/obsolete/sync_summary/reference.html"><strong aria-hidden="true">7.6.10.</strong> Sync Summary</a></li></ol></li><li class="expanded "><a href="datasets/fxa.html"><strong aria-hidden="true">7.7.</strong> Firefox Accounts Datasets</a></li><li><ol class="section"><li class="expanded "><a href="datasets/fxa_metrics/attribution.html"><strong aria-hidden="true">7.7.1.</strong> Firefox Account Attribution</a></li><li class="expanded "><a href="datasets/fxa_metrics/funnels.html"><strong aria-hidden="true">7.7.2.</strong> Firefox Account Funnel Metrics</a></li><li class="expanded "><a href="datasets/fxa_metrics/emails.html"><strong aria-hidden="true">7.7.3.</strong> Firefox Account Email Metrics</a></li><li class="spacer"></li></ol></li></ol></li><li class="expanded "><a href="concepts/index.html"><strong aria-hidden="true">8.</strong> Telemetry Behavior Reference</a></li><li><ol class="section"><li class="expanded "><a href="concepts/history.html"><strong aria-hidden="true">8.1.</strong> History of Telemetry</a></li><li class="expanded "><a href="concepts/profile/index.html"><strong aria-hidden="true">8.2.</strong> Profile Behavior</a></li><li><ol class="section"><li class="expanded "><a href="concepts/profile/profile_creation.html"><strong aria-hidden="true">8.2.1.</strong> Profile Creation</a></li><li class="expanded "><a href="concepts/profile/realworldusage.html"><strong aria-hidden="true">8.2.2.</strong> Real World Usage</a></li><li class="expanded "><a href="concepts/profile/profilehistory.html"><strong aria-hidden="true">8.2.3.</strong> Profile History</a></li></ol></li><li class="expanded "><a href="concepts/channels/index.html"><strong aria-hidden="true">8.3.</strong> Channel Behavior</a></li><li><ol class="section"><li class="expanded "><a href="concepts/channels/channel_normalization.html"><strong aria-hidden="true">8.3.1.</strong> Channel Normalization and Querying</a></li></ol></li><li class="expanded "><a href="concepts/censuses.html"><strong aria-hidden="true">8.4.</strong> Census metrics</a></li><li class="expanded "><a href="concepts/engagement.html"><strong aria-hidden="true">8.5.</strong> Engagement metrics</a></li><li class="expanded "><a href="concepts/sample_id.html"><strong aria-hidden="true">8.6.</strong> Sampling</a></li><li class="spacer"></li></ol></li><li class="expanded "><a href="meta/index.html"><strong aria-hidden="true">9.</strong> About this Documentation</a></li><li><ol class="section"><li class="expanded "><a href="meta/contributing.html"><strong aria-hidden="true">9.1.</strong> Contributing</a></li><li class="expanded "><a href="meta/structure.html"><strong aria-hidden="true">9.2.</strong> Structure</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar" class="menu-bar">
                    <div id="menu-bar-sticky-container">
                        <div class="left-buttons">
                            <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                                <i class="fa fa-bars"></i>
                            </button>
                            <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                                <i class="fa fa-paint-brush"></i>
                            </button>
                            <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                                <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                            </ul>
                            
                            <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                                <i class="fa fa-search"></i>
                            </button>
                            
                        </div>

                        <h1 class="menu-title">Firefox Data Documentation</h1>

                        <div class="right-buttons">
                            <a href="print.html" title="Print this book" aria-label="Print this book">
                                <i id="print-button" class="fa fa-print"></i>
                            </a>
                            
                        </div>
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#firefox-data-documentation" id="firefox-data-documentation">Firefox Data Documentation</a></h1>
<p>This documentation is intended to help Mozilla's developers and data scientists analyze and interpret the data gathered
by the Firefox Telemetry system.</p>
<p>At <a href="https://www.mozilla.org">Mozilla</a>, our data-gathering and data-handling practices are anchored in our
<a href="https://www.mozilla.org/en-US/privacy/principles/">Data Privacy Principles</a> and elaborated in the
<a href="https://www.mozilla.org/en-US/privacy/">Mozilla Privacy Policy</a>. You can learn more about what data Firefox
collects and the choices you can make as a Firefox user in the
<a href="https://www.mozilla.org/en-US/privacy/firefox/">Firefox Privacy Notice</a>.</p>
<p>If there's information missing from these docs, or if you'd like to contribute, see <a href="meta/contributing.html">this article on contributing</a>,
and feel free to <a href="https://bugzilla.mozilla.org/enter_bug.cgi?assigned_to=nobody%40mozilla.org&amp;bug_file_loc=http%3A%2F%2F&amp;bug_ignored=0&amp;bug_severity=normal&amp;bug_status=NEW&amp;cf_fx_iteration=---&amp;cf_fx_points=---&amp;component=Documentation%20and%20Knowledge%20Repo%20%28RTMO%29&amp;contenttypemethod=autodetect&amp;contenttypeselection=text%2Fplain&amp;defined_groups=1&amp;flag_type-4=X&amp;flag_type-607=X&amp;flag_type-800=X&amp;flag_type-803=X&amp;flag_type-916=X&amp;form_name=enter_bug&amp;maketemplate=Remember%20values%20as%20bookmarkable%20template&amp;op_sys=Linux&amp;priority=--&amp;product=Data%20Platform%20and%20Tools&amp;rep_platform=x86_64&amp;target_milestone=---&amp;version=unspecified">file a bug here</a>.</p>
<p>The source for this documentation can be found in <a href="https://github.com/mozilla/firefox-data-docs">this repo</a>.</p>
<h2><a class="header" href="#using-this-document" id="using-this-document">Using this document</a></h2>
<p>This documentation is divided into four main sections:</p>
<h3><a class="header" href="#a-hrefconceptsgetting_startedhtmlgetting-starteda" id="a-hrefconceptsgetting_startedhtmlgetting-starteda"><a href="concepts/getting_started.html">Getting Started</a></a></h3>
<p>This section provides a <strong>quick introduction</strong> to analyzing telemetry data.
After reading these articles, you will be able to confidently perform analysis
over telemetry data.</p>
<h3><a class="header" href="#a-hreftoolsindexhtmltoolsa" id="a-hreftoolsindexhtmltoolsa"><a href="tools/index.html">Tools</a></a></h3>
<p>Describes the tools we maintain to access and analyze product data.</p>
<h3><a class="header" href="#a-hrefcookbooksindexhtmlcookbooks--tutorialsa" id="a-hrefcookbooksindexhtmlcookbooks--tutorialsa"><a href="cookbooks/index.html">Cookbooks &amp; Tutorials</a></a></h3>
<p>This section contains tutorials presented in a simple problem/solution format.</p>
<h3><a class="header" href="#a-hrefdatasetsreferencehtmldata-collection-and-datasetsa" id="a-hrefdatasetsreferencehtmldata-collection-and-datasetsa"><a href="datasets/reference.html">Data Collection and Datasets</a></a></h3>
<p>Describes all available data we have from our products.
For each dataset, we include a description of the dataset's purpose,
what data is included, how the data is collected,
and how you can change or augment the dataset.
You do not need to read this section end-to-end.</p>
<p>You can find the <a href="https://mozilla.github.io/firefox-data-docs/">fully-rendered documentation here</a>,
rendered with <a href="https://github.com/rust-lang/mdBook">mdBook</a>, and hosted on Github pages.</p>
<h1><a class="header" href="#reporting-a-problem" id="reporting-a-problem">Reporting a problem</a></h1>
<p>If you have a problem with data tools, datasets, or other pieces of infrastructure,
please help us out by reporting it.</p>
<p>Most of our work is tracked in Bugzilla in the <a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Data%20Platform%20and%20Tools">Data Platform and Tools</a> product.</p>
<p>Bugs should be filed in the closest-matching component in the Data Platform and Tools
product, but if there is no component for the item in question, please file an issue
in the <a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Data%20Platform%20and%20Tools&amp;component=General">General component</a>.</p>
<p>Components are triaged at least weekly by the component owner(s). For issues needing
urgent attention, it is recommended that you use the <code>needinfo</code> flag to attract attention
from a specific person. If an issue doesn't receive the appropriate attention within a
week, you can send email to the <code>fx-data-dev</code> mailing list, reach out on IRC
in <code>#datapipeline</code>, or on Slack in <code>#fx-metrics</code>.</p>
<p>When a bug is triaged, it will be assigned a <strong>priority</strong> and <strong>points</strong>. <strong>Priorities</strong> have the
following meanings:</p>
<ul>
<li><strong><code>P1</code></strong>: in active development in the current sprint</li>
<li><strong><code>P2</code></strong>: planned to be worked on in the current quarter</li>
<li><strong><code>P3</code></strong>: planned to be worked on next quarter</li>
<li><strong><code>P4</code></strong> and beyond: nice to have, we would accept a patch, but not actively being worked on.</li>
</ul>
<p><strong>Points</strong> reflect the amount of effort required for a bug and are assigned as follows:</p>
<ul>
<li><strong>1 point</strong>: one day or less of effort</li>
<li><strong>2 points</strong>: two days of effort</li>
<li><strong>3 points</strong>: three days to a week of effort</li>
<li><strong>5 points</strong> or more: SO MUCH EFFORT, major project.</li>
</ul>
<h3><a class="header" href="#problems-with-the-data" id="problems-with-the-data">Problems with the data</a></h3>
<p>There are bugzilla components for several of core datasets.
described in this documentation, so if possible, please use a specific component.</p>
<p>If there is a problem with a dataset that does not have its own component, please
file an issue in the <a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Data%20Platform%20and%20Tools&amp;component=Datasets%3A%20General">Datasets: General component</a>.</p>
<h3><a class="header" href="#problems-with-tools" id="problems-with-tools">Problems with tools</a></h3>
<p>There are bugzilla components for several of the <a href="concepts/../tools/interfaces.html">tools</a> that
comprise the <a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Data%20Platform%20and%20Tools">Data Platform</a>,
so please file a bug in the specific component that most closely matches the
tool in question.</p>
<p>Operational bugs, such as services being unavailable, should be filed either in
the component for the service itself or in the <a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Data%20Platform%20and%20Tools&amp;component=Operations">Operations component</a>.</p>
<h3><a class="header" href="#other-problems" id="other-problems">Other problems</a></h3>
<p>When in doubt, please file issues in the <a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Data%20Platform%20and%20Tools&amp;component=General">General component</a>.</p>
<h1><a class="header" href="#terminology" id="terminology">Terminology</a></h1>
<ul>
<li><strong>Analyst</strong>: Someone performing analysis.
This is more general than <strong>data scientist</strong>.</li>
<li><strong>Ping</strong>: A message sent from the Firefox browser to our telemetry servers containing information on browser state, user actions, etc...
(<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/common-ping.html">more details</a>)</li>
<li><strong>Dataset</strong>: A set of data, includes ping data, derived datasets, etc...</li>
<li><strong>Derived Dataset</strong>: A processed dataset, such as <code>main_summary</code> or the
<code>clients_daily</code> dataset</li>
<li><strong>Session</strong>: The time from when a Firefox browser starts until it shuts down</li>
<li><strong>Subsession</strong>: <code>Sessions</code> are split into <code>subsessions</code> when a 24 hour threshold is crossed or an environment change occurs
(<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/concepts/sessions.html?highlight=subsession">more details</a>)</li>
<li>...</li>
</ul>
<h1><a class="header" href="#getting-started" id="getting-started">Getting Started</a></h1>
<p>This document is meant to be a complete guide to using Firefox Data,
so it can look overwhelming at first.
These readings will <strong>get you up and running quickly</strong>
After these readings you should be able to produce simple analyses
but you should definitely get your analyses reviewed.</p>
<p>This section is meant to introduce new analysts to our data.
I consider a &quot;new analyst&quot; to be an employee
who is interested in working with our data
but doesn't have previous experience with our tools/data.
They could be technical or non-technical: engineer, PM, or data scientist.</p>
<h1><a class="header" href="#getting-started-with-firefox-desktop-data" id="getting-started-with-firefox-desktop-data">Getting Started with Firefox Desktop Data</a></h1>
<p>The remainder of this section section describes Firefox Desktop Telemetry
which goes back in various forms for many years.
Modern data collection is based on the <a href="concepts/glean/glean.html">Glean platform</a>.
Older mobile product data is slightly different again, and is described
in <a href="concepts/choosing_a_dataset_mobile.html">Choosing a Mobile Dataset</a>.</p>
<p>Firefox clients out in the wild send us data as <em>pings</em>.
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html"><code>Main</code> pings</a> contain some combination of <em>environment</em> data
(e.g. operating system, hardware, Firefox version), <a href="https://probes.telemetry.mozilla.org/"><em>measurements</em></a>
(e.g. max number of open tabs, time spent running in JavaScript garbage collection),
and <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/events.html"><em>events</em></a>.
We have quite a few different pings, but most of our data for Firefox Desktop
comes in from <code>main</code> pings.</p>
<h2><a class="header" href="#measurement-types" id="measurement-types">Measurement Types</a></h2>
<p>When we need to measure specific things about clients, we use probes.
A single ping will send in many different probes.
There are two types of probes that we are interested in here: <em>Histograms</em> and <em>Scalars</em>.</p>
<p>You can search for and find more details about probes using the
<a href="https://probes.telemetry.mozilla.org/">Probe Dictionary</a>.
It shows things like probe descriptions, when a probe started being collected,
and whether it is collected on the release channel.</p>
<p>Histograms are bucketed counts.
The <a href="https://github.com/mozilla/gecko-dev/blob/master/toolkit/components/telemetry/Histograms.json"><code>Histograms.json</code></a> file has the definitions for all histograms,
which includes the minimum, maximum, and number of buckets.
Any recorded value instead just increments its associated bucket.
We have four main types of histograms:</p>
<ol>
<li>Boolean - Only two buckets, associated with true and false.</li>
<li>Enumerated - Integer buckets, where usually each bucket has a label.</li>
<li>Linear - Buckets are divided evenly between the minimum and maximum;
e.g. [1-2] is a bucket, and so is [100-101].</li>
<li>Exponential - Larger valued buckets cover a larger range;
e.g. [1-2] is a bucket, and so is [100-200].</li>
</ol>
<p>To see some of these in action, take a look at the <a href="https://telemetry.mozilla.org/histogram-simulator">Histogram Simulator</a>.</p>
<p>Scalars are simply a single value.
The <a href="https://dxr.mozilla.org/mozilla-central/rev/tip/toolkit/components/telemetry/Scalars.yaml"><code>Scalars.yaml</code></a> file has the definitions for all scalars.
These values can be integers, strings, or booleans.</p>
<h2><a class="header" href="#tmo" id="tmo">TMO</a></h2>
<p>The simplest way to start looking at probe data is to head over to
<a href="https://telemetry.mozilla.org/"><code>telemetry.mozilla.org</code></a> or <a href="https://telemetry.mozilla.org/">TMO</a> for short.</p>
<p>From there, you will likely want either <a href="https://telemetry.mozilla.org/new-pipeline/dist.html">the Measurement Dashboard</a>
or <a href="https://telemetry.mozilla.org/new-pipeline/evo.html">the Evolution Dashboard</a>.
Using these dashboards you can compare a probe's value between populations,
e.g. <code>GC_MS</code> for 64 bit vs. 32 bit, and even track it across builds.</p>
<p>The <a href="https://telemetry.mozilla.org/new-pipeline/dist.html">Measurement Dashboard</a> is a snapshot, aggregating all
the data from all chosen dimensions.
The Y axis is % of samples, and the X axis is the bucket.
You can compare between dimensions, but it does not give you the ability to
see how data is changing over time.
To investigate that you must use the <a href="https://telemetry.mozilla.org/new-pipeline/evo.html">Evolution Dashboard</a>.</p>
<p>The <a href="https://telemetry.mozilla.org/new-pipeline/evo.html">Evolution Dashboard</a> shows how the data changes over time.
Choose which statistics you'd like to plot over time, e.g. Median or 95th percentile.
The X axis is time, and the Y axis is the value for whichever statistic you've chosen.
<a href="https://telemetry.mozilla.org/new-pipeline/evo.html#!aggregates=median!95th-percentile&amp;cumulative=0&amp;end_date=2017-06-13&amp;keys=!__none__!__none__&amp;max_channel_version=nightly%252F56&amp;measure=GC_MS&amp;min_channel_version=nightly%252F53&amp;processType=*&amp;product=Firefox&amp;sanitize=1&amp;sort_keys=submissions&amp;start_date=2017-06-12&amp;trim=1&amp;use_submission_date=0">This dashboard</a>, for example, shows how <code>GC_MS</code> is improving from
nightly 53 to nightly 56!
While the median is not changing much, the 95th percentile is trending down,
indicating that long garbage collections are being shortened.</p>
<p>The X axis on the Evolution Dashboard shows either Build ID (a date), or Submission Date.
The difference is that on any single date we might receive submissions from
lots of builds, but aggregating by Build ID means we can be sure a change was
because of a new build.</p>
<p>The second plot on the Evolution View is the number of pings we saw containing
that probe (Metric Count).</p>
<h3><a class="header" href="#tmo-caveats" id="tmo-caveats">TMO Caveats</a></h3>
<ul>
<li>Data is aggregated on a <em>per-ping</em> basis, meaning <em>these dashboards cannot
be used to say something definitive about users</em>.
Please repeat that to yourself.
A trend in the evolution view may be caused not by a change affecting lots of
users, but a change affecting <em>one</em> single user who is now sending 50% of
the pings we see.
<a href="https://mozilla.report/post/projects%2Fproblematic_client.kp">And yes, that does happen.</a></li>
<li>Sometimes it looks like no data is there, but you think there should be.
Check under advanced settings and check &quot;Don't Sanitize&quot; and &quot;Don't Trim Buckets&quot;.
If it's still not there, let us know in IRC on #telemetry.</li>
<li>TMO Measurement Dashboards do not currently show release-channel data.
Release-channel data <a href="https://medium.com/georg-fritzsche/data-preference-changes-in-firefox-58-2d5df9c428b5">ceased being aggregated</a> as of Firefox 58.
We're looking into ways of doing this correctly in the near future.</li>
</ul>
<h2><a class="header" href="#where-to-go-next" id="where-to-go-next">Where to go next</a></h2>
<ul>
<li><a href="concepts/../tools/stmo.html">Analysis using STMO</a></li>
<li><a href="concepts/../tools/spark.html">Advanced analysis with Spark</a></li>
<li><a href="concepts/../tools/experiments.html">Experimental data</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Mozilla/Performance/Adding_a_new_Telemetry_probe">Adding probes, collecting more data</a></li>
<li><a href="concepts/../datasets/derived.html">Augmenting the derived datasets</a></li>
</ul>
<h1><a class="header" href="#choosing-a-desktop-product-dataset" id="choosing-a-desktop-product-dataset">Choosing a Desktop Product Dataset</a></h1>
<p>This document will help you find the best data source for a given analysis.</p>
<p>This guide focuses on descriptive datasets and does not cover experimentation.
For example, this guide will help if you need to answer questions like:</p>
<ul>
<li>How many users do we have in Germany, how many crashes we see per day?</li>
<li>How many users have a given addon installed?</li>
</ul>
<p>If you're interested in figuring out whether there's a causal link between two events
take a look at our <a href="concepts/../tools/experiments.html">tools for experimentation</a>.</p>
<h2><a class="header" href="#table-of-contents" id="table-of-contents">Table of Contents</a></h2>
<ul>
<li><a href="concepts/choosing_a_dataset.html#raw-pings">Raw Pings</a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#main-ping">&quot;main&quot; ping</a></li>
<li><a href="concepts/choosing_a_dataset.html#first-shutdown-ping">&quot;first-shutdown&quot; ping</a></li>
<li><a href="concepts/choosing_a_dataset.html#event-ping">&quot;event&quot; ping</a></li>
<li><a href="concepts/choosing_a_dataset.html#update-ping">&quot;update&quot; ping</a></li>
<li><a href="concepts/choosing_a_dataset.html#new-profile-ping">&quot;new-profile&quot; ping</a></li>
<li><a href="concepts/choosing_a_dataset.html#crash-ping">&quot;crash&quot; ping</a></li>
<li><a href="concepts/choosing_a_dataset.html#deletion-request-ping">&quot;deletion request&quot; ping</a></li>
<li><a href="concepts/choosing_a_dataset.html#pingsender">Pingsender</a></li>
<li><a href="concepts/choosing_a_dataset.html#analysis">Analysis</a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the Data</a></li>
<li><a href="concepts/choosing_a_dataset.html#further-reading">Further Reading</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#main-ping-derived-datasets">Main Ping Derived Datasets</a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#clients_daily"><code>clients_daily</code></a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#contents">Contents</a></li>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#clients_last_seen"><code>clients_last_seen</code></a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#content">Content</a></li>
<li><a href="concepts/choosing_a_dataset.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#main_summary"><code>main_summary</code></a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#contents">Contents</a></li>
<li><a href="concepts/choosing_a_dataset.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#first_shutdown_summary"><code>first_shutdown_summary</code></a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#contents">Contents</a></li>
<li><a href="concepts/choosing_a_dataset.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#client_count_daily"><code>client_count_daily</code></a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#content">Content</a></li>
<li><a href="concepts/choosing_a_dataset.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the Data</a></li>
<li><a href="concepts/choosing_a_dataset.html#further-reading">Further Reading</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#new-profile-derived-datasets">New-Profile Derived Datasets</a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#contents">Contents</a></li>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the Data</a></li>
<li><a href="concepts/choosing_a_dataset.html#further-reading">Further Reading</a></li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#update-derived-dataset">Update Derived Dataset</a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#contents">Contents</a></li>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the Data</a></li>
<li><a href="concepts/choosing_a_dataset.html#further-reading">Further Reading</a></li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#other-datasets">Other Datasets</a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#contents">Contents</a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#obsolete-datasets">Obsolete Datasets</a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#heavy_users"><code>heavy_users</code></a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#contents">Contents</a></li>
<li><a href="concepts/choosing_a_dataset.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the Data</a></li>
<li><a href="concepts/choosing_a_dataset.html#further-reading">Further Reading</a></li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#retention"><code>retention</code></a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#contents">Contents</a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#churn"><code>churn</code></a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#content">Content</a></li>
<li><a href="concepts/choosing_a_dataset.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#error_aggregates"><code>error_aggregates</code></a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#contents">Contents</a></li>
<li><a href="concepts/choosing_a_dataset.html#accessing-the-data">Accessing the data</a></li>
<li><a href="concepts/choosing_a_dataset.html#further-reading">Further Reading</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="concepts/choosing_a_dataset.html#appendix">Appendix</a>
<ul>
<li><a href="concepts/choosing_a_dataset.html#mobile-metrics">Mobile Metrics</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#raw-pings" id="raw-pings">Raw Pings</a></h1>
<p>We receive data from our users via <strong>pings</strong>.
There are several types of pings,
each containing different measurements and sent for different purposes.
To review a complete list of ping types and their schemata, see
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/index.html">this section of the Mozilla Source Tree Docs</a>.</p>
<p>Pings are also described by a JSONSchema specification which can be found in <a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/tree/master/schemas/telemetry">the <code>mozilla-pipeline-schemas</code> repository</a>.</p>
<p>There are a few pings that are central to delivering our core data collection
primitives (Histograms, Events, Scalars) and for keeping an eye on Firefox
behaviour (Environment, New Profiles, Updates, Crashes).</p>
<p>For instance, a user's first session in Firefox might have four pings like this:</p>
<p><img src="concepts//datasets/images/first_session_pings.png" alt="Flowchart of pings in the user's first session" /></p>
<h3><a class="header" href="#main-ping" id="main-ping">&quot;main&quot; ping</a></h3>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html">&quot;main&quot; ping</a> is the workhorse of the Firefox Telemetry system.
It delivers the Telemetry Environment as well as Histograms and Scalars for all
process types that collect data in Firefox. It has several variants each with
specific delivery characteristics:</p>
<table><thead><tr><th>Reason</th><th>Sent when</th><th>Notes</th></tr></thead><tbody>
<tr><td>shutdown</td><td>Firefox session ends cleanly</td><td>Accounts for about <a href="https://sql.telemetry.mozilla.org/queries/3434">80%</a> of all &quot;main&quot; pings. Sent by Pingsender immediately after Firefox shuts down, subject to conditions: Firefox 55+, if the OS isn't also shutting down, and if this isn't the client's first session. If Pingsender fails or isn't used, the ping is sent by Firefox at the beginning of the next Firefox session.</td></tr>
<tr><td>daily</td><td>It has been more than 24 hours since the last &quot;main&quot; ping, and it is around local midnight</td><td>In long-lived Firefox sessions we might go days without receiving a &quot;shutdown&quot; ping. Thus the &quot;daily&quot; ping is sent to ensure we occasionally hear from long-lived sessions.</td></tr>
<tr><td>environment-change</td><td>Telemetry Environment changes</td><td>Is sent immediately when triggered by Firefox (Installing or removing an addon or changing a monitored user preference are common ways for the Telemetry Environment to change)</td></tr>
<tr><td>aborted-session</td><td>Firefox session doesn't end cleanly</td><td>Sent by Firefox at the beginning of the next Firefox session.</td></tr>
</tbody></table>
<p>It was introduced in Firefox 38.</p>
<h3><a class="header" href="#first-shutdown-ping" id="first-shutdown-ping">&quot;first-shutdown&quot; ping</a></h3>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/first-shutdown-ping.html">&quot;first-shutdown&quot; ping</a> is identical to the &quot;main&quot;
ping with reason &quot;shutdown&quot; created at the end of the user's first session,
but sent with a different ping type. This was introduced when we started
using Pingsender to send shutdown pings as there would be a lot of
first-session &quot;shutdown&quot; pings that we'd start receiving all of a sudden.</p>
<p>It is sent using Pingsender.</p>
<p>It was introduced in Firefox 57.</p>
<h3><a class="header" href="#event-ping" id="event-ping">&quot;event&quot; ping</a></h3>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/event-ping.html">&quot;event&quot; ping</a> provides low-latency eventing support to Firefox
Telemetry. It delivers the Telemetry Environment, Telemetry Events from all
Firefox processes, and some diagnostic information about Event Telemetry. It is
sent every hour if there have been events recorded, and up to once every 10
minutes (governed by a <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/internals/preferences.html">preference</a>) if the maximum event limit
for the ping (default to 1000 per process, governed by a
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/internals/preferences.html">preference</a>) is reached before the hour is up.</p>
<p>It was introduced in Firefox 62.</p>
<h3><a class="header" href="#update-ping" id="update-ping">&quot;update&quot; ping</a></h3>
<p>Firefox Update is the most important means we have of reaching our users with
the latest fixes and features. The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/update-ping.html">&quot;update&quot; ping</a> notifies us
when an update is downloaded and ready to be applied (reason: &quot;ready&quot;) and when
the update has been successfully applied (reason: &quot;success&quot;). It contains the
Telemetry Environment and information about the update.</p>
<p>It was introduced in Firefox 56.</p>
<h3><a class="header" href="#new-profile-ping" id="new-profile-ping">&quot;new-profile&quot; ping</a></h3>
<p>When a user starts up Firefox for the first time, a profile is created.
Telemetry marks the occasion with the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/new-profile-ping.html">&quot;new-profile&quot; ping</a>
which sends the Telemetry Environment. It is sent either 30 minutes after Firefox
starts running for the first time in this profile (reason: &quot;startup&quot;) or at the
end of the profile's first session (reason: &quot;shutdown&quot;), whichever comes first.
&quot;new-profile&quot; pings are sent immediately when triggered. Those with reason
&quot;startup&quot; are sent by Firefox. Those with reason &quot;shutdown&quot; are sent by
Pingsender.</p>
<p>It was introduced in Firefox 55.</p>
<h3><a class="header" href="#crash-ping" id="crash-ping">&quot;crash&quot; ping</a></h3>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/crash-ping.html">&quot;crash&quot; ping</a> provides diagnostic information whenever a
Firefox process exits abnormally. Unlike the &quot;main&quot; ping with reason
&quot;aborted-session&quot;, this ping does not contain Histograms or Scalars. It
contains a Telemetry Environment, <a href="https://searchfox.org/mozilla-central/source/toolkit/crashreporter/CrashAnnotations.yaml">Crash Annotations</a>, and
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/crash-ping.html#stack-traces">Stack Traces</a>.</p>
<p>It was introduced in Firefox 40.</p>
<h3><a class="header" href="#deletion-request-ping" id="deletion-request-ping">&quot;deletion request&quot; ping</a></h3>
<p>In the event a user opts out of Telemetry, we send one final
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/data/deletion-request-ping.html">&quot;deletion-request&quot; ping</a> to let us know. It contains
only the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/common-ping.html">common ping data</a> and an empty payload.</p>
<p>It was introduced in Firefox 72, replacing the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/obsolete/optout-ping.html">&quot;optout&quot; ping</a>
(which was in turn introduced in Firefox 63).</p>
<h3><a class="header" href="#pingsender" id="pingsender">Pingsender</a></h3>
<p><a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/internals/pingsender.html">Pingsender</a> is a small application shipped with Firefox which
attempts to send pings even if Firefox is not running. If Firefox has crashed or has already shut
down we would otherwise have to wait for the next Firefox session to begin to
send pings.</p>
<p>Pingsender was introduced in Firefox 54 to send &quot;crash&quot; pings. It was expanded
to send &quot;main&quot; pings of reason &quot;shutdown&quot; in Firefox 55 (excepting the first
session). It sends the &quot;first-shutdown&quot; ping since its introduction in Firefox 57.</p>
<h3><a class="header" href="#analysis" id="analysis">Analysis</a></h3>
<p>The large majority of analyses can be completed using only the
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html">main ping</a>.
This ping includes histograms, scalars, and other performance and diagnostic data.</p>
<p>Few analyses actually rely directly on any raw ping data.
Instead, we provide <strong>derived datasets</strong> which are processed versions of these data,
made to be:</p>
<ul>
<li>Easier and faster to query</li>
<li>Organized to make the data easier to analyze</li>
<li>Cleaned of erroneous or misleading data</li>
</ul>
<p>Before analyzing raw ping data,
<strong>check to make sure there isn't already a derived dataset</strong> made for your purpose.
If you do need to work with raw ping data, be aware that the volume of data can be high.
Try to limit the size of your data by controlling the date range, and start off using a sample.</p>
<h4><a class="header" href="#accessing-the-data" id="accessing-the-data">Accessing the Data</a></h4>
<p>Ping data lives in BigQuery and is accessible in <a href="https://sql.telemetry.mozilla.org/">re:dash</a>;
see the <a href="concepts/../cookbooks/bigquery.html">BigQuery intro</a> article.</p>
<h4><a class="header" href="#further-reading" id="further-reading">Further Reading</a></h4>
<p>You can find <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/index.html">the complete ping documentation</a>.
To augment our data collection, see <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Performance/Adding_a_new_Telemetry_probe">Collecting New Data</a> and the
<a href="https://wiki.mozilla.org/Firefox/Data_Collection">Data Collection Policy</a>.</p>
<h1><a class="header" href="#main-ping-derived-datasets" id="main-ping-derived-datasets">Main Ping Derived Datasets</a></h1>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html">main ping</a> contains most of the measurements used to track performance
and health of Firefox in the wild.
This ping includes histograms, scalars, and events.</p>
<p>This section describes the derived datasets we provide to make analyzing this data easier.</p>
<h2><a class="header" href="#clients_daily" id="clients_daily"><code>clients_daily</code></a></h2>
<p>The <code>clients_daily</code> table is intended as the first stop for asking questions
about how people use Firefox. It should be easy to answer simple questions.
Each row in the table is a (<code>client_id</code>, <code>submission_date</code>) and contains a
number of aggregates about that day's activity.</p>
<h4><a class="header" href="#contents" id="contents">Contents</a></h4>
<p>Many questions about Firefox take the form &quot;What did clients with
characteristics X, Y, and Z do during the period S to E?&quot; The
<code>clients_daily</code> table is aimed at answer those questions.</p>
<h4><a class="header" href="#accessing-the-data-1" id="accessing-the-data-1">Accessing the Data</a></h4>
<p>The <code>clients_daily</code> table is accessible through re:dash using the
<code>Telemetry (BigQuery)</code> data source.</p>
<p>Here's an <a href="https://sql.telemetry.mozilla.org/queries/23746#61771">example query</a>.</p>
<h2><a class="header" href="#clients_last_seen" id="clients_last_seen"><code>clients_last_seen</code></a></h2>
<p>The <code>clients_last_seen</code> dataset is useful for efficiently determining exact
user counts such as <a href="concepts/../../../cookbooks/dau.html">DAU and MAU</a>.</p>
<p>It does <em>not</em> use approximates, unlike the HyperLogLog algorithm used in the
<a href="concepts//datasets/obsolete/client_count/reference.html"><code>client_count_daily</code> dataset</a>,
and it includes the most recent values in a 28 day window for all columns in
the <a href="concepts//datasets/batch_view/clients_daily/reference.html"><code>clients_daily</code> dataset</a>.</p>
<p>This dataset should be used instead of <code>client_count_daily</code>.</p>
<h4><a class="header" href="#content" id="content">Content</a></h4>
<p>For each <code>submission_date</code> this dataset contains one row per <code>client_id</code>
that appeared in <code>clients_daily</code> in a 28 day window including
<code>submission_date</code> and preceding days.</p>
<p>The <code>days_since_seen</code> column indicates the difference between <code>submission_date</code>
and the most recent <code>submission_date</code> in <code>clients_daily</code> where the <code>client_id</code>
appeared. A client observed on the given <code>submission_date</code> will have <code>days_since_seen = 0</code>.</p>
<p>Other <code>days_since_</code> columns use the most recent date in <code>clients_daily</code> where
a certain condition was met. If the condition was not met for a <code>client_id</code> in
a 28 day window <code>NULL</code> is used. For example <code>days_since_visited_5_uri</code> uses the
condition <code>scalar_parent_browser_engagement_total_uri_count_sum &gt;= 5</code>. These
columns can be used for user counts where a condition must be met on any day
in a window instead of using the most recent values for each <code>client_id</code>.</p>
<p>The rest of the columns use the most recent value in <code>clients_daily</code> where
the <code>client_id</code> appeared.</p>
<h4><a class="header" href="#background-and-caveats" id="background-and-caveats">Background and Caveats</a></h4>
<p>User counts generated using <code>days_since_seen</code> only reflect the most recent
values from <code>clients_daily</code> for each <code>client_id</code> in a 28 day window. This means
<a href="concepts/../../../cookbooks/active_dau.html">Active MAU</a>
as defined cannot be efficiently calculated using <code>days_since_seen</code> because if
a given <code>client_id</code> appeared every day in February and only on February 1st had
<code>scalar_parent_browser_engagement_total_uri_count_sum &gt;= 5</code> then it would only
be counted on the 1st, and not the 2nd-28th. Active MAU can be efficiently and
correctly calculated using <code>days_since_visited_5_uri</code>.</p>
<p>MAU can be calculated over a <code>GROUP BY submission_date[, ...]</code> clause using
<code>COUNT(*)</code>, because there is exactly one row in the dataset for each
<code>client_id</code> in the 28 day MAU window for each <code>submission_date</code>.</p>
<p>User counts generated using <code>days_since_seen</code> can use <code>SUM</code> to reduce groups,
because a given <code>client_id</code> will only be in one group per <code>submission_date</code>. So
if MAU were calculated by <code>country</code> and <code>channel</code>, then the sum of the MAU for
each <code>country</code> would be the same as if MAU were calculated only by <code>channel</code>.</p>
<h4><a class="header" href="#accessing-the-data-2" id="accessing-the-data-2">Accessing the Data</a></h4>
<p>The data is available in Re:dash and BigQuery. Take a look at this full running
<a href="https://sql.telemetry.mozilla.org/queries/62029/source#159510">example query in Re:dash</a>.</p>
<h2><a class="header" href="#main_summary" id="main_summary"><code>main_summary</code></a></h2>
<h4><a class="header" href="#contents-1" id="contents-1">Contents</a></h4>
<p>The <code>main_summary</code> table contains one row for each ping.
Each column represents one field from the main ping payload,
though only a subset of all main ping fields are included.
This dataset <strong>does not include most histograms</strong>.</p>
<h4><a class="header" href="#background-and-caveats-1" id="background-and-caveats-1">Background and Caveats</a></h4>
<p>This table is massive, and due to its size, it can be difficult to work with.</p>
<p>Instead, we recommend using the <code>clients_daily</code> or <code>clients_last_seen</code> dataset
where possible.</p>
<p>If you do need to query this table, make use of the <code>sample_id</code> field and
limit to a short submission date range.</p>
<h4><a class="header" href="#accessing-the-data-3" id="accessing-the-data-3">Accessing the Data</a></h4>
<p>The <code>main_summary</code> table is accessible through re:dash.
Here's an <a href="https://sql.telemetry.mozilla.org/queries/4201/source">example query</a>.</p>
<h2><a class="header" href="#first_shutdown_summary" id="first_shutdown_summary"><code>first_shutdown_summary</code></a></h2>
<p>The <code>first_shutdown_summary</code> table is a summary of the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/first-shutdown-ping.html"><code>first-shutdown</code>
ping</a>.</p>
<h4><a class="header" href="#contents-2" id="contents-2">Contents</a></h4>
<p>The first shutdown ping contains first session usage data. The
dataset has rows similar to the
<a href="concepts//datasets/batch_view/new_profile/reference.html"><code>telemetry_new_profile_parquet</code></a>,
but in the shape of
<a href="concepts//datasets/batch_view/main_summary/reference.html"><code>main_summary</code></a>.</p>
<h4><a class="header" href="#background-and-caveats-2" id="background-and-caveats-2">Background and Caveats</a></h4>
<p>Ping latency was reduced through the
shutdown ping-sender mechanism in Firefox 55. To maintain consistent historical
behavior, the first main ping is not sent until the second start up. In Firefox 57, a
separate first-shutdown ping was created to evaluate first-shutdown behavior while maintaining backwards compatibility.</p>
<p>In many cases, the first-shutdown ping is a duplicate of the main ping. The first-shutdown summary can be used in conjunction with the main summary by taking the union and deduplicating on the <code>document_id</code>.</p>
<h4><a class="header" href="#accessing-the-data-4" id="accessing-the-data-4">Accessing the Data</a></h4>
<p>The data can be accessed as <code>first_shutdown_summary</code>.</p>
<p>The data is backfilled to 2017-09-22, the date of its first nightly appearance. This data should be available to all releases on and after Firefox 57.</p>
<h2><a class="header" href="#client_count_daily" id="client_count_daily"><code>client_count_daily</code></a></h2>
<p>The <code>client_count_daily</code> dataset is useful for estimating user counts over a few
<a href="https://github.com/mozilla/telemetry-airflow/blob/adfce4a30895faa607ccf586b292b61ad68d8f75/jobs/client_count_daily_view.sh">pre-defined dimensions</a>.</p>
<p>The <code>client_count_daily</code> dataset is similar to the deprecated
<a href="concepts//datasets/batch_view/client_count/reference.html"><code>client_count</code> dataset</a>
except that is aggregated by submission date and not activity date.</p>
<h4><a class="header" href="#content-1" id="content-1">Content</a></h4>
<p>This dataset includes columns for a dozen factors and an HLL variable.
The <code>hll</code> column contains a
<a href="https://en.wikipedia.org/wiki/HyperLogLog">HyperLogLog</a>
variable, which is an approximation to the exact count.
The factor columns include <strong>submission</strong> date and the dimensions listed
<a href="https://github.com/mozilla/telemetry-airflow/blob/adfce4a30895faa607ccf586b292b61ad68d8f75/jobs/client_count_daily_view.sh">here</a>.
Each row represents one combinations of the factor columns.</p>
<h4><a class="header" href="#background-and-caveats-3" id="background-and-caveats-3">Background and Caveats</a></h4>
<p>It's important to understand that the <code>hll</code> column is <strong>not a standard count</strong>.
The <code>hll</code> variable avoids double-counting users when aggregating over multiple days.
The HyperLogLog variable is a far more efficient way to count distinct elements of a set,
but comes with some complexity.
To find the cardinality of an HLL use <code>cardinality(cast(hll AS HLL))</code>.
To find the union of two HLL's over different dates, use <code>merge(cast(hll AS HLL))</code>.
The <a href="https://sql.telemetry.mozilla.org/queries/81/source#129">Firefox ER Reporting Query</a>
is a good example to review.
Finally, Roberto has a relevant write-up
<a href="https://robertovitillo.com/2016/04/12/measuring-product-engagment-at-scale/">here</a>.</p>
<h4><a class="header" href="#accessing-the-data-5" id="accessing-the-data-5">Accessing the Data</a></h4>
<p>The data is available in Re:dash.
Take a look at this
<a href="https://sql.telemetry.mozilla.org/queries/81/source#129">example query</a>.</p>
<p>I don't recommend accessing this data from ATMO.</p>
<h4><a class="header" href="#further-reading-1" id="further-reading-1">Further Reading</a></h4>
<h1><a class="header" href="#new-profile-derived-datasets" id="new-profile-derived-datasets">New-Profile Derived Datasets</a></h1>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/new-profile-ping.html">new-profile ping</a> is sent from Firefox Desktop on the first session of a newly
created profile and contains the initial information about the user environment.</p>
<p>This data is available in the <code>telemetry_new_profile_parquet</code> dataset.</p>
<p>The <code>telemetry_new_profile_parquet</code> table is the most direct representation of a new-profile ping.</p>
<h4><a class="header" href="#contents-3" id="contents-3">Contents</a></h4>
<p>The table contains one row for each ping. Each column represents one field from the new-profile ping payload, though only a subset of all fields are included.</p>
<h4><a class="header" href="#accessing-the-data-6" id="accessing-the-data-6">Accessing the Data</a></h4>
<p>The data is stored as a parquet table in S3 at the following address.</p>
<pre><code>s3://net-mozaws-prod-us-west-2-pipeline-data/telemetry-new-profile-parquet/v2/
</code></pre>
<p>The <code>telemetry_new_profile_parquet</code> is accessible through re:dash.
Here's an <a href="https://sql.telemetry.mozilla.org/queries/5888#table">example query</a>.</p>
<h4><a class="header" href="#further-reading-2" id="further-reading-2">Further Reading</a></h4>
<p>This dataset is generated automatically using direct to parquet. The configuration responsible for generating this dataset was introduced in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1360256">bug 1360256</a>.</p>
<h1><a class="header" href="#update-derived-dataset" id="update-derived-dataset">Update Derived Dataset</a></h1>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/update-ping.html">update ping</a>
is sent from Firefox Desktop when a browser update is ready to be applied and after it was correctly applied.
It contains the build information and the update blob information, in addition to some information about the
user environment.
The <code>telemetry_update_parquet</code> table is the most direct representation of an update ping.</p>
<h4><a class="header" href="#contents-4" id="contents-4">Contents</a></h4>
<p>The table contains one row for each ping. Each column represents one field from the update ping payload, though only a subset of all fields are included.</p>
<h4><a class="header" href="#accessing-the-data-7" id="accessing-the-data-7">Accessing the Data</a></h4>
<p>The data is stored as a parquet table in S3 at the following address.</p>
<pre><code>s3://net-mozaws-prod-us-west-2-pipeline-data/telemetry-update-parquet/v1/
</code></pre>
<p>The <code>telemetry_update_parquet</code> is accessible through re:dash.
Here's an <a href="https://sql.telemetry.mozilla.org/queries/31267#table">example query</a>.</p>
<h4><a class="header" href="#further-reading-3" id="further-reading-3">Further Reading</a></h4>
<p>This dataset is generated automatically using direct to parquet. The configuration responsible for generating this dataset was introduced in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1384861">bug 1384861</a>.</p>
<h1><a class="header" href="#other-datasets" id="other-datasets">Other Datasets</a></h1>
<p>Public crash statistics for Firefox are available through the Data Platform in a <code>socorro_crash</code> dataset.
The crash data in <a href="https://wiki.mozilla.org/Socorro">Socorro</a> is sanitized and made available to ATMO and STMO.
A nightly import job converts batches of JSON documents into a columnar format using the associated JSON Schema. </p>
<h3><a class="header" href="#contents-5" id="contents-5">Contents</a></h3>
<h4><a class="header" href="#accessing-the-data-8" id="accessing-the-data-8">Accessing the Data</a></h4>
<p>The dataset is available in parquet at <code>s3://telemetry-parquet/socorro_crash/v2</code>.
It is also indexed with Athena and Presto with the table name <code>socorro_crash</code>.</p>
<h1><a class="header" href="#obsolete-datasets" id="obsolete-datasets">Obsolete Datasets</a></h1>
<h2><a class="header" href="#heavy_users" id="heavy_users"><code>heavy_users</code></a></h2>
<p>The <code>heavy_users</code> table provides information about whether a given <code>client_id</code> is
considered a &quot;heavy user&quot; on each day (using submission date).</p>
<h4><a class="header" href="#contents-6" id="contents-6">Contents</a></h4>
<p>The <code>heavy_users</code> table contains one row per client-day, where day is
<code>submission_date</code>. A client has a row for a specific <code>submission_date</code> if
they were active at all in the 28 day window ending on that <code>submission_date</code>.</p>
<p>A user is a &quot;heavy user&quot; as of day N if, for the 28 day period ending
on day N, the sum of their <code>active_ticks</code> is in the 90th percentile (or
above) of all clients during that period. For more analysis on this,
and a discussion of new profiles, see
<a href="https://metrics.mozilla.com/protected/sguha/heavy/heavycutoffs5.html">this link</a>.</p>
<h4><a class="header" href="#background-and-caveats-4" id="background-and-caveats-4">Background and Caveats</a></h4>
<ol>
<li>Data starts at 20170801. There is technically data in the table before
this, but the <code>heavy_user</code> column is <code>NULL</code> for those dates because it
needed to bootstrap the first 28 day window.</li>
<li>Because it is top the 10% of clients for each 28 day period, more
than 10% of clients active on a given <code>submission_date</code> will be
considered heavy users. If you join with another data source
(<code>main_summary</code>, for example), you may see a larger proportion of heavy
users than expected.</li>
<li>Each day has a separate, but related, set of heavy users. Initial
investigations show that approximately 97.5% of heavy users as of a
certain day are still considered heavy users as of the next day.</li>
<li>There is no &quot;fixing&quot; or weighting of new profiles - days before the
profile was created are counted as zero <code>active_ticks</code>. Analyses may
need to use the included <code>profile_creation_date</code> field to take this
into account.</li>
</ol>
<h4><a class="header" href="#accessing-the-data-9" id="accessing-the-data-9">Accessing the Data</a></h4>
<p>The data is available both via <code>sql.t.m.o</code> and Spark.</p>
<p>In Spark:</p>
<pre><code class="language-python">spark.read.parquet(&quot;s3://telemetry-parquet/heavy_users/v1&quot;)
</code></pre>
<p>In SQL:</p>
<pre><code class="language-sql">SELECT * FROM heavy_users LIMIT 3
</code></pre>
<h4><a class="header" href="#further-reading-4" id="further-reading-4">Further Reading</a></h4>
<p>The code responsible for generating this dataset is
<a href="https://github.com/mozilla/telemetry-batch-view/blob/master/GRAVEYARD.md#heavy-users">here</a></p>
<h2><a class="header" href="#retention" id="retention"><code>retention</code></a></h2>
<p>The <code>retention</code> table provides client counts relevant to client retention at a
1-day granularity. The project is tracked in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1381840">Bug 1381840</a></p>
<h3><a class="header" href="#contents-7" id="contents-7">Contents</a></h3>
<p>The <code>retention</code> table contains a set of attribute columns used to specify a
cohort of users and a set of metric columns to describe cohort activity. Each
row contains a permutation of attributes, an approximate set of clients in a
cohort, and the aggregate engagement metrics.</p>
<p>This table uses the HyperLogLog (HLL) sketch to create an approximate set of
clients in a cohort. HLL allows counting across overlapping cohorts in a single
pass while avoiding the problem of double counting. This data-structure has the
benefit of being compact and performant in the context of retention analysis,
at the expense of precision. For example, calculating a 7-day retention period
can be obtained by aggregating over a week of retention data using the union
operation. With SQL primitive, this requires a recalculation of COUNT DISTINCT
over <code>client_id</code>'s in the 7-day window.</p>
<h4><a class="header" href="#background-and-caveats-5" id="background-and-caveats-5">Background and Caveats</a></h4>
<ol>
<li>The data starts at 2017-03-06, the <a href="https://wiki.mozilla.org/RapidRelease/Calendar">merge date where Nightly started to
track Firefox 55 in Mozilla-Central</a>. However, there was
not a consistent view into the behavior of first session profiles until the
<a href="concepts//datasets/batch_view/new_profile/reference.html"><code>new_profile</code> ping</a>. This means much of the data is inaccurate
before 2017-06-26.</li>
<li>This dataset uses 4 day reporting latency to aggregate at least 99% of the
data in a given submission date. This figure is derived from the
<a href="https://sql.telemetry.mozilla.org/dashboard/telemetry-health">telemetry-health measurements on submission latency</a>, with
the discussion in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1407410">Bug 1407410</a>. This latency metric was reduced
Firefox 55 with the introduction of the shutdown ping-sender mechanism.</li>
<li>Caution should be taken before adding new columns. Additional attribute
columns will grow the number of rows exponentially.</li>
<li>The number of HLL bits chosen for this dataset is 13. This means the default
size of the HLL object is 2^13 bits or 1KiB. This maintains about a 1% error
on average. See <a href="https://github.com/twitter/algebird/blob/develop/algebird-core/src/main/scala/com/twitter/algebird/HyperLogLog.scala#L230-L255">this table from Algebird's HLL implementation</a> for
more details.</li>
</ol>
<h4><a class="header" href="#accessing-the-data-10" id="accessing-the-data-10">Accessing the Data</a></h4>
<p>The data is primarily available through <a href="https://sql.telemetry.mozilla.org/">Re:dash on STMO</a> via
the Presto source. This service has been configured to use predefined HLL
functions.</p>
<p>The column should first be cast to the HLL type. The scalar
<code>cardinality(&lt;hll_column&gt;)</code> function will approximate the number of unique
items per HLL object. The aggregate <code>merge(&lt;hll_column&gt;)</code> function will perform
the set union between all objects in a column.</p>
<p>Example: Cast the count column into the appropriate type.</p>
<pre><code class="language-sql">SELECT cast(hll as HLL) as n_profiles_hll FROM retention
</code></pre>
<p>Count the number of clients seen over all attribute combinations.</p>
<pre><code class="language-sql">SELECT cardinality(cast(hll as HLL)) FROM retention
</code></pre>
<p>Group-by and aggregate client counts over different release channels.</p>
<pre><code class="language-sql">SELECT channel, cardinality(merge(cast(hll AS HLL))
FROM retention
GROUP BY channel
</code></pre>
<p>The HyperLogLog library wrappers are available for use outside of the
configured STMO environment, <a href="https://github.com/mozilla/spark-hyperloglog"><code>spark-hyperloglog</code></a> and
<a href="https://github.com/vitillo/presto-hyperloglog"><code>presto-hyperloglog</code></a>.</p>
<p>Also see the <a href="concepts//datasets/obsolete/client_count_daily/reference.html"><code>client_count_daily</code> dataset</a>.</p>
<h2><a class="header" href="#churn" id="churn"><code>churn</code></a></h2>
<p>The churn dataset tracks the 7-day churn rate of telemetry profiles. This
dataset is generally used for analyzing cohort churn across segments and time.</p>
<h4><a class="header" href="#content-2" id="content-2">Content</a></h4>
<p>Churn is the rate of attrition defined by <code>(clients seen in week N)/(clients seen in week 0)</code>
for groups of clients with some shared attributes. A group of clients with
shared attributes is called a <em>cohort</em>. The cohorts in this dataset are created
every week and can be tracked over time using the <code>acquisition_date</code> and the
weeks since acquisition or <code>current_week</code>.</p>
<p>The following example demonstrates the current logic for generating this
dataset. Each column represents the days since some arbitrary starting date.</p>
<table><thead><tr><th>client</th><th>00</th><th>01</th><th>02</th><th>03</th><th>04</th><th>05</th><th>06</th><th>07</th><th>08</th><th>09</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th></tr></thead><tbody>
<tr><td>A</td><td>X</td><td></td><td></td><td></td><td></td><td></td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td>B</td><td></td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td>C</td><td>X</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>X</td></tr>
</tbody></table>
<p>All three clients are part of the same cohort. Client A is retained for weeks 0
and 1 since there is activity in both periods. A client only needs to show up
once in the period to be counted as retained. Client B is acquired in week 0 and
is active frequently but does not appear in following weeks. Client B is
considered churned on week 1. However, a client that is churned can become
retained again. Client C is considered churned on week 1 but retained on week 2.</p>
<p>The following table summarizes the above daily activity into the following view
where every column represents the current week since acquisition date..</p>
<table><thead><tr><th>client</th><th>0</th><th>1</th><th>2</th></tr></thead><tbody>
<tr><td>A</td><td>X</td><td>X</td><td></td></tr>
<tr><td>B</td><td>X</td><td></td><td></td></tr>
<tr><td>C</td><td>X</td><td></td><td>X</td></tr>
</tbody></table>
<p>The clients are then grouped into cohorts by attributes. An attribute describes
a property about the cohort such as the country of origin or the binary
distribution channel. Each group also contains descriptive aggregates of
engagement. Each metric describes the activity of a cohort such as size and
overall usage at a given time instance.</p>
<h4><a class="header" href="#background-and-caveats-6" id="background-and-caveats-6">Background and Caveats</a></h4>
<p>The original concept for churn is captured in <a href="https://mana.mozilla.org/wiki/display/FIREFOX/Project%3A+Firefox+Churn+v1.0">this Mana
page</a>.
The original derived data-set was created in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1198537">bug
1198537</a>.  The first
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1389230">major revision (<code>v2</code>)</a> of
this data-set added attribution, search, and uri counts.  The second <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1389231">major
revision (<code>v3</code>)</a> included
additional clients through the <code>new-profile</code> ping and adjusted the collection
window from 10 to 5 days.</p>
<ul>
<li>Each row in this dataset describes a unique segment of users
<ul>
<li>The number of rows is exponential with the number of dimensions</li>
<li>New fields should be added sparing to account for data-set size</li>
</ul>
</li>
<li>The dataset lags by 10 days in order account for submission latency
<ul>
<li>This value was determined to be time for 99% of main pings to arrive at the
server. With the shutdown-ping sender, this has been reduced to 4 days.
However, <code>churn_v3</code> still tracks releases older than Firefox 55.</li>
</ul>
</li>
<li>The start of the period is fixed to Sundays. Once it has been aggregated, the
period cannot be shifted due to the way clients are counted.
<ul>
<li>A supplementary 1-day <code>retention</code> dataset using HyperLogLog for client
counts is available for counting over arbitrary retention periods and date
offsets. Additionally, calculating churn or retention over specific cohorts
is tractable in STMO with <code>main_summary</code> or <code>clients_daily</code> datasets.</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#accessing-the-data-11" id="accessing-the-data-11">Accessing the Data</a></h4>
<p><code>churn</code> is available in Re:dash under Athena and Presto. The data is also
available in parquet for consumption by columnar data engines at
<code>s3://telemetry-parquet/churn/v3</code>.</p>
<h2><a class="header" href="#error_aggregates" id="error_aggregates"><code>error_aggregates</code></a></h2>
<p>The <code>error_aggregates_v2</code> table represents counts of errors counted from main and crash
pings, aggregated every 5 minutes. It is the dataset backing the main <a href="https://data-missioncontrol.dev.mozaws.net/">mission
control</a> view, but may also be queried
independently.</p>
<h4><a class="header" href="#contents-8" id="contents-8">Contents</a></h4>
<p>The <code>error_aggregates_v2</code> table contains counts of various error measures (for
example: crashes, &quot;the slow script dialog showing&quot;), aggregated across each
unique set of dimensions (for example: channel, operating system) every 5
minutes. You can get an aggregated count for any particular set of dimensions
by summing using SQL.</p>
<h5><a class="header" href="#experiment-unpacking" id="experiment-unpacking">Experiment unpacking</a></h5>
<p>It's important to note that when this dataset is written, pings from clients participating in an experiment 
are aggregated on the <code>experiment_id</code> and <code>experiment_branch</code> dimensions corresponding to what experiment and branch 
they are participating in. However, they are also aggregated with the rest of the population where the values of 
these dimensions are null.
Therefore care must be taken when writing aggregating queries over the whole population - in these cases one needs to
filter for <code>experiment_id is null</code> and <code>experiment_branch is null</code> in order to not double-count pings from experiments.</p>
<h4><a class="header" href="#accessing-the-data-12" id="accessing-the-data-12">Accessing the data</a></h4>
<p>You can access the data via re:dash. Choose <code>Athena</code> and then select the
<code>telemetry.error_aggregates_v2</code> table.</p>
<h4><a class="header" href="#further-reading-5" id="further-reading-5">Further Reading</a></h4>
<p>The code responsible for generating this dataset is <a href="https://github.com/mozilla/telemetry-streaming/blob/master/src/main/scala/com/mozilla/telemetry/streaming/ErrorAggregator.scala">here</a>.</p>
<h1><a class="header" href="#appendix" id="appendix">Appendix</a></h1>
<h2><a class="header" href="#mobile-metrics" id="mobile-metrics">Mobile Metrics</a></h2>
<p>There are several tables owned by the mobile team documented
<a href="https://wiki.mozilla.org/Mobile/Metrics/Redash">here</a>:</p>
<ul>
<li><code>android_addons</code></li>
<li><code>mobile_clients</code></li>
</ul>
<h1><a class="header" href="#choosing-a-mobile-product-dataset" id="choosing-a-mobile-product-dataset">Choosing a Mobile Product Dataset</a></h1>
<h2><a class="header" href="#products-overview" id="products-overview">Products Overview</a></h2>
<p>Before doing an analysis, it is important to know which products you want to include.
Here is a quick overview of Mozilla's mobile products.</p>
<table><thead><tr><th>Product Name</th><th>App Name</th><th>OS</th><th>Notes</th></tr></thead><tbody>
<tr><td>Firefox Android</td><td><code>Fennec</code></td><td>Android</td><td></td></tr>
<tr><td>Firefox iOS</td><td><code>Fennec</code></td><td>iOS</td><td></td></tr>
<tr><td>Focus Android</td><td><code>Focus</code></td><td>Android</td><td>Privacy browser</td></tr>
<tr><td>Focus iOS</td><td><code>Focus</code></td><td>iOS</td><td>Privacy browser</td></tr>
<tr><td>Klar</td><td><code>Klar</code></td><td>Android</td><td>German Focus release</td></tr>
<tr><td>Firefox for Fire TV</td><td><code>FirefoxForFireTV</code></td><td>Android</td><td></td></tr>
<tr><td>Firefox for Echo Show</td><td><code>FirefoxConnect</code></td><td>Android</td><td></td></tr>
<tr><td>Firefox Lite</td><td><code>Zerda</code></td><td>Android</td><td>Formerly Rocket (See below)</td></tr>
<tr><td>Fenix (Firefox Preview)</td><td><code>org_mozilla_fenix</code></td><td>Android</td><td>Uses Glean (see below)</td></tr>
</tbody></table>
<p>Firefox Lite was formerly known as Rocket.
It is only available in certain countries in Asia Pacific - for more
information on Firefox Lite data please see the <a href="https://github.com/mozilla-tw/FirefoxLite/blob/master/docs/telemetry.md">telemetry documentation</a>.</p>
<p>Focus is our privacy focused mobile browser which blocks trackers by default
and does not store a browsing history.</p>
<p>Klar is the release name for Focus in Germany.</p>
<p>For more information on how telemetry is sent for iOS apps,
see the <a href="https://github.com/mozilla-mobile/telemetry-ios">telemetry documentation</a>.</p>
<p>Some telemetry is also sent by FirefoxReality and some non-Mozilla forks of our
browsers.
It is best to filter on App Name to ensure you are looking at only the app you
are trying to analyze data for.</p>
<h2><a class="header" href="#raw-pings-1" id="raw-pings-1">Raw Pings</a></h2>
<p>Mobile data is structured differently than desktop.
Instead of sending a <code>main</code> ping, mobile has two key types of pings - a <code>core</code>
ping and an <code>events</code> ping.
The core ping is sent once per session and contains a much smaller set of
metrics than the main ping, due to network and data size constraints.
All mobile apps send the core ping.
For more information on the core ping, there is telemetry documentation <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/core-ping.html">here</a>.</p>
<p>Event pings are not sent for all products.
Event pings are sent by Focus Android, Focus iOS, Klar, Firefox for FireTV,
Firefox for Echo Show and Firefox Lite.
Event pings are sent more often than core pings, at most once per 10 minute interval.
If the ping records 10,000 events it is sent immediately, unless it is within
10 minutes of the last event ping sent, in which case some data may be lost.
For more information on the event ping, there is telemetry documentation <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/event-ping.html">here</a>.</p>
<p>Fennec (Firefox Android) does not send event pings, but instead has a
<code>saved_session</code> ping which has the same format as <code>main</code> pings, but is only
available for pre-release users and select few release users who have opted in
to telemetry collection.
Data from this must be treated with caution as it comes from a biased
population and should not be used to make conclusions about Fennec users
as a whole.</p>
<p>For more information on the implementation of the event pings and to view event
descriptions for <a href="https://github.com/mozilla-mobile/focus-android/blob/master/docs/Telemetry.md">Focus</a>, <a href="https://github.com/mozilla-mobile/firefox-tv/blob/master/docs/telemetry.md">Firefox for FireTV</a> or <a href="https://github.com/mozilla-mobile/firefox-echo-show/blob/master/docs/telemetry.md">Firefox for Echo Show</a>,
please see the linked documentation.</p>
<h3><a class="header" href="#core-ping-derived-datasets" id="core-ping-derived-datasets">Core Ping Derived Datasets</a></h3>
<h4><a class="header" href="#telemetrycore" id="telemetrycore"><code>telemetry.core</code></a></h4>
<p>For most analyses of mobile data, use the <code>telemetry.core</code> table.
This table contains data for all the non-desktop Firefox applications which
send core pings.</p>
<p>Remember to filter on <code>app_name</code> and <code>os</code>, as Firefox iOS and Firefox Android
have the same <code>app_name</code>.
Best practice is to always filter on <code>app_name</code>, <code>os</code>, app version
(found as <code>metadata_app_version</code>) and release channel (which can be found as
under metadata as <code>metadata.normalized_channel</code>).</p>
<p>There are versioned tables for core ping storage, but the table without a version suffix is
the most up-to-date table and it is best to use this in your analysis.</p>
<p>The <code>seq</code> field indicates the order of the pings coming in. A record
containing <code>seq = 1</code> is the first ping we have received for that client id
and can be used as a proxy to identify new users.</p>
<h3><a class="header" href="#event-ping-derived-datasets" id="event-ping-derived-datasets">Event Ping Derived Datasets</a></h3>
<p>There are multiple event tables for mobile data. The two main event tables are
<code>telemetry.focus_event</code> and <code>telemetry.mobile_event</code>.
As the name suggests, one contains the event pings from Focus (iOS, Android
and Klar) the other contains event data for other apps.
Both tables have the same format and columns.</p>
<h4><a class="header" href="#telemetrymobile_events" id="telemetrymobile_events"><code>telemetry,mobile_events</code></a></h4>
<p>This table contains event data for Firefox for Fire TV, Firefox for Echo Show
and Firefox Lite. There is a metadata column containing a list of metrics.</p>
<p>Like when querying <code>telemetry.core</code>, there are multiple apps contained in each
table, so it is best practice to filter on at least <code>app_name</code> and <code>os</code>.
One thing to note is that there is no <code>app_version</code> field in these tables,
so in order to filter or join on a specific version you must know the
corresponding <code>metadata.app_build_id</code>(s) for that <code>app_version</code>.
This can be found by reaching out to the engineering team building the app.</p>
<p>Some other applications also send event data to this table, including Lockbox
and FirefoxReality.
For more information on the event data sent from these applications, see their
documentation.</p>
<h4><a class="header" href="#telemetryfocus_events" id="telemetryfocus_events"><code>telemetry.focus_events</code></a></h4>
<p>This table contains event data for Focus Android, Focus iOS and Klar.</p>
<p>Like when querying <code>telemetry.core</code>, there are multiple apps contained in each
table, so it is best practice to filter on at least <code>app_name</code> and <code>os</code>.
One thing to note is that there is no <code>app_version</code> field in these tables, so
in order to filter or join on a specific version you must know the corresponding
<code>app_build_id</code>(s) for that <code>app_version</code>.
This can be found by reaching out to the engineering team building the app.</p>
<p>Some other applications send data to this table, but it is preferred to use
this only for analysis of event data from Focus and its related apps.</p>
<h3><a class="header" href="#notes" id="notes">Notes</a></h3>
<p>Each app has its own set of release channels and each app implements them in
its own way.
Most have a <code>nightly</code>, <code>beta</code>, <code>release</code> and an <code>other</code> channel, used at
various stages of development.
Users sign up to test pre-released versions of the app.
In Focus Android, the <code>beta</code> channel uses the same APK in the Google Play Store
as the <code>release</code> channel, but beta users get access to this version earlier
than the release population.
Once the <code>release</code> version is published, Beta users will be on the same version
of the app as Release users and will be indistinguishable (without a query
going back and flagging them by <code>client_id</code>).
Beta releases have their <code>normalized_channel</code> tagged <code>release</code> and the only way
to filter to beta users is to check that they were on a higher version number
before the official release date.</p>
<p>There was an incident on Oct 25, 2018 where a chunk of <code>client_id</code>s on
Firefox Android were reset to the same <code>client_id</code>.
For more information see the blameless post-mortem document <a href="https://docs.google.com/document/d/1r1PDQnqhsrPkft0pB46v9uhXGxR_FzK4laKJLGttXdA">here</a> or
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1501329">bug 1501329</a>.
Because of this, some retention analyses spanning this time frame may be impacted.</p>
<h3><a class="header" href="#upcoming-changes" id="upcoming-changes">Upcoming Changes</a></h3>
<p>In the future, Android apps will use Glean - the new mobile telemetry SDK.
Plans are to integrate this new SDK starting with Project Fenix, then update
the other existing apps to Glean starting the second half of 2019.
Instead of <code>core</code> and <code>event</code> pings, Glean will send <code>baseline</code>, <code>metrics</code>
and <code>events</code> pings.
For more information on Glean visit the <a href="https://github.com/mozilla-mobile/android-components/tree/master/components/service/glean/#contact">Glean GitHub page</a>
or <code>#Glean</code> on Slack.</p>
<h2><a class="header" href="#introduction" id="introduction">Introduction</a></h2>
<p>STMO is shorthand for
<a href="https://sql.telemetry.mozilla.org"><code>sql.telemetry.mozilla.org</code></a>, an installation
of the excellent <a href="https://redash.io/">Re:dash</a> data analysis and dashboarding
tool that has been customized and configured for use with a number of the
Firefox organization's data sets. As the name and URL imply, effective use of
this tool requires familiarity with
<a href="https://en.wikipedia.org/wiki/SQL">SQL</a>, with which all of the
tool's data extraction and analysis are performed.</p>
<h2><a class="header" href="#concepts" id="concepts">Concepts</a></h2>
<p>There are three building block from which analyses in STMO are constructed:
queries, visualizations, and dashboards.</p>
<h4><a class="header" href="#queries" id="queries">Queries</a></h4>
<p>STMO's basic unit of analysis is the query. A query is a block of SQL code that
extracts and (optionally) transforms data from a single data source. Queries
can vary widely in complexity. Some queries are trivial one liners
(e.g. <code>SELECT some_field FROM tablename LIMIT 10</code>), while others are many pages long,
small programs in their own right.</p>
<p>The raw output from a query is tabular data, where each row is one set of
return values for the query's output columns. A query can be run manually or it
can be specified to have a refresh schedule, where it will execute
automatically after a specified interval of time.</p>
<h4><a class="header" href="#visualizations" id="visualizations">Visualizations</a></h4>
<p>Tabular data is great, but rarely is a grid of values the best way to make
sense of your data. Each query can be associated with multiple visualizations,
each visualization rendering the extracted data in some more useful
format. There are many visualization types, including charts (line, bar, area,
pie, etc.), counters, maps, pivot tables, and more. Each visualization type
provides a set of configuration parameters that allow you to specify how to map
from the raw query output to the desired visualization. Some visualization types
make demands of the query output; a map visualization requires each row to contain
a longitude value and a latitude value, for instance.</p>
<h4><a class="header" href="#dashboards" id="dashboards">Dashboards</a></h4>
<p>A dashboard is a collection of visualizations, combined into a single visual
presentation for convenient perusal. A dashboard is decoupled from any
particular queries. While it is possible to include multiple visualizations
from a single query in one dashboard, it is not required; users can add any
visualizations they can access to the dashboards they create.</p>
<h2><a class="header" href="#data-sources" id="data-sources">Data Sources</a></h2>
<p>SQL provides the ability to extract and manipulate the data, but you won't get
very far without having some familiarity with what data is actually available,
and how that data is structured. Each query in STMO is associated with exactly
one data source, and you have to know ahead of time which data source contains
the information that you need. One of the most commonly used data sources is
called <em>Telemetry (BigQuery)</em>, which contains most of the data that is
obtained from telemetry pings received from Firefox clients. <em>BigQuery</em>
refers to Google's <a href="https://cloud.google.com/bigquery/">BigQuery</a> data warehouse.</p>
<p>Other available data sources include <em>Crash DB</em>, <em>Tiles</em>, <em>Sync Stats</em>, <em>Push</em>,
<em>Test Pilot</em>, and even a <em>Re:dash metadata</em> which connects to STMO's
own Re:dash database. You can learn more about the available data sets and how
to find the one that's right for you on the <a href="tools/../concepts/choosing_a_dataset.html">Choosing a
dataset</a> page. If you have data set
questions, or would like to know if specific data is or can be made available
in STMO, please inquire in the <code>#datapipeline</code> or <code>#datatools</code> channels on
<code>irc.mozilla.org</code>; or in <code>#fx-metrics</code> on Slack.</p>
<h2><a class="header" href="#creating-an-example-dashboard" id="creating-an-example-dashboard">Creating an Example Dashboard</a></h2>
<p>The rest of this document will take you through the process of creating a
simple dashboard using STMO.</p>
<h4><a class="header" href="#creating-a-query" id="creating-a-query">Creating A Query</a></h4>
<p>We start by creating a query. Our first query will count the number of client
ids that we have coming from each country, for the top N countries. Clicking on
the 'New Query' button near the top left of the site will bring you to the
query editing page:</p>
<p><img src="tools/../assets/STMO_screenshots/new_query.png" alt="New Query Page" title="New Query page" /></p>
<p>For this (and most queries where we're counting distinct client IDs) we'll want
to use
<a href="tools/../datasets/bigquery/clients_last_seen/reference.html"><code>clients_last_seen</code></a>,
which is generated from Firefox telemetry pings.</p>
<ul>
<li>
<p>Search for the table in <code>Telemetry (BigQuery)</code></p>
<p>Click on the 'Data Source' drop-down and
select <code>Telemetry (BigQuery)</code>, then search for the table we want by typing
<code>clients_last_seen</code> into the &quot;Search schema...&quot; search box above the schema
browser interface to the left of the main query edit box. You should see that
there is, in fact, a <code>clients_last_seen</code> table (showing up as
<code>telemetry.clients_last_seen</code>), as well as versioned <code>clients_last_seen</code> data
sets (showing up as <code>telemetry.clients_last_seen_v&lt;VERSION&gt;</code>).</p>
</li>
<li>
<p>If the table you want is not found</p>
<p>Again, there are many different data sources connected to STMO, so if the
one you want is not in the Telemetry source, we should check other sources.
If you're having trouble finding the data you need, feel free to ask in
<code>#fx-metrics</code> on Slack</p>
</li>
<li>
<p>Introspect the available columns</p>
<p>Click on <code>telemetry.clients_last_seen</code> in the schema browser to expose
the columns that are available in the table. Three of the columns are of
interest to us for this query: <code>country</code>, <code>days_since_seen</code>, and
<code>submission_date</code>.</p>
</li>
</ul>
<p>So a query that extracts all of the unique country values and the MAU for one
day for each one, sorted from highest MAU to lowest MAU looks like this:</p>
<pre><code class="language-sql">SELECT
  country,
  COUNTIF(days_since_seen &lt; 28) AS mau
FROM
  telemetry.clients_last_seen
WHERE
  submission_date = '2019-04-01'
GROUP BY
  country
ORDER BY
  mau DESC
</code></pre>
<p>If you type that into the main query edit box and then click on the &quot;Execute&quot;
button, you should see a blue bar appear below the edit box containing the text
&quot;Executing query...&quot; followed by a timer indicating how long the query has been
running. After a reasonable (for some definition of &quot;reasonable&quot;, usually less
than a minute) amount of time the query should complete, resulting in a
table showing a MAU value for each country. Congratulations, you've
just created and run your first STMO query!</p>
<p>Now would be a good time to click on the large &quot;New Query&quot; text near the top of
the page; it should turn into an edit box, allowing you to rename the
query. For this exercise, you should use a unique prefix (such as your name)
for your query name, so it will be easy to find your query later; I used
<code>rmiller:Top Countries</code>.</p>
<h4><a class="header" href="#creating-a-visualization" id="creating-a-visualization">Creating A Visualization</a></h4>
<p>Now that the query is created, we'll want to provide a simple
visualization. The table with results from the first query execution should be
showing up underneath the query edit box. Next to the <code>TABLE</code> heading should be
another heading entitled <code>+NEW VISUALIZATION</code>.</p>
<p><img src="tools/../assets/STMO_screenshots/new_visualization.png" alt="New Visualization" title="New Visualization" /></p>
<p>Clicking on the <code>+NEW VISUALIZATION</code> link should bring you to the
&quot;Visualization Editor&quot; screen, where you can specify a visualization name (&quot;Top
Countries bar chart&quot;), a chart type (&quot;Bar&quot;), an x-axis column (<code>country</code>), and
a y-axis column (<code>mau</code>).:</p>
<p><img src="tools/../assets/STMO_screenshots/vis_editor.png" alt="Visualization Editor" title="Visualization Editor" /></p>
<p>After the <code>GENERAL</code> settings have been specified, we'll want to tweak a few
more settings on the <code>X AXIS</code> tab. You'll want to click on this tab and then
change the 'Scale' setting to 'Category', and un-check the 'Sort Values'
check-box to allow the query's sort order to take precedence:</p>
<p><img src="tools/../assets/STMO_screenshots/x_axis_editor.png" alt="Visualization X Axis" title="Visualization X Axis" /></p>
<h4><a class="header" href="#a-note-about-limits" id="a-note-about-limits">A Note About Limits</a></h4>
<p>Once you save the visualization settings and return to the query source page,
you should have a nice bar graph near the bottom of the page. You may notice,
however, that the graph has quite a long tail. Rather than seeing <em>all</em> of
the countries, it might be nicer to only see the top 20. We can do this by adding
a <code>LIMIT</code> clause to the end of our query:</p>
<pre><code class="language-sql">SELECT
  country,
  COUNTIF(days_since_seen &lt; 28) AS mau
FROM
  telemetry.clients_last_seen
WHERE
  submission_date = '2019-04-01'
GROUP BY
  country
ORDER BY
  mau DESC
LIMIT
  20
</code></pre>
<p>If you edit the query to add a limit clause and again hit the 'Execute' button,
you should get a new bar graph that only shows the 20 countries with the
highest number of unique clients. In this case, the full result set has
approximately 250 return values, and so limiting the result count improves
readability. In other cases, however, an unlimited query might return thousands
or even millions of rows. When those queries are run, readability is not the
only problem; queries that return millions of rows can tax the system, failing
to return the desired results, and negatively impacting the performance of all
of the other users of the system. Thus, a very important warning:</p>
<p><strong>ALL QUERIES SHOULD INCLUDE A &quot;LIMIT&quot; STATEMENT BY DEFAULT!</strong></p>
<p>You should be in the habit of adding a &quot;LIMIT 100&quot; clause to the end of all new
queries, to prevent your query from returning a gigantic result set that causes
UI and performance problems. You may learn that the total result set is small
enough that the limit is unnecessary, but unless you're certain that is the
case specifying an explicit LIMIT helps prevent unnecessary issues.</p>
<h4><a class="header" href="#query-parameters" id="query-parameters">Query Parameters</a></h4>
<p>We got our chart under control by adding a &quot;LIMIT 20&quot; clause at the end. But
what if we only want the top 10? Or maybe sometimes we want to see the top 30?
We don't always know how many results our users will want. Is it possible to
allow users to specify how many results they want to see?</p>
<p>As you've probably guessed, I wouldn't be asking that question if the answer
wasn't &quot;yes&quot;. STMO allows queries to accept user arguments by the use of double
curly-braces around a variable name. So our query now becomes the following:</p>
<pre><code class="language-sql">SELECT
  country,
  COUNTIF(days_since_seen &lt; 28) AS mau
FROM
  telemetry.clients_last_seen
WHERE
  submission_date = '2019-04-01'
GROUP BY
  country
ORDER BY
  mau DESC
LIMIT
  {{country_count}}
</code></pre>
<p>Once you replace the hard coded limit value with <code>{{country_count}}</code> you should
see an input field show up directly above the bar chart. If you enter a numeric
value into this input box and click on 'Execute' the query will run with the
specified limit. Clicking on the 'Save' button will then save the query, using
the entered parameter value as the default.</p>
<h4><a class="header" href="#creating-a-dashboard" id="creating-a-dashboard">Creating A Dashboard</a></h4>
<p>Now we can create a dashboard to display our visualization. Do this by clicking
on the 'Dashboards' drop-down near the top left of the page, and then clicking
the 'New Dashboard' option. Choose a name for your dashboard, and you will be
brought to a mostly empty page. Clicking on the '...' button near the top right
of the page will give you the option to 'Add Widget'. This displays the
following dialog:</p>
<p><img src="tools/../assets/STMO_screenshots/add_widget.png" alt="Add Widget" title="Add Widget" /></p>
<p>The &quot;Search a query by name&quot; field is where you can enter in the unique prefix
used in your query name to find the query you created. This will not yet work,
however, because your query isn't published. Publishing a query makes it show
up in searches and on summary pages. Since this is only an exercise, we won't
want to leave our query published, but it must be published briefly in order to
add it to our dashboard. You can publish your query by returning to the query
source page and clicking the &quot;Publish&quot; button near the top right of the screen.</p>
<p>Once your query is published, it should show up in the search results when you
type your unique prefix into the &quot;Search a query by name&quot; field on the &quot;Add
Widget&quot; dialog. When you select your query, a new &quot;Choose Visualization&quot;
drop-down will appear, allowing you to choose which of the query's
visualizations to use. Choose the bar chart you created and then click on the
&quot;Add to Dashboard&quot; button. Voila! Now your dashboard should have a bar chart,
and you should be able to edit the <code>country_count</code> value and click the refresh
button to change the number of countries that show up on the chart.</p>
<h4><a class="header" href="#completing-the-dashboard" id="completing-the-dashboard">Completing the Dashboard</a></h4>
<p>A dashboard with just one graph is a bit sad, so let's flesh it out by adding a
handful of additional widgets. We're going to create three more queries, each
with a very similar bar chart. The text of the queries will be provided here,
but creating the queries and the visualizations and wiring them up to the
dashboard will be left as an exercise to the user. The queries are as follows:</p>
<ul>
<li>Top OSes (recommended <code>os_count</code> value == 6)</li>
</ul>
<pre><code class="language-sql">SELECT
  os,
  COUNTIF(days_since_seen &lt; 28) AS mau
FROM
  telemetry.clients_last_seen
WHERE
  submission_date = '2019-04-01'
GROUP BY
  os
ORDER BY
  mau DESC
LIMIT
  {{os_count}}
</code></pre>
<ul>
<li>Channel Counts</li>
</ul>
<pre><code class="language-sql">SELECT
  normalized_channel AS channel,
  COUNTIF(days_since_seen &lt; 28) AS mau
FROM
  telemetry.clients_last_seen
WHERE
  submission_date = '2019-04-01'
GROUP BY
  channel
ORDER BY
  mau DESC
</code></pre>
<ul>
<li>App Version Counts (recommended <code>app_version_count value</code> == 20)</li>
</ul>
<pre><code class="language-sql">SELECT
  app_name,
  app_version,
  COUNTIF(days_since_seen &lt; 28) AS mau
FROM
  telemetry.clients_last_seen
WHERE
  submission_date = '2019-04-01'
GROUP BY
  app_name,
  app_version
ORDER BY
  mau DESC
LIMIT
  {{app_version_count}}
</code></pre>
<p>Creating bar charts for these queries and adding them to the original dashboard
can result in a dashboard resembling this:</p>
<p><img src="tools/../assets/STMO_screenshots/finished_dashboard.png" alt="Completed Dashboard" title="Completed Dashboard" /></p>
<p>Some final notes to help you create your dashboards:</p>
<ul>
<li>
<p>Don't forget that you'll need to publish each of your queries before you can
add its visualizations to your dashboard.</p>
</li>
<li>
<p>Similarly, it's a good idea to un-publish any test queries after you've used
them in a dashboard so as not to permanently pollute everyone's search results
with your tests and experiments. Queries that are the result of actual
work-related analysis should usually remain published, so others can see and
learn from them.</p>
</li>
<li>
<p>The 'Firefox' label on the 'App Version counts' graph is related to the use
of the 'Group by' visualization setting. I encourage you to experiment with
the use of 'Group by' in your graphs to learn more about how this can be
used.</p>
</li>
<li>
<p>This tutorial has only scratched the surface of the wide variety of very
sophisticated visualizations supported by STMO. You can see a great many much
more sophisticated queries and dashboards by browsing around and exploring
the work that has been published by others.</p>
</li>
<li>
<p>The <a href="https://redash.io/help/">Re:dash help center</a> is useful for further deep
diving into Re:dash and all of its capabilities.</p>
</li>
</ul>
<h4><a class="header" href="#prototyping-queries" id="prototyping-queries">Prototyping Queries</a></h4>
<p>Sometimes you want to start working on your query before the data is available.
You can do this with most of the data sources by selecting a static test data
set, then working with it as usual. You can also use this method to explore
how a given SQL backend behaves.</p>
<p>Note that <code>UNION ALL</code> will retain duplicate rows while <code>UNION</code> will discard them.</p>
<p>Here are a couple of examples:</p>
<p><strong>Simple three-column test dataset</strong></p>
<pre><code class="language-sql">WITH test AS (
 SELECT 1 AS client_id, 'foo' AS v1, 'bar' AS v2 UNION ALL
 SELECT 2 AS client_id, 'bla' AS v1, 'baz' AS v2 UNION ALL
 SELECT 3 AS client_id, 'bla' AS v1, 'bar' AS v2 UNION ALL
 SELECT 2 AS client_id, 'bla' AS v1, 'baz' AS v2 UNION ALL
 SELECT 3 AS client_id, 'bla' AS v1, 'bar' AS v2
)

SELECT * FROM test
</code></pre>
<p><strong>Convert a semantic version string to a sortable array field</strong></p>
<pre><code class="language-sql">WITH foo AS (
 SELECT '1.0.1' AS v UNION
 SELECT '1.10.3' AS v UNION
 SELECT '1.0.2' AS v UNION
 SELECT '1.1' AS v UNION
 -- Doesn't work with these type of strings due to casting
 -- SELECT '1.3a1' AS v UNION
 SELECT '1.2.1' AS v
)

SELECT cast(split(v, '.') AS array&lt;bigint&gt;) FROM foo ORDER BY 1
</code></pre>
<p><strong>How do boolean fields get parsed from strings?</strong></p>
<pre><code class="language-sql">WITH bar AS (
 SELECT '1' AS b UNION
 SELECT '0' UNION
 SELECT 't' UNION
 SELECT 'f' UNION
 SELECT 'true' UNION
 SELECT 'false' UNION
 SELECT 'turkey'
)
SELECT b, try(cast(b AS boolean)) from bar
</code></pre>
<h1><a class="header" href="#analysis-gotchas" id="analysis-gotchas">Analysis Gotchas</a></h1>
<p>When performing analysis on any data there are some mistakes that are easy to
make and details that are easy to overlook.
Do you know exactly what question you hope to answer?
Is your sample representative of your population?
Is your result &quot;real&quot;? How precisely can you state your conclusion?</p>
<p>This document is not about those traps.
Instead, it is about quirks and pitfalls specific to <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/index.html">Telemetry</a>.</p>
<h3><a class="header" href="#notable-historic-events" id="notable-historic-events">Notable historic events</a></h3>
<p>When looking at trends, it is helpful to be aware of events from the past
that might impact comparisons with history. Here are a few to keep in mind:</p>
<ul>
<li><strong>October 29 2019</strong> - Glean SDK Timing Distribution(s) are reporting buckets
1 nanosecond apart. This is due to a potential rounding bug in Glean SDK
versions less than <code>19.0.0</code>. See <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1591938">Bug 1591938</a>.</li>
<li><strong>October 23 2019</strong> - <a href="https://docs.google.com/document/d/1gQF-iU3E21SG985Cl2Ius4LoRXduUrNa5In9hafLIqs/edit">Hot-fix shipped through add-ons</a> that
reset the Telemetry endpoint preference back to the default for a large number of users.</li>
<li><strong>September 1 - October 18 2019</strong> - BigQuery Ping tables are
<a href="https://github.com/mozilla-services/cloudops-infra/pull/1491">missing the <code>X-PingSender-Version</code> header information</a>.
This data is available before and after this time period.</li>
<li><strong>May 4 - May 11 2019</strong> - <a href="https://blog.mozilla.org/blog/2019/05/09/what-we-do-when-things-go-wrong/">Telemetry source data deleted</a>.
No source data is available for this period and derived tables may have
missing days or imputed values.
Derived tables that depend on multiple days may have have affected dates
beyond the deletion region.</li>
<li><strong>January 31 2019</strong> - <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1474285">Profile-per-install</a> landed in <code>mozilla-central</code>
and affects how new profiles are created.
See <a href="https://github.com/mozilla/bigquery-etl/issues/212">discussion in <code>bigquery-etl#212</code></a>.</li>
<li><strong>October 25 2018</strong> - many <code>client_id</code>s on Firefox Android were reset to the
same <code>client_id</code>.
For more information see the blameless post-mortem document <a href="https://docs.google.com/document/d/1r1PDQnqhsrPkft0pB46v9uhXGxR_FzK4laKJLGttXdA">here</a>
or <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1501329">Bug 1501329</a>.</li>
<li><strong>November 2017</strong> - Quantum Launch. There was a surge in new profiles and usage.</li>
<li><strong>June 1 and 5, 2016</strong> - <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1482509">Main Summary <code>v4</code> data is missing</a>
for these two days.</li>
<li><strong>March 2016</strong> - Unified Telemetry launched.</li>
</ul>
<h3><a class="header" href="#pseudo-replication" id="pseudo-replication">Pseudo-replication</a></h3>
<p>Telemetry data is a collection of pings.
A single main-ping represents a single subsession.
Some clients have more subsessions than others.</p>
<p>So when you say <a href="https://mzl.la/2q75dbF">&quot;63% of beta 53 has Firefox set as its default browser&quot;</a>,
make sure you specify it is 63% of <em>pings</em>, since it is only around 46% of clients.
(Apparently users with Firefox Beta 53 set as their default browser submit
more main-pings than users who don't).</p>
<h3><a class="header" href="#profiles-vs-users" id="profiles-vs-users">Profiles vs Users</a></h3>
<p>In the section above you'll notice I said &quot;clients&quot; not &quot;users.&quot;
That is because of all the things we're able to count, users isn't one of them.</p>
<p>Users can have multiple Firefox profiles running on the same computer at
the same time (like developers).</p>
<p>Users can have the same Firefox profile running on several computers on
different days of the week (also developers).</p>
<p>The only things we can count are pings and clients.
Clients we can count because we send a <code>client_id</code> with each ping that uniquely
identifies the profile from which it came.
This is generally close enough to our idea of &quot;user&quot; that we can get away with
counting profiles and calling them users, but you may run into some instances
where the distinction matters.</p>
<p>When in doubt, be precise. You're counting <em>clients</em>.</p>
<p><a href="concepts/./profile/index.html">This article</a> contains a more thorough treatment of
the concept of &quot;profiles&quot;.</p>
<h3><a class="header" href="#opt-in-vs-opt-out" id="opt-in-vs-opt-out">Opt-in vs Opt-out</a></h3>
<p>We don't collect the same information from everyone.</p>
<p>Every profile that doesn't have Telemetry disabled sends us &quot;opt-out&quot; Telemetry.
This includes:</p>
<ul>
<li>Nearly everything in the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/environment.html">Environment</a></li>
<li>Some very specific <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/histograms.html">Histograms</a>, <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/scalars.html">Scalars</a>, and <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/events.html">Events</a> that are marked
<code>&quot;releaseChannelCollection&quot;: &quot;opt-out&quot;</code></li>
</ul>
<p>Most probes are &quot;opt-in&quot;: we do not get information from them unless the user
opts into sending us this information.
Users can opt-in in two ways:</p>
<ol>
<li>Using Firefox's Options UI to tick the box that gives us permission</li>
<li>Installing any pre-release version of Firefox</li>
</ol>
<p>The nature of selection bias is such that the population in #1 is useless for analysis.
If you want to encourage users to collect good information for us,
ask them to install Beta:
it's only slightly harder than finding and checking the opt-in check-box in Firefox.</p>
<h3><a class="header" href="#trusting-dates" id="trusting-dates">Trusting Dates</a></h3>
<p>Don't trust client times.</p>
<p>Any timestamp recorded by the user is subject to &quot;clock skew.&quot;
The user's clock can be set (purposefully or accidentally) to any time at all.
The nature of SSL certificates tends to keep this within a certain relatively-accurate window,
because a user who's clock is too far in the past or too far in the future
might confuse certain expiration-date-checking code.</p>
<p>Examples of client times: <code>crashDate</code>, <code>crashTime</code>, <code>meta/Date</code>, <code>sessionStartDate</code>,
<code>subsessionStartDate</code>, <code>profile/creationDate</code></p>
<p>Examples of server times you can trust: <code>submission_timestamp</code>, <code>submission_date</code></p>
<p><em>Note that <code>submission_date</code> does not appear in the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/common-ping.html">ping documentation</a>
because it is added in post-processing.
It can be found in the <code>meta</code> field of the ping as in the <a href="https://dbc-caf9527b-e073.cloud.databricks.com/#notebook/30598/">Databricks Example</a>.</em></p>
<h3><a class="header" href="#date-formats" id="date-formats">Date Formats</a></h3>
<p>Not all dates and times are created equal.
Most of the dates and times in Telemetry pings are <a href="https://en.wikipedia.org/wiki/ISO_8601">ISO 8601</a>.
Most are full timestamps, though their resolution may differ from being per-second to being per-day.</p>
<p>Then there's <code>profile/creationDate</code> which is just a number of days since epoch (January 1, 1970).
Like <code>17177</code> for the date 2017-01-11.</p>
<p><strong>Tip:</strong> To convert <code>profile/creationDate</code> to a usable date in SQL:
<code>DATE_ADD('day', profile_created, DATE '1970-01-01')</code></p>
<p>In derived datasets ISO dates are sometimes converted to strings in one of
two formats: <code>%Y-%m-%d</code> or <code>%Y%m%d</code>.</p>
<p>The date formats for different rows in <code>main_summary</code> are described on the
<a href="concepts/../datasets/batch_view/main_summary/reference.html#time-formats"><code>main_summary</code> reference page</a>.</p>
<p>Build ids look like dates but aren't.
If you take the first eight characters you can use that as a proxy
for the day the build was released.</p>
<p><code>metadata/Date</code> is an HTTP Date header in a <a href="http://tools.ietf.org/html/rfc7231#section-7.1.1.1">RFC 7231</a>-compatible format.</p>
<p><strong>Tip:</strong> To parse <code>metadata/Date</code> to a usable date in SQL:
<code>DATE_PARSE(SUBSTR(client_submission_date, 1, 25), '%a, %d %b %Y %H:%i:%s')</code></p>
<h3><a class="header" href="#delays" id="delays">Delays</a></h3>
<p>Telemetry data takes a while to get into our hands.
The largest data mule in Telemetry is the main-ping.
It is (pending <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1336360">Bug 1336360</a>) sent at the beginning of a client's <em>next</em> Firefox session.
If the user shuts down their Firefox for the weekend,
we won't get their Friday data until Monday morning.</p>
<p>A rule of thumb is data from two days ago is usually fairly representative.</p>
<p>If you'd like to read more about this subject and look at pretty graphs,
there are a series of blog posts <a href="https://chuttenblog.wordpress.com/2017/02/09/data-science-is-hard-client-delays-for-crash-pings/">here</a>, <a href="https://chuttenblog.wordpress.com/2017/07/12/latency-improvements-or-yet-another-satisfying-graph/">here</a> and <a href="https://chuttenblog.wordpress.com/2017/09/12/two-days-or-how-long-until-the-data-is-in/">here</a>.</p>
<h4><a class="header" href="#pingsender-1" id="pingsender-1">Pingsender</a></h4>
<p>Pingsender greatly reduces delay in sending pings to Mozilla,
but only some types of pings are sent by Pingsender.
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1310703">Bug 1310703</a> introduced Pingsender for crash pings and was merged in Firefox 54,
which hit release on June 13, 2017.
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1336360">Bug 1336360</a> moved shutdown pings to Pingsender and was merged in Firefox 55,
which hit release on August 8, 2017.
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1374270">Bug 1374270</a> added sending health pings on shutdown via Pingsender and was
merged in Firefox 56, which hit release on Sept 28, 2017.
Other types of pings are not sent with Pingsender.
This is usually okay because Firefox is expected to continue running long
enough to send those pings.</p>
<p>Mobile clients do not have Pingsender,
so they suffer delay as given in <a href="https://sql.telemetry.mozilla.org/queries/49867#134105">this query</a>.</p>
<h3><a class="header" href="#submission-date" id="submission-date">Submission Date</a></h3>
<p><code>submission_date</code> is the server time at which a ping is received from the client.
We use it to partition many of our data sets.</p>
<p>In <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1422892">bug 1422892</a> we decided
to standardize on <code>submission_date</code>.</p>
<p>TL;DR</p>
<ul>
<li>not subject to client clock skew</li>
<li>doesn't require normalization</li>
<li>good for backfill</li>
<li>good for daily processing</li>
<li>and usually good enough</li>
</ul>
<h1><a class="header" href="#optimizing-sql-queries" id="optimizing-sql-queries">Optimizing SQL Queries</a></h1>
<p>After you write a query in <a href="https://sql.telemetry.mozilla.org">STMO</a>, you can make big steps to improve performance by
understanding how data is stored, what databases are doing under the covers, and what you can change about your query to
take advantage of those two pieces.</p>
<h2><a class="header" href="#tldr-what-to-do-for-quick-improvements" id="tldr-what-to-do-for-quick-improvements">TL;DR: What to do for quick improvements</a></h2>
<ul>
<li>Filter on a partitioned column (<em>even</em> if you have a <code>LIMIT</code>)</li>
<li>Use a sample of the data based on the <code>sample_id</code> field. This can be helpful
for initial development, even if you later run the query using the entire
population (without sampling).</li>
<li>Select only the columns you want explicitly (Don't use <code>SELECT *</code>)</li>
<li>Use approximate algorithms: e.g. <code>approx_distinct(...)</code> instead of <code>COUNT(DISTINCT ...)</code></li>
</ul>
<p> Partitioned columns can be identified in the Schema Explorer in <a href="https://sql.telemetry.mozilla.org">re:dash</a>.
They are the first few columns under a table name, and their name is preceded by a <code>[P]</code>.</p>
<h2><a class="header" href="#some-explanations" id="some-explanations">Some Explanations</a></h2>
<p>There are a few key things to understand about our data storage and these databases to
learn how to properly optimize queries.</p>
<h3><a class="header" href="#what-are-these-databases" id="what-are-these-databases">What are these databases?</a></h3>
<p>The databases we use are not traditional relational databases like PostgreSQL or MySQL.
They are distributed SQL engines, where the data is stored separately from the compute resources.
They include multiple machines all working together in a coordinated fashion.</p>
<h4><a class="header" href="#how-does-this-impact-my-queries" id="how-does-this-impact-my-queries">How does this impact my queries?</a></h4>
<p>What that means is that multiple machines will be working together to get the result of your
query. Because there is more than one machine, we worry a lot about <em>Data Shuffles</em>: when all
of the machines have to send data around to all of the other machines.</p>
<p>For example, consider the following query, which gives the number of rows present for each
<code>client_id</code>:</p>
<pre><code>SELECT client_id, COUNT(*)
FROM telemetry.main
GROUP BY client_id
</code></pre>
<p>The steps that would happen are this:</p>
<ol>
<li>Each machine reads a different piece of the data, and parses out the <code>client_id</code> for
each row. Internally, it then computes the number of rows seen for each <code>client_id</code>,
<em>but only for the data that it read</em>.</li>
<li>Each machine is then given a set of <code>client_id</code>s to aggregate. For example, the first
machine may be told to get the count of <code>client1</code>. It will then have to ask every other
machine for the total seen for <code>client1</code>. It can then aggregate the total.</li>
<li>Given that every <code>client_id</code> has now been aggregated, each machine reports to the coordinator
the <code>client_id</code>s that it was responsible for, as well as the count of rows seen for each.
The coordinator is responsible for returning the result of the query to the client,
which in our example is STMO.</li>
</ol>
<p>A similar process happens on data joins, where different machines are told to join on
different keys. In that case, data from both tables needs to be shuffled to every machine.</p>
<h4><a class="header" href="#key-takeaways" id="key-takeaways">Key Takeaways</a></h4>
<ul>
<li>Use <code>LIMIT</code> for query prototyping. This can dramatically reduce the amount of data scanned
as well as speeding things up.</li>
<li>Use approximate algorithms. These mean less data needs to be shuffled, since we can use
probabilistic data structures instead of the raw data itself.</li>
<li>Specify large tables first in a <code>JOIN</code> operation. In this case, small tables can be sent to
every machine, eliminating one data shuffle operation. Note that Spark supports a <code>broadcast</code>
command explicitly.</li>
</ul>
<h3><a class="header" href="#how-is-the-data-stored" id="how-is-the-data-stored">How is the data stored?</a></h3>
<p>The data is stored in columnar format. Let's try and understand that with an example.</p>
<h4><a class="header" href="#traditional-row-stores" id="traditional-row-stores">Traditional Row Stores</a></h4>
<p>Consider a completely normal CSV file, which is actually an example of a row store.</p>
<pre><code>name,age,height
&quot;Ted&quot;,27,6.0
&quot;Emmanuel&quot;,45,5.9
&quot;Cadence&quot;,5,3.5
</code></pre>
<p>When this data is stored to disk, you could read an entire record in a consecutive order. For example if
the first <code>&quot;</code> was stored at block 1 on disk, then a sequential scan from 1 will give the first row of
data: <code>&quot;ted&quot;,27,6.0</code>. Keep scanning and you'll get <code>\n&quot;Emm</code>... and so on.</p>
<p>So for the above, the following query will be fast:</p>
<pre><code>SELECT *
FROM people
WHERE name == 'Ted'
</code></pre>
<p>Since the database can just scan the first row of data. However, the following is more difficult:</p>
<pre><code>SELECT name
FROM people
</code></pre>
<p>Now the database has to read <em>all</em> of the rows, and then pick out the <code>name</code> column. This is a lot
more overhead!</p>
<h4><a class="header" href="#columnar-stores" id="columnar-stores">Columnar Stores</a></h4>
<p>Columnar turns the data sideways. For example, we can make a columnar version of the above data,
and still store it in CSV:</p>
<pre><code>name,&quot;Ted&quot;,&quot;Emmanuel&quot;,&quot;Cadence&quot;
age,27,45,5
height,6.0,5.9,3.5
</code></pre>
<p>Pretty easy! Now let's consider how we can query the data when it's stored this way.</p>
<pre><code>SELECT *
FROM people
WHERE name == &quot;ted&quot;
</code></pre>
<p>This query is pretty hard! We have to read all of the data now, because the
<code>(name, age, height)</code> isn't stored together.</p>
<p>Now let's consider our other query:</p>
<pre><code>SELECT name
FROM people
</code></pre>
<p>Suddenly, this is easy! We don't have to check in as many places for data,
we can just read the first few blocks of disks sequentially.</p>
<h4><a class="header" href="#data-partitions" id="data-partitions">Data Partitions</a></h4>
<p>We can improve performance even further by taking advantage of partitions. These are entire files of data
that share a value for a column. So for example, if everyone in the <code>people</code> table lived in <code>DE</code>, then we
could add that to the filename: <code>/country=DE/people.csv</code>.</p>
<p>From there, our query engine would have to know how to read that path, and understand that it's telling us
that all of those people share a country. So if we were to query for this:</p>
<pre><code>SELECT *
FROM people
WHERE country == 'US'
</code></pre>
<p>The database wouldn't have to even read the file! It could just look at the path and realize there was
nothing of interest.</p>
<p>Our tables are usually partitioned by date, e.g. <code>submission_date</code> or <code>DATE(submission_timestamp)</code>.</p>
<h4><a class="header" href="#key-takeaways-1" id="key-takeaways-1">Key Takeaways</a></h4>
<ul>
<li>Limit queries to a specific few columns you need, to reduce the amount of data that has to be read</li>
<li>Filter on partitions to prune down the data you need</li>
</ul>
<h1><a class="header" href="#getting-help" id="getting-help">Getting Help</a></h1>
<h3><a class="header" href="#mailing-lists" id="mailing-lists">Mailing lists</a></h3>
<p>Telemetry-related announcements including new datasets, outages, feature
releases, etc are sent to <a href="mailto:fx-data-dev@mozilla.org"><code>fx-data-dev@mozilla.org</code></a>, a public
mailing list.
Please subscribe to the <a href="https://mail.mozilla.org/listinfo/fx-data-dev">mailing list here</a>.</p>
<p>There's also an internal mailing list,
<a href="mailto:fx-data-platform@mozilla.com"><code>fx-data-platform@mozilla.com</code></a>,
meant for internal data platform team communications.
Please speak to your manager if you believe you should be on the list.</p>
<h3><a class="header" href="#irc" id="irc">IRC</a></h3>
<p>The data platform team is available in <code>#telemetry</code> on <code>irc.mozilla.org</code>.
For pipeline-specific issues, you can also find us in <code>#datapipeline</code>.</p>
<h3><a class="header" href="#slack" id="slack">Slack</a></h3>
<p>The Mozilla data org is reachable at <code>#fx-metrics</code> in the internal Mozilla Slack.</p>
<h1><a class="header" href="#tools" id="tools">Tools</a></h1>
<p>This section describes tools we recommend using to analyze Firefox data.</p>
<h1><a class="header" href="#projects" id="projects">Projects</a></h1>
<p>Below are a number of trailheads that lead into the projects and code that comprise the Firefox Data Platform.</p>
<h2><a class="header" href="#telemetry-apis" id="telemetry-apis">Telemetry APIs</a></h2>
<table><thead><tr><th>Name and repo</th><th>Description</th></tr></thead><tbody>
<tr><td><a href="https://github.com/mozilla/python_moztelemetry"><code>python_moztelemetry</code></a></td><td>Python APIs for Mozilla Telemetry</td></tr>
<tr><td><a href="https://github.com/mozilla/moztelemetry"><code>moztelemetry</code></a></td><td>Scala APIs for Mozilla Telemetry</td></tr>
<tr><td><a href="https://github.com/mozilla/spark-hyperloglog"><code>spark-hyperloglog</code></a></td><td>Algebird's HyperLogLog support for Apache Spark</td></tr>
<tr><td><a href="https://github.com/mozilla/mozanalysis"><code>mozanalysis</code></a></td><td>A library for Mozilla experiments analysis</td></tr>
<tr><td><a href="https://github.com/mozilla-mobile/android-components/tree/master/components/service/glean"><code>glean</code></a></td><td>A client-side mobile Telemetry SDK for collecting metrics and sending them to Mozilla's Telemetry service</td></tr>
</tbody></table>
<h2><a class="header" href="#etl-code-and-datasets" id="etl-code-and-datasets">ETL code and Datasets</a></h2>
<table><thead><tr><th>Name and repo</th><th>Description</th></tr></thead><tbody>
<tr><td><a href="https://github.com/mozilla/bigquery-etl"><code>bigquery-etl</code></a></td><td>SQL ETL code for building derived datasets in BigQuery</td></tr>
<tr><td><a href="https://github.com/mozilla/telemetry-batch-view"><code>telemetry-batch-view</code></a></td><td>Scala ETL code for derived datasets</td></tr>
<tr><td><a href="https://github.com/mozilla/python_mozetl"><code>python_mozetl</code></a></td><td>Python ETL code for derived datasets</td></tr>
<tr><td><a href="https://github.com/mozilla/telemetry-airflow"><code>telemetry-airflow</code></a></td><td>Airflow configuration and DAGs for scheduled jobs</td></tr>
<tr><td><a href="https://github.com/mozilla/python_mozaggregator"><code>python_mozaggregator</code></a></td><td>Aggregation job for <code>telemetry.mozilla.org</code> aggregates</td></tr>
<tr><td><a href="https://github.com/mozilla/telemetry-streaming"><code>telemetry-streaming</code></a></td><td>Spark Streaming ETL jobs for Mozilla Telemetry</td></tr>
</tbody></table>
<p>See also <a href="https://docs.telemetry.mozilla.org"><code>firefox-data-docs</code></a> for documentation on datasets.</p>
<h2><a class="header" href="#infrastructure" id="infrastructure">Infrastructure</a></h2>
<table><thead><tr><th>Name and repo</th><th>Description</th></tr></thead><tbody>
<tr><td><a href="https://github.com/mozilla-services/mozilla-pipeline-schemas"><code>mozilla-pipeline-schemas</code></a></td><td>JSON and Parquet Schemas for Mozilla Telemetry and other structured data</td></tr>
<tr><td><a href="https://github.com/mozilla/gcp-ingestion"><code>gcp-ingestion</code></a></td><td>Documentation and implementation of the Mozilla telemetry ingestion system on Google Cloud Platform</td></tr>
<tr><td><a href="https://github.com/mozilla/jsonschema-transpiler"><code>jsonschema-transpiler</code></a></td><td>Convert JSON Schema into BigQuery table definitions</td></tr>
<tr><td><a href="https://github.com/mozilla/mozilla-schema-generator"><code>mozilla-schema-generator</code></a></td><td>Incorporate probe metadata to generate BigQuery table schemas</td></tr>
<tr><td><a href="https://github.com/mozilla-services/hindsight"><code>hindsight</code></a></td><td>Real-time data processing</td></tr>
<tr><td><a href="https://github.com/mozilla-services/lua_sandbox"><code>lua_sandbox</code></a></td><td>Generic sandbox for safe data analysis</td></tr>
<tr><td><a href="https://github.com/mozilla-services/lua_sandbox_extensions"><code>lua_sandbox_extensions</code></a></td><td>Modules and packages that extend the Lua sandbox</td></tr>
<tr><td><a href="https://github.com/mozilla-services/nginx_moz_ingest"><code>nginx_moz_ingest</code></a></td><td>Nginx module for Telemetry data ingestion</td></tr>
<tr><td><a href="https://github.com/mozilla-services/puppet-config/tree/master/pipeline"><code>puppet-config</code></a></td><td>Cloud services puppet config for deploying infrastructure</td></tr>
<tr><td><a href="https://github.com/mozilla/parquet2hive"><code>parquet2hive</code></a></td><td>Hive import statement generator for Parquet datasets</td></tr>
<tr><td><a href="https://github.com/mozilla-services/edge-validator"><code>edge-validator</code></a></td><td>A service endpoint for validating incoming data</td></tr>
</tbody></table>
<h2><a class="header" href="#data-applications" id="data-applications">Data applications</a></h2>
<table><thead><tr><th>Name and repo</th><th>Description</th></tr></thead><tbody>
<tr><td><a href="https://github.com/mozilla/telemetry-dashboard"><code>telemetry.mozilla.org</code></a></td><td>Main entry point for viewing <a href="https://telemetry.mozilla.org">aggregate Telemetry data</a></td></tr>
<tr><td><a href="https://growth-stage.bespoke.nonprod.dataops.mozgcp.net">Growth &amp; Usage dashboard</a></td><td>Dashboard for questions about product growth and usage</td></tr>
<tr><td><a href="https://github.com/mozilla/glam">Glean Aggregate Metrics</a></td><td>Aggregate info about probes and measures</td></tr>
<tr><td><a href="https://debug-ping-preview.firebaseapp.com">Glean Debug View</a></td><td>Tag and view Glean submissions with low latency</td></tr>
<tr><td><a href="https://github.com/mozilla/cerberus">Cerberus</a> &amp; <a href="https://github.com/mozilla/medusa">Medusa</a></td><td>Automatic alert system for telemetry aggregates</td></tr>
<tr><td><a href="https://github.com/mozilla/missioncontrol">Mission Control</a></td><td>Low latency dashboard for stability and health metrics</td></tr>
<tr><td><a href="https://github.com/mozilla/redash">Re:dash</a></td><td>Mozilla's fork of the <a href="https://sql.telemetry.mozilla.org">data query / visualization system</a></td></tr>
<tr><td><a href="https://github.com/mozilla/redash-stmo"><code>redash-stmo</code></a></td><td>Mozilla's extensions to Re:dash</td></tr>
<tr><td><a href="https://github.com/mozilla/taar">TAAR</a></td><td>Telemetry-aware addon recommender</td></tr>
<tr><td><a href="https://github.com/mozilla/ensemble">Ensemble</a></td><td>A minimalist platform for publishing data</td></tr>
<tr><td><a href="https://github.com/mozilla/firefox-hardware-report">Hardware Report</a></td><td>Firefox Hardware Report, <a href="https://hardware.metrics.mozilla.com/">available here</a></td></tr>
<tr><td><a href="https://github.com/mozilla/python-zeppelin"><code>python-zeppelin</code></a></td><td>Convert Zeppelin notebooks to Markdown</td></tr>
<tr><td><a href="https://github.com/mozilla/stmocli">St. Mocli</a></td><td>A command-line interface to <a href="https://sql.telemetry.mozilla.org">STMO</a></td></tr>
<tr><td><a href="https://github.com/mozilla/probe-scraper">probe-scraper</a></td><td>Scrape and publish Telemetry probe data from Firefox</td></tr>
<tr><td><a href="https://github.com/mozilla/firefox-test-tube">test-tube</a></td><td>Compare data across branches in experiments</td></tr>
<tr><td><a href="https://github.com/mozilla/experimenter">experimenter</a></td><td>A web application for managing experiments</td></tr>
<tr><td><a href="https://github.com/mozilla/stmoab">St. Moab</a></td><td>Automatically generate Re:dash dashboard for A/B experiments</td></tr>
<tr><td><a href="http://iodide.telemetry.mozilla.org/">Iodide</a> (<a href="https://github.com/iodide-project/iodide">code</a>)</td><td>Literate scientific computing and communication for the web</td></tr>
</tbody></table>
<h2><a class="header" href="#legacy-projects" id="legacy-projects">Legacy projects</a></h2>
<p>Projects in this section are less active, but may not be officially
deprecated. Please check with the <code>fx-data-dev</code> mailing list before
starting a new project using anything in this section.</p>
<table><thead><tr><th>Name and repo</th><th>Description</th></tr></thead><tbody>
<tr><td><a href="https://github.com/mozilla/telemetry-next-node"><code>telemetry-next-node</code></a></td><td>A <code>node.js</code> package for accessing Telemetry Aggregates data</td></tr>
<tr><td><a href="https://github.com/mozilla/emr-bootstrap-spark"><code>emr-bootstrap-spark</code></a></td><td>AWS bootstrap scripts for Spark.</td></tr>
<tr><td><a href="https://github.com/mozilla/emr-bootstrap-presto"><code>emr-bootstrap-presto</code></a></td><td>AWS bootstrap scripts for Presto.</td></tr>
</tbody></table>
<h2><a class="header" href="#reference-materials" id="reference-materials">Reference materials</a></h2>
<h3><a class="header" href="#public" id="public">Public</a></h3>
<table><thead><tr><th>Name and repo</th><th>Description</th></tr></thead><tbody>
<tr><td><a href="https://github.com/mozilla/firefox-data-docs"><code>firefox-data-docs</code></a></td><td>All the info you need to <a href="https://docs.telemetry.mozilla.org">answer questions about Firefox users with data</a></td></tr>
<tr><td>Firefox source docs</td><td><a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/">Mozilla Source Tree Docs - Telemetry section</a></td></tr>
<tr><td><a href="https://github.com/mozilla/mozilla-reports"><code>reports.t.m.o</code></a></td><td>Knowledge repository for <a href="https://mozilla.report">public reports</a></td></tr>
</tbody></table>
<h3><a class="header" href="#non-public" id="non-public">Non-public</a></h3>
<table><thead><tr><th>Name and repo</th><th>Description</th></tr></thead><tbody>
<tr><td><a href="https://github.com/mozilla/Fx-Data-Planning"><code>Fx-Data-Planning</code></a></td><td>Quarterly goals and internal documentation</td></tr>
</tbody></table>
<h1><a class="header" href="#an-overview-of-mozillas-data-pipeline" id="an-overview-of-mozillas-data-pipeline">An overview of Mozillas Data Pipeline</a></h1>
<p>This post describes the architecture of Mozillas data pipeline,
which is used to collect Telemetry data from our products and logs from various services.</p>
<p>The bulk of the data handled by this pipeline is Firefox Telemetry data, but the
same tool-chain is used to collect, store, and analyze data coming from many
sources.</p>
<p>Here is a simplified diagram of how data is ingested into the data warehouse.</p>
<pre class="mermaid">graph TD

f1(fa:fa-firefox Firefox) -->|HTTP Post| k1(fa:fa-filter Ingestion Edge)
k1 --> p1(fa:fa-stream Raw Topic)
p1 --> d1(fa:fa-exchange-alt Landfill Sink)
d1 --> b1(fa:fa-database Landfill BQ)
p1 --> d2(fa:fa-exchange-alt Decoder)
d2 -->|success| p2(fa:fa-stream Decoded Topic)
d2 -.->|fail| p3(fa:fa-stream Errors Topic)
p3 --> d4(fa:fa-exchange-alt Errors Sink)
p2 --> d3(fa:fa-exchange-alt BigQuery Sink)
d3 --> b2(fa:fa-database Live Tables BQ)
d4 --> b3(fa:fa-database Error Tables BQ)

classDef pubsub fill:#eff,stroke:#099;
classDef dataflow fill:#efe,stroke:#090;
classDef kube fill:#fef,stroke:#909;
classDef producers fill:#fee,stroke:#f90;
classDef bq fill:#ececff,stroke:#9370db;
class p1,p2,p3 pubsub
class d1,d2,d3,d4 dataflow
class k1 kube
class f1 producers
class b1,b2,b3 bq
</pre>
<h2><a class="header" href="#firefox" id="firefox">Firefox</a></h2>
<p>There are different APIs and formats to <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/index.html">collect data</a> in Firefox, all suiting different use cases:</p>
<ul>
<li><a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/histograms.html">histograms</a>  for recording multiple data points;</li>
<li><a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/scalars.html">scalars</a>  for recording single values;</li>
<li><a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/measuring-time.html">timings</a>  for measuring how long operations take;</li>
<li><a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/events.html">events</a>  for recording time-stamped events.</li>
</ul>
<p>These are commonly referred to as <em><a href="concepts/pipeline/../../datasets/new_data.html">probes</a></em>.
Each probe must declare the <a href="https://wiki.mozilla.org/Firefox/Data_Collection">collection policy</a> it conforms to: either <em>release</em> or <em>prerelease</em>.
When adding a new measurement data-reviewers carefully inspect the probe and eventually approve the requested collection policy:</p>
<ul>
<li>Release data is collected from all Firefox users.</li>
<li>Prerelease data is collected from users on Firefox Nightly and Beta channels.</li>
</ul>
<p>Users may choose to turn the data collection off in preferences.</p>
<p>A <em>session</em> begins when Firefox starts up and ends when it shuts down.
As a session could be long-running and last weeks, it gets sliced into
smaller logical units called <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/concepts/sessions.html#subsessions">subsessions</a>.
Each subsession generates a batch of data containing the current state
of all probes collected so far, in the form of a [<code>main</code> ping], which is
sent to our servers.
The <code>main</code> ping is just one of the many <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/concepts/pings.html#ping-types">ping types</a> we support.
Developers can <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/custom-pings.html">create their own ping types</a> if needed.</p>
<p><em>Pings</em> are submitted via an <a href="https://dxr.mozilla.org/mozilla-central/rev/6a23526fe5168087d7e4132c0705aefcaed5f571/toolkit/components/telemetry/TelemetryController.jsm#202">API</a> that performs a HTTP POST request to our edge servers.
If a ping fails to successfully <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/concepts/submission.html#submission">submit</a> (e.g. because of missing internet connection),
Firefox will store the ping on disk and retry to send it until the maximum ping age is exceeded.</p>
<h2><a class="header" href="#ingestion" id="ingestion">Ingestion</a></h2>
<p>Submissions coming in from the wild hit a load balancer and then an
HTTP Server that <a href="concepts/pipeline/http_edge_spec.html">accepts POST requests</a> containing a
message body of optionally-gzipped JSON.</p>
<p>These messages are forwarded to a PubSub message queue with minimal processing,
and made available in a <strong>Raw</strong> topic.</p>
<p>A Dataflow job reads this topic and writes the raw messages to a BigQuery <strong>Landfill</strong> sink.
This Landfill data is not used for analysis, but is stored in its raw form for
recovery and backfill purposes.</p>
<p>If there is a processing error or data-loss downstream in the pipeline, this is an important fail-safe.</p>
<h2><a class="header" href="#decoding" id="decoding">Decoding</a></h2>
<p>Once the raw data has been added to the PubSub queue, it's time to process it.</p>
<p>The decoder is implemented as a [Dataflow] job, and is written in Java.</p>
<p>The decoding process tackles decompression, parsing, validation, deduplication,
and enrichment of incoming messages.</p>
<p>After a message is decompressed and parsed as JSON, we apply [JSONSchema validation]
to ensure that submissions are well-formed.</p>
<p>Sometimes duplicate submissions are sent to the pipeline, either due to normal
networking failures or [weird behaviour] out there in the world.
We watch for duplicate submissions, and discard any subsequent occurrences of
already-seen records.</p>
<p>Submissions are also enriched with some metadata about the request itself,
including things like HTTP headers, GeoIP information, and submission timestamp.</p>
<p>Messages that pass <em>successfully</em> through all these steps are written to another
PubSub <strong>Decoded</strong> topic.</p>
<p>A failure in any of these steps results in messages being sent to the <strong>Errors</strong> sink.
This separates invalid data from valid data, while still making it available for
monitoring and debugging.
This is a good way to keep an eye on the health of the pipeline and the data
flowing through.</p>
<h2><a class="header" href="#data-warehouse" id="data-warehouse">Data Warehouse</a></h2>
<p>Decoded data is ultimately written out to BigQuery, which acts as the data warehouse.</p>
<p>By this time, incoming data has already been validated against the corresponding
JSONSchema specification for each document type.
Part of the decoding process above transforms this JSON structure into something
more easily represented in BigQuery.
One important transformation here is to convert all incoming fields from
<code>UPPER CASE</code> or <code>camelCase</code> to <code>snake_case</code>.
Another important transformation is to incorporate metadata about known probes
and metrics to generate more complete schemas.</p>
<p>This is handled by a combination of the decoder above, the [schema transpiler]
and the [schema generator].
The result are tables that contains SQL-friendly field names for all known
measures, as implemented in the [probe scraper].</p>
<p>A Dataflow job reads from the Decoded topic and writes out to <strong>[live ping tables]</strong>.
These tables are updated frequently, and typically reflect data within a few
minutes of it being ingested. They are optimized for accessing recent data,
but are only guaranteed to contain a few days of history.</p>
<p>Historical raw ping data is stored in <strong>[historical ping tables]</strong>, also known as <strong>stable tables</strong>.
These tables include only completed days of data, are populated once a day
shortly after midnight UTC.
Data in the Stable tables is partitioned by day, and optimized for accessing
larger time periods. It is also optimized for limiting analysis to a fraction
of the data using the <code>normalized_channel</code> and <code>sample_id</code> fields.</p>
<h1><a class="header" href="#beyond-the-data-warehouse" id="beyond-the-data-warehouse">Beyond the Data Warehouse</a></h1>
<p>The diagram above shows the path data takes to get into the data warehouse.
After that, we have to start using it!</p>
<h2><a class="header" href="#workflow-management-and-etl" id="workflow-management-and-etl">Workflow Management and ETL</a></h2>
<p>We use <a href="https://github.com/mozilla/telemetry-airflow/">Airflow</a> for workflow management.</p>
<p>It orchestrates the daily creation of the Stable tables described above,
as well as many other derived datasets.</p>
<p>The ETL code to create derived datasets is commonly implemented using queries in BigQuery.</p>
<p>Many examples can be found in the [bigquery-etl] repository.</p>
<p>Data in BigQuery is also accessible via Spark, and several ETL jobs also run via Dataproc.</p>
<p>These jobs produce data sets that are used for downstream analysis and data
applications (such as <a href="https://telemetry.mozilla.org/">measurement</a> and <a href="https://missioncontrol.telemetry.mozilla.org">stability</a> dashboards,
<a href="https://github.com/mozilla/taar">addon recommendation</a>, and other <a href="concepts/pipeline/../../tools/projects.html#data-applications">data products</a>).</p>
<h2><a class="header" href="#data-analysis" id="data-analysis">Data Analysis</a></h2>
<p>Once the data reaches our data warehouse in BigQuery it can be processed
in a number of ways as described in the <a href="concepts/pipeline/../../cookbooks/bigquery.html">Accessing BigQuery</a> article.</p>
<p>Data analysis is most commonly done using <a href="https://sql.telemetry.mozilla.org/">SQL queries</a> or using <a href="concepts/pipeline/../../tools/spark.html">Spark</a>.</p>
<h1><a class="header" href="#http-edge-server-specification" id="http-edge-server-specification">HTTP Edge Server Specification</a></h1>
<p>This document specifies the behavior of the server that accepts submissions from
any HTTP client e.g. Firefox telemetry.</p>
<p>The original implementation of the HTTP Edge Server was tracked in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1129222">Bug 1129222</a>.</p>
<h2><a class="header" href="#general-data-flow" id="general-data-flow">General Data Flow</a></h2>
<p>HTTP submissions come in from the wild, hit a load balancer,
then the HTTP Edge Server described in this document.
Data is accepted via a POST/PUT request from clients,
and forwarded to the <a href="concepts/pipeline/data_pipeline.html">Data Pipeline</a>, where
any further processing, analysis, and storage will be handled.</p>
<p>Submission payloads are expected to be optionally-gzipped JSON
documents described by a [JSONSchema].</p>
<h2><a class="header" href="#server-requestresponse" id="server-requestresponse">Server Request/Response</a></h2>
<h3><a class="header" href="#get-request" id="get-request">GET Request</a></h3>
<p>Accept GET on <code>/status</code>, returning <code>OK</code> if all is well. This can be used to
check the health of web servers.</p>
<h3><a class="header" href="#get-response-codes" id="get-response-codes">GET Response codes</a></h3>
<ul>
<li><em>200</em> - OK. <code>/status</code> and all's well</li>
<li><em>404</em> - Any GET other than <code>/status</code></li>
<li><em>500</em> - All is not well</li>
</ul>
<h3><a class="header" href="#postput-request" id="postput-request">POST/PUT Request</a></h3>
<p>Treat POST and PUT the same. Accept POST or PUT to URLs of the form:</p>
<p><code>/submit/&lt;namespace&gt;/&lt;docType&gt;/&lt;docVersion&gt;/&lt;docId&gt;</code></p>
<p>A specific example submission URL looks like:</p>
<p><code>/submit/eng-workflow/hgpush/1/2c3a0767-d84a-4d02-8a92-fa54a3376049</code></p>
<p>With the following components:</p>
<ul>
<li><code>namespace</code> - an identifier used for grouping a set of related document types. Typically this represents an application that produces data.</li>
<li><code>docType</code> - a short descriptive name of the document type. Examples include <code>event</code>, <code>crash</code>, or <code>baseline</code></li>
<li><code>docVersion</code> - a numeric value indicating the version of the schema for this <code>docType</code></li>
<li><code>docId</code> - a UUID identifying the exact submission. If the same <code>docId</code> is seen more than once, it will be discarded as a duplicate.</li>
</ul>
<p>The combination of <code>namespace</code>, <code>docType</code> and <code>docVersion</code> together identify a specific schema to be used for validating submissions to the above endpoint.</p>
<p>If a schema is not present in the [schemas repository] corresponding to this combination, the submission
will be considered an error and will not proceed to the data lake.</p>
<h4><a class="header" href="#special-handling-for-firefox-desktop-telemetry" id="special-handling-for-firefox-desktop-telemetry">Special handling for Firefox Desktop Telemetry</a></h4>
<p>Firefox Desktop Telemetry uses a slightly different URL scheme:</p>
<p><code>/submit/telemetry/docId/docType/appName/appVersion/appUpdateChannel/appBuildID</code></p>
<p>A specific example:</p>
<p><code>/submit/telemetry/ce39b608-f595-4c69-b6a6-f7a436604648/main/Firefox/61.0a1/nightly/20180328030202</code></p>
<p>Here the <code>namespace</code> is fixed as &quot;telemetry&quot;, and there is no <code>docVersion</code> in the URL.
This means that incoming JSON documents must be parsed to determine the schema version
to apply for validation. This logic is part of the downstream [decoder] job.</p>
<h3><a class="header" href="#postput-response-codes" id="postput-response-codes">POST/PUT Response codes</a></h3>
<ul>
<li><em>200</em> - OK. Request accepted into the pipeline.</li>
<li><em>400</em> - Bad request, for example an un-encoded space in the URL.</li>
<li><em>404</em> - not found - POST/PUT to an unknown namespace</li>
<li><em>405</em> - wrong request type (anything other than POST/PUT)</li>
<li><em>411</em> - missing content-length header</li>
<li><em>413</em> - request body too large (Note that if we have badly-behaved clients that retry on <code>4XX</code>, we may opt to send back 202 on body/path too long).</li>
<li><em>414</em> - request path too long (See above)</li>
<li><em>500</em> - internal error</li>
</ul>
<h3><a class="header" href="#supported-http-headers" id="supported-http-headers">Supported HTTP Headers</a></h3>
<p>The following headers will be passed through the pipeline and made available as metadata.</p>
<ul>
<li><code>Date</code> - The client-supplied timestamp of the incoming request.
Used for computing client clock skew.</li>
<li><code>DNT</code> - The &quot;Do Not Track&quot; header.</li>
<li><code>X-PingSender-Version</code> - The version of <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/internals/pingsender.html">Pingsender</a> used to send this ping (if applicable).</li>
<li><code>X-Debug-ID</code> - An optional tag used to make data available to the [Glean Debug View].</li>
</ul>
<h2><a class="header" href="#other-considerations" id="other-considerations">Other Considerations</a></h2>
<h3><a class="header" href="#compression" id="compression">Compression</a></h3>
<p>Compression of submission payloads is optional but recommended.</p>
<p>The supported compression scheme is <code>gzip</code>.</p>
<p>We do not decompress or validate the content of submissions at the edge,
the server will reply with a success code even if a message is badly formed.</p>
<p>Badly formed data is still accepted and made available for monitoring, recovery,
analysis, and analysis purposes.</p>
<h3><a class="header" href="#bad-messages" id="bad-messages">Bad Messages</a></h3>
<p>Since the actual message is not examined by the edge server the only failures
that occur are defined by the response status codes above. Messages are only
forwarded to the pipeline when a response code of <code>200</code> is returned to the client.</p>
<h3><a class="header" href="#geoip-lookups" id="geoip-lookups">GeoIP Lookups</a></h3>
<p>No GeoIP lookup is performed by the edge server. If a client IP is available the
the decoder performs the lookup and then discards the IP before the message hits
long-term storage.</p>
<h3><a class="header" href="#data-retention" id="data-retention">Data Retention</a></h3>
<p>The edge server only stores data while waiting for it to be accepted to
PubSub, spilling to local disk in the case of a PubSub outage.</p>
<p>This means that in the normal case, data is not retained on the edge at all.
In the case of errors writing to PubSub, data is retained until the service
is restored and messages can be flushed to the queue.
Based on <a href="https://status.cloud.google.com/incident/cloud-pubsub">past outages</a>, this is typically a few hours or less.</p>
<h1><a class="header" href="#event-data-pipeline" id="event-data-pipeline">Event Data Pipeline</a></h1>
<p>We collect event-oriented data from different sources. This data is collected and processed in a
specific path through our data pipeline, which we will detail here.</p>
<pre class="mermaid">graph TD

subgraph Products
fx_code(fa:fa-cog Firefox code) --> firefox(fa:fa-firefox Firefox Telemetry)
fx_extensions(fa:fa-cog Mozilla extensions) --> firefox
mobile(fa:fa-cog Mobile products) --> mobile_telemetry(fa:fa-firefox Mobile Telemetry)
end

subgraph Data Platform
firefox -.->|main ping, Firefox <62| pipeline((fa:fa-database Firefox Data Pipeline))
firefox -->|event ping, Firefox 62+| pipeline
mobile_telemetry --> |mobile events ping| pipeline
pipeline -->|Firefox <62 events| main_summary[fa:fa-bars main summary table]
pipeline -->|Firefox 62+ events| events_table[fa:fa-bars events table]
main_summary --> events_table
pipeline -->|Mobile events| mobile_events_table[fa:fa-bars mobile events table]
end

subgraph Data Tools
events_table --> redash
mobile_events_table --> redash
main_summary --> redash(fa:fa-bar-chart Redash)
pipeline -->|on request| amplitude(fa:fa-bar-chart Amplitude)
end

style fx_code fill:#f94,stroke-width:0px
style fx_extensions fill:#f94,stroke-width:0px
style mobile fill:#f94,stroke-width:0px
style firefox fill:#f61,stroke-width:0px
style mobile_telemetry fill:#f61,stroke-width:0px
style pipeline fill:#79d,stroke-width:0px
style main_summary fill:lightblue,stroke-width:0px
style events_table fill:lightblue,stroke-width:0px
style mobile_events_table fill:lightblue,stroke-width:0px
style redash fill:salmon,stroke-width:0px
style amplitude fill:salmon,stroke-width:0px
</pre>
<h1><a class="header" href="#overview" id="overview">Overview</a></h1>
<p>Across the different Firefox teams there is a common need for a more fine grained understanding of
product usage, like understanding the order of interactions or how they occur over time.
To address that our data pipeline needs to support working with event-oriented data.</p>
<p>We specify a common event data format, which allows for broader, shared usage of data processing tools.
To make working with event data feasible, we provide different mechanisms to get the event data
from products to our data pipeline and make the data available in tools for analysis.</p>
<h1><a class="header" href="#the-event-format" id="the-event-format">The event format</a></h1>
<p>Events are submitted as an array, e.g.:</p>
<pre><code class="language-javascript">[
  [2147, &quot;ui&quot;, &quot;click&quot;, &quot;back_button&quot;],
  [2213, &quot;ui&quot;, &quot;search&quot;, &quot;search_bar&quot;, &quot;google&quot;],
  [2892, &quot;ui&quot;, &quot;completion&quot;, &quot;search_bar&quot;, &quot;yahoo&quot;,
    {&quot;querylen&quot;: &quot;7&quot;, &quot;results&quot;: &quot;23&quot;}],
  [5434, &quot;dom&quot;, &quot;load&quot;, &quot;frame&quot;, null,
    {&quot;prot&quot;: &quot;https&quot;, &quot;src&quot;: &quot;script&quot;}],
  // ...
]
</code></pre>
<p>Each event is of the form:</p>
<pre><code class="language-javascript">[timestamp, category, method, object, value, extra]
</code></pre>
<p>Where the individual fields are:</p>
<ul>
<li><code>timestamp</code>: <code>Number</code>, positive integer. This is the time in ms when the event was recorded, relative to the main process start time.</li>
<li><code>category</code>: <code>String</code>, identifier. The category is a group name for events and helps to avoid name conflicts.</li>
<li><code>method</code>: <code>String</code>, identifier. This describes the type of event that occurred, e.g. <code>click</code>, <code>keydown</code> or <code>focus</code>.</li>
<li><code>object</code>: <code>String</code>, identifier. This is the object the event occurred on, e.g. <code>reload_button</code> or <code>urlbar</code>.</li>
<li><code>value</code>: <code>String</code>, optional, may be null. This is a user defined value, providing context for the event.</li>
<li><code>extra</code>: <code>Object</code>, optional, may be null. This is an object of the form <code>{&quot;key&quot;: &quot;value&quot;, ...}</code>, both keys and values need to be strings. This is used for events when additional richer context is needed.</li>
</ul>
<p>See also the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/events.html#serialization-format">Firefox Telemetry documentation</a>.</p>
<h1><a class="header" href="#event-data-collection" id="event-data-collection">Event data collection</a></h1>
<h2><a class="header" href="#firefox-event-collection" id="firefox-event-collection">Firefox event collection</a></h2>
<p>To collect this event data in Firefox there are different APIs in Firefox, all addressing different
use cases:</p>
<ul>
<li>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/events.html"><em>Telemetry event API</em></a>
allows easy recording of events from Firefox code.</li>
<li>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/events.html#registerevents"><em>dynamic event API</em></a>
allows code from Mozilla addons to record new events into Telemetry without shipping Firefox
code.</li>
<li>The <em><a href="https://searchfox.org/mozilla-central/rev/55da592d85c2baf8d8818010c41d9738c97013d2/toolkit/components/extensions/schemas/telemetry.json#87">Telemetry WebExtension API</a></em> (<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1280234">introduced here</a>)
which allows Mozilla extensions to record new events into Telemetry.</li>
</ul>
<p>For all these APIs, events will get sent to the pipeline through the
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/event-ping.html">event ping</a>, which gets sent hourly, if any pings were recorded, or up to every 10 minutes whenever 1000 events were recorded.
Before Firefox 62, events were sent through the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html">main ping</a> instead, with a hard limit of 500 events per ping.
From Firefox 61, all events recorded through these APIs are <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1440673">automatically counted in scalars</a>.</p>
<p>Finally, <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/custom-pings.html"><em>custom pings</em></a>
can follow the event data format and potentially connect to the existing tooling with some integration work.</p>
<h2><a class="header" href="#mobile-event-collection" id="mobile-event-collection">Mobile event collection</a></h2>
<p>Mobile events data primarily flows through the mobile events ping (<a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/tree/dev/schemas/telemetry/mobile-event">ping schema</a>), from e.g. <a href="https://github.com/mozilla-mobile/firefox-ios/wiki/Event-Tracking-with-Mozilla&#x27;s-Telemetry-Service#event-ping">Firefox iOS</a>, Firefox for Fire TV and Rocket.</p>
<p>Currently we also collect event data from Firefox Focus through the <a href="https://github.com/mozilla-mobile/focus-ios/wiki/Event-Tracking-with-Mozilla%27s-Telemetry-Service#event-ping"><code>focus-events</code> ping</a>,
using the <a href="https://github.com/mozilla-mobile/telemetry-ios"><code>telemetry-ios</code></a> and
<a href="https://github.com/mozilla-mobile/telemetry-android"><code>telemetry-android</code></a> libraries.</p>
<h1><a class="header" href="#datasets" id="datasets">Datasets</a></h1>
<p>On the pipeline side, the event data is made available in different datasets:</p>
<ul>
<li><a href="concepts/pipeline/../choosing_a_dataset.html#mainsummary"><code>main_summary</code></a> has a row for each main ping and includes
its event payload for Firefox versions before 62.</li>
<li><a href="concepts/pipeline/../../datasets/batch_view/events/reference.html"><code>events</code></a> contains a row for each event received from main pings and event pings. See <a href="https://sql.telemetry.mozilla.org/queries/52582/source">this sample query</a>.</li>
<li><code>telemetry_mobile_event_parquet</code> contains a row for each mobile event ping. See <a href="https://sql.telemetry.mozilla.org/queries/52581/source">this sample query</a>.</li>
<li><code>focus_events_longitudinal</code> currently contains events from Firefox Focus.</li>
</ul>
<h1><a class="header" href="#data-tooling" id="data-tooling">Data tooling</a></h1>
<p>The above datasets are all accessible through <a href="concepts/pipeline/../../tools/stmo.html">Re:dash</a> and <a href="concepts/pipeline/../../tools/spark.html">Spark jobs</a>.</p>
<p>For product analytics based on event data, we have <a href="https://sso.mozilla.com/amplitude">Amplitude</a>
(hosted by the IT data team). We can connect our event data sources data to Amplitude.
We have an active connector to Amplitude for mobile events, which can push event data over
daily. For Firefox Desktop events this will be available soon.</p>
<h1><a class="header" href="#an-overview-of-mozillas-data-pipeline-1" id="an-overview-of-mozillas-data-pipeline-1">An overview of Mozillas Data Pipeline</a></h1>
<p><em>Note: This article describes the AWS-based pipeline which is being retired;
the client-side concepts here still apply, but this article will be updated
to reflect the new GCP pipeline.</em></p>
<p>This post describes the architecture of Mozillas data pipeline, which is used to collect Telemetry data from our users and logs from various services. One of the cool perks of working at Mozilla is that most of what we do is out in the open and because of that I can do more than just show you some diagram with arrows of our architecture; I can point you to the code, script &amp; configuration that underlies it!</p>
<p>To make the examples concrete, the following description is centered around the collection of Firefox Telemetry data. The same tool-chain is used to collect, store and analyze data coming from disparate sources though, such as service logs.</p>
<pre class="mermaid">graph TD
  firefox((fa:fa-firefox Firefox))-->|JSON| elb
  elb[Load Balancer]-->|JSON| nginx
  nginx-->|JSON| landfill(fa:fa-database S3 Landfill)
  nginx-->|protobuf| kafka[fa:fa-files-o Kafka]
  kafka-->|protobuf| cep(Hindsight CEP)
  kafka-->|protobuf| dwl(Hindsight DWL)
  cep--> hsui(Hindsight UI)
  dwl-->|protobuf| datalake(fa:fa-database S3 Data Lake)
  dwl-->|parquet| datalake
  datalake-->|parquet| prestodb
  prestodb-->redash[fa:fa-line-chart Re:dash]
  datalake-->spark
  spark-->datalake
  airflow[fa:fa-clock-o Airflow]-->|Scheduled tasks|spark{fa:fa-star Spark}
  spark-->|aggregations|rdbms(fa:fa-database PostgreSQL)
  rdbms-->tmo[fa:fa-bar-chart TMO]
  rdbms-->cerberus[fa:fa-search-plus Cerberus]


style firefox fill:#f61
style elb fill:#777
style nginx fill:green
style landfill fill:tomato
style datalake fill:tomato
style kafka fill:#aaa
style cep fill:palegoldenrod
style dwl fill:palegoldenrod
style hsui fill:palegoldenrod
style prestodb fill:cornflowerblue
style redash fill:salmon
style spark fill:darkorange
style airflow fill:lawngreen
style rdbms fill:cornflowerblue
style tmo fill:lightgrey
style cerberus fill:royalblue
</pre>
<h1><a class="header" href="#firefox-1" id="firefox-1">Firefox</a></h1>
<p>There are different APIs and formats to <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/index.html">collect data</a> in Firefox, all suiting different use cases:</p>
<ul>
<li><a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/histograms.html">histograms</a>  for recording multiple data points;</li>
<li><a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/scalars.html">scalars</a>  for recording single values;</li>
<li><a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/measuring-time.html">timings</a>  for measuring how long operations take;</li>
<li><a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/events.html">events</a>  for recording time-stamped events.</li>
</ul>
<p>These are commonly referred to as <em><a href="concepts/pipeline/../../datasets/new_data.html">probes</a></em>. Each probe must declare the <a href="https://wiki.mozilla.org/Firefox/Data_Collection">collection policy</a> it conforms to: either <em>release</em> or <em>prerelease</em>. When adding a new measurement data-reviewers carefully inspect the probe and eventually approve the requested collection policy:</p>
<ul>
<li>Release data is collected from all Firefox users.</li>
<li>Prerelease data is collected from users on Firefox Nightly and Beta channels.</li>
</ul>
<p>Users may choose to turn the data collection off in preferences.</p>
<p>A <em>session</em> begins when Firefox starts up and ends when it shuts down. As a session could be long-running and last weeks, it gets sliced into smaller logical units called <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/concepts/sessions.html#subsessions">subsessions</a>. Each subsession generates a batch of data containing the current state of all probes collected so far, i.e. a <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html">main ping</a>, which is sent to our servers. The main ping is just one of the many <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/concepts/pings.html#ping-types">ping types</a> we support. Developers can <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/custom-pings.html">create their own ping types</a> if needed.</p>
<p><em>Pings</em> are submitted via an <a href="https://dxr.mozilla.org/mozilla-central/rev/6a23526fe5168087d7e4132c0705aefcaed5f571/toolkit/components/telemetry/TelemetryController.jsm#202">API</a> that performs a HTTP POST request to our edge servers. If a ping fails to successfully <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/concepts/submission.html#submission">submit</a> (e.g. because of missing internet connection), Firefox will store the ping on disk and retry to send it until the maximum ping age is exceeded.</p>
<h1><a class="header" href="#kafka" id="kafka">Kafka</a></h1>
<p>HTTP submissions coming in from the wild hit a <a href="https://aws.amazon.com/elasticloadbalancing/">load balancer</a> and then an NGINX <a href="https://github.com/mozilla-services/nginx_moz_ingest">module</a>. The <a href="https://github.com/mozilla-services/nginx_moz_ingest">module</a> accepts data via a <a href="https://wiki.mozilla.org/CloudServices/DataPipeline/HTTPEdgeServerSpecification">HTTP request</a> which it wraps in a Hindsight protobuf message and forwards to two places: a Kafka cluster and a short-lived S3 bucket (landfill) which acts as a fail-safe in case there is a processing error and/or data loss within the rest of the pipeline. The deployment scripts and configuration files of NGINX and Kafka live in a <a href="https://github.com/mozilla-services/puppet-config/tree/02f716a3e0df1117fc2494b41e85a1416f8e2a64/pipeline">private repository</a>.</p>
<p>The data from Kafka is read from the Complex Event Processors (CEP) and the Data Warehouse Loader (DWL), both of which use Hindsight.</p>
<h1><a class="header" href="#hindsight" id="hindsight">Hindsight</a></h1>
<p><a href="https://github.com/mozilla-services/hindsight">Hindsight</a>, an open source stream processing software system developed by Mozilla as <a href="https://github.com/mozilla-services/heka">Heka</a>s successor, is useful for a wide variety of different tasks, such as:</p>
<ul>
<li>converting data from one format to another;</li>
<li>shipping data from one location to another;</li>
<li>performing real time analysis, graphing, and anomaly detection.</li>
</ul>
<p>Hindsights core is a lightweight data processing kernel written in C that controls a set of Lua <a href="https://github.com/mozilla-services/hindsight/blob/9593668e84a642aff9dd95ccc648b6585948abfe/docs/index.md">plugins</a> executed inside a sandbox.</p>
<p>The CEP are custom plugins that are created, configured and deployed from an <a href="https://github.com/mozilla-services/hindsight_admin">UI</a> which produce real-time plots like the number of pings matching a certain criteria.  Mozilla employees can <a href="https://pipeline-cep.prod.mozaws.net/">access the UI</a> and create/deploy their own custom plugin in real-time without interfering with other plugins running.</p>
<p><img src="concepts/pipeline/../../assets/CEP_custom_plugin.jpeg" alt="CEP Custom Plugin" title="CEP  a custom plugin in action" /></p>
<p>The DWL is composed of a set of plugins that transform, convert &amp; finally shovel pings into S3 for long term storage. In the specific case of Telemetry data, an input plugin <a href="https://github.com/mozilla-services/lua_sandbox_extensions/blob/0895238e32d25241ef46f561e43039beb201c7cd/kafka/sandboxes/heka/input/kafka.lua">reads pings from Kafka</a>, <a href="https://github.com/mozilla-services/lua_sandbox_extensions/blob/5d8907ee9f1a20e3a02bfe5b57d4312b173487a3/moz_telemetry/io_modules/decoders/moz_telemetry/ping.lua">pre-processes</a> them and <a href="https://github.com/mozilla-services/lua_sandbox_extensions/blob/5d8907ee9f1a20e3a02bfe5b57d4312b173487a3/moz_telemetry/sandboxes/heka/output/moz_telemetry_s3.lua">sends batches to S3</a>, our data lake, for long term storage. The data is compressed and partitioned by a set of dimensions, like date and application.</p>
<p>The data has traditionally been serialized to <a href="https://hekad.readthedocs.io/en/latest/message/index.html#stream-framing">Protobuf</a> sequence files which contain some nasty free-form JSON fields. Hindsight gained recently the ability to <a href="https://github.com/mozilla-services/lua_sandbox_extensions/pull/48">dump data directly in Parquet form</a> though.</p>
<p>The deployment scripts and configuration files of the CEP &amp; DWL live in a <a href="https://github.com/mozilla-services/puppet-config/tree/02f716a3e0df1117fc2494b41e85a1416f8e2a64/pipeline">private repository</a>.</p>
<h1><a class="header" href="#spark" id="spark">Spark</a></h1>
<p>Once the data reaches our data lake on S3 it can be processed with Spark on Mozilla's <a href="https://dbc-caf9527b-e073.cloud.databricks.com">Databricks instance</a>. Databricks allows Mozilla employees to write custom analyses in notebooks, and also schedule Databricks jobs to run periodically.</p>
<p>As mentioned earlier, most of our data lake contains data serialized to Protobuf with free-form JSON fields. Needless to say, parsing JSON is terribly slow when ingesting Terabytes of data per day. A set of <a href="https://github.com/mozilla/telemetry-batch-view">ETL jobs</a>, written in Scala by Data Engineers and scheduled with <a href="https://github.com/mozilla/telemetry-airflow/">Airflow</a>, create <a href="concepts/pipeline/../choosing_a_dataset.html">Parquet views</a> of our raw data. We have a Github repository <a href="https://github.com/mozilla/telemetry-batch-view/">telemetry-batch-view</a> that showcases this.</p>
<h1><a class="header" href="#aggregates-dataset" id="aggregates-dataset">Aggregates Dataset</a></h1>
<pre class="mermaid">graph TD
%% Data Flow Diagram for mozaggregator/TMO-adjacent services
firefox((fa:fa-firefox Firefox)) --> |main ping| pipeline
fennec((fa:fa-firefox Fennec)) --> |saved-session ping| pipeline
pipeline((Telemetry Pipeline))

subgraph mozaggregator
  service(service)
  aggregator
  rdbms(fa:fa-database PostgreSQL)
end

pipeline --> aggregator
pipeline --> spark{fa:fa-star Spark}
pipeline --> redash[fa:fa-line-chart Re:dash]

subgraph telemetry.mozilla.org
  telemetry.js(telemetry.js) --> dist
  telemetry.js --> evo
  orphan[Update Orphaning]
  crashdash[tmo/crashes]
end

redash --> crashdash
service --> telemetry.js
spark --> orphan

telemetry.js --> telemetry-next-node(telemetry-next-node)
subgraph alerts.tmo
  cerberus[fa:fa-search-plus Cerberus] -->medusa
  medusa --> html
  medusa --> email
end

telemetry-next-node --> cerberus

style redash fill:salmon
style spark fill:darkorange
style rdbms fill:cornflowerblue
style cerberus fill:royalblue
style firefox fill:#f61
style fennec fill:#f61
style telemetry.js fill:lightgrey
style dist fill:lightgrey
style evo fill:lightgrey
</pre>
<p>A dedicated Spark job feeds daily aggregates to a PostgreSQL database which powers a <a href="https://github.com/mozilla/python_mozaggregator/#api">HTTP service</a> to easily retrieve faceted roll-ups. The service is mainly used by <a href="https://telemetry.mozilla.org/">TMO</a>, a dashboard that visualizes distributions and time-series, and <a href="https://github.com/mozilla/cerberus/">Cerberus</a>, an anomaly detection tool that detects and alerts developers of changes in the distributions. Originally the sole purpose of the Telemetry pipeline was to feed data into this dashboard but in time its scope and flexibility grew to support more general use-cases.</p>
<p><img src="concepts/pipeline/../../assets/TMO_example.jpeg" alt="TMO" title="TMO  timeseries" /></p>
<h1><a class="header" href="#presto--redash" id="presto--redash">Presto &amp; re:dash</a></h1>
<p>We maintain a couple of <a href="https://github.com/mozilla/emr-bootstrap-presto">Presto clusters</a> and a centralized Hive metastore to query Parquet data with SQL. The Hive metastore provides an universal view of our Parquet dataset to both Spark and Presto clusters.</p>
<p>Presto, and other databases, are behind a <a href="https://sql.telemetry.mozilla.org/">re:dash</a> service (<a href="https://sql.telemetry.mozilla.org/">STMO</a>) which provides a convenient &amp; powerful interface to query SQL engines and build dashboards that can be shared within the company. Mozilla maintains its own <a href="https://github.com/mozilla/redash">fork of re:dash</a> to iterate quickly on new features, but as good open source citizen we push our changes upstream.</p>
<p><img src="concepts/pipeline/../../assets/STMO_example.jpeg" alt="STMO" title="STMO  who doesnt love SQL?" /></p>
<h1><a class="header" href="#is-that-it" id="is-that-it">Is that it?</a></h1>
<p>No, not really. If you want to read more, check out <a href="concepts/pipeline/data_pipeline_detail.html">this article</a>. For example, the DWL pushes some of the Telemetry data to Redshift and other tools that satisfy more niche needs. The pipeline ingests logs from services as well and there are many specialized dashboards out there I havent mentioned.</p>
<p>There is a vast ecosystem of tools for processing data at scale, each with their pros &amp; cons. The pipeline grew organically and we added new tools as new use-cases came up that we couldnt solve with our existing stack. There are still scars left from that growth though which require some effort to get rid of, like ingesting data from schema-less format.</p>
<h1><a class="header" href="#a-detailed-look-at-the-data-platform" id="a-detailed-look-at-the-data-platform">A Detailed Look at the Data Platform</a></h1>
<p>For a more gentle introduction to the data platform, please read the <a href="concepts/pipeline/data_pipeline.html">Pipeline Overview</a> article.</p>
<p>This article goes into more depth about the architecture and flow of data in the platform.</p>
<h2><a class="header" href="#the-entire-platform" id="the-entire-platform">The Entire Platform</a></h2>
<p>The full detail of the platform can get quite complex, but at a high level the structure is fairly simple.</p>
<pre class="mermaid">graph LR
  Producers[Data Producers] --> Ingestion
  Ingestion --> Storage[Long-term Storage]
  Ingestion --> Stream[Stream Processing]
  Stream --> Storage
  Batch[Batch Processing] --> Storage
  Storage --> Batch
  Self[Self Serve] -.- Stream
  Self -.- Batch
  Stream -.-> Visualization
  Batch -.-> Visualization
  Stream --> Export
  Batch --> Export
</pre>
<p>Each of these high-level parts of the platform are described in more detail below.</p>
<h2><a class="header" href="#data-producers" id="data-producers">Data Producers</a></h2>
<p>By far most data handled by the Data Platform is <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html">produced by Firefox</a>. There are other producers, though, and the eventual aim is to generalize data production using a client SDK or set of standard tools.</p>
<p>Most data is submitted via HTTP POST, but data is also produced in the form of service logs and <code>statsd</code> messages.</p>
<p>If you would like to locally test a new data producer, the <a href="https://github.com/mozilla/gzipServer"><code>gzipServer</code></a> project provides a simplified server that makes it easy to inspect submitted messages.</p>
<h2><a class="header" href="#ingestion-1" id="ingestion-1">Ingestion</a></h2>
<pre class="mermaid">graph LR
  subgraph HTTP
    tee
    lb[Load Balancer]
    mozingest
  end
  subgraph Kafka
    kafka_unvalidated[Kafka unvalidated]
    kafka_validated[Kafka validated]
    zookeeper[ZooKeeper] -.- kafka_unvalidated
    zookeeper -.- kafka_validated
  end
  subgraph Storage
    s3_heka[S3 Heka Protobuf Storage]
    s3_parquet[S3 Parquet Storage]
  end
  subgraph Data Producers
    Firefox --> lb
    more_producers[Other Producers] --> lb
  end

  lb --> tee
  tee --> mozingest
  mozingest --> kafka_unvalidated
  mozingest --> Landfill
  kafka_unvalidated --> dwl[Data Store Loader]
  kafka_validated --> cep[Hindsight CEP]
  kafka_validated --> sparkstreaming[Spark Streaming]
  Schemas -.->|validation| dwl
  dwl --> kafka_validated
  dwl --> s3_heka
  dwl --> s3_parquet
  sparkstreaming --> s3_parquet
</pre>
<p>Data arrives as an HTTP POST of an optionally gzipped payload of JSON. See the common <a href="concepts/pipeline/http_edge_spec.html">Edge Server</a> specification for details.</p>
<p>Submissions hit a load balancer which handles the SSL connection, then forwards to a &quot;tee&quot; server, which may direct some or all submissions to alternate backends. In the past, the tee was used to manage the <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1302265">cutover between different versions of the backend</a> infrastructure. It is implemented as an <a href="http://openresty.org/en/"><code>OpenResty</code></a> plugin.</p>
<p>From there, the <a href="https://github.com/mozilla-services/nginx_moz_ingest"><code>mozingest</code></a> HTTP Server receives submissions from the tee and batches and stores data durably on Amazon S3 as a fail-safe (we call this &quot;Landfill&quot;). Data is then passed along via <a href="https://kafka.apache.org/">Kafka</a> for validation and further processing. If there is a problem with decoding, validation, or any of the code described in the rest of this section, data can be re-processed from this fail-safe store. The <code>mozingest</code> server is implemented as an <code>nginx</code> module.</p>
<p>Validation, at a minimum, ensures that a payload is valid JSON (possibly compressed). Many document types also have a <a href="https://github.com/mozilla-services/mozilla-pipeline-schemas">JSONSchema specification</a>, and are further validated against that.</p>
<p>Invalid messages are redirected to a separate &quot;errors&quot; stream for debugging and inspection.</p>
<p>Valid messages proceed for further decoding and processing. This involves things like doing GeoIP lookup and discarding the IP address, and attaching some HTTP header info as annotated metadata.</p>
<p>Validated and annotated messages become available for stream processing.</p>
<p>They are also batched and stored durably for later batch processing and ad-hoc querying.</p>
<p>See also the &quot;<a href="https://docs.google.com/document/d/1PqiF1rF2fCk_kQuGSwGwildDf4Crg9MJTY44E6N5DSk/edit">generic ingestion</a>&quot; proposal which aims to make ingestion, validation, storage, and querying available as self-serve for platform users.</p>
<h5><a class="header" href="#data-flow-for-valid-submissions" id="data-flow-for-valid-submissions">Data flow for valid submissions</a></h5>
<pre class="mermaid">sequenceDiagram
    participant Fx as Firefox
    participant lb as Load Balancer
    participant mi as mozingest
    participant lf as Landfill
    participant k as Kafka
    participant dwl as Data Store Loader
    participant dl as Data Lake

    Fx->>lb: HTTPS POST
    lb->>mi: forward
    mi-->>lf: failsafe store
    mi->>k: enqueue
    k->>dwl: validate, decode
    dwl->>k: enqueue validated
    dwl->>dl: store durably
</pre>
<h5><a class="header" href="#other-ingestion-methods" id="other-ingestion-methods">Other ingestion methods</a></h5>
<p>Hindsight is used for <a href="https://mozilla-services.github.io/lua_sandbox_extensions/moz_logging/">ingestion of logs</a> from applications and services, it supports parsing of log lines and appending similar metadata as the HTTP ingestion above (timestamp, source, and so on).</p>
<p><a href="https://github.com/etsy/statsd"><code>Statsd</code></a> messages are ingested in the usual way.</p>
<h2><a class="header" href="#storage" id="storage">Storage</a></h2>
<pre class="mermaid">graph TD
  subgraph RDBMS
    PostgreSQL
    Redshift
    MySQL
    BigQuery
  end
  subgraph NoSQL
    DynamoDB
  end
  subgraph S3
    landfill[Landfill]
    s3_heka[Heka Data Lake]
    s3_parquet[Parquet Data Lake]
    s3_analysis[Analysis Outputs]
    s3_public[Public Outputs]
  end

  Ingestion --> s3_heka
  Ingestion --> s3_parquet
  Ingestion --> landfill
  Ingestion -.-> stream[Stream Processing]
  stream --> s3_parquet
  batch[Batch Processing] --> s3_parquet
  batch --> PostgreSQL
  batch --> DynamoDB
  batch --> s3_public
  selfserve[Self Serve] --> s3_analysis
  s3_analysis --> selfserve
  Hive -->|Presto| redash[Re:dash]
  PostgreSQL --> redash
  Redshift --> redash
  MySQL --> redash
  BigQuery --> redash

  s3_parquet -.- Hive
</pre>
<p><a href="https://aws.amazon.com/s3/">Amazon S3</a> forms the backbone of the platform storage layer. The primary format used in the Data Lake is <a href="http://parquet.apache.org/">parquet</a>, which is a strongly typed columnar storage format that can easily be read and written by <a href="https://spark.apache.org/docs/latest/index.html">Spark</a>, as well as being compatible with SQL interfaces such as <a href="https://cwiki.apache.org/confluence/display/Hive/Home">Hive</a> and <a href="http://prestosql.io/">Presto</a>. Some data is also stored in <a href="https://hekad.readthedocs.io/en/dev/message/index.html#stream-framing">Heka-framed protobuf</a> format. This custom format is usually reserved for data where we do not have a complete <a href="https://github.com/mozilla-services/mozilla-pipeline-schemas">JSONSchema specification</a>.</p>
<p>Using S3 for storage avoids the need for an always-on cluster, which means that data at rest is inexpensive. S3 also makes it very easy to automatically expire (delete) objects after a certain period of time, which is helpful for implementing data retention policies.</p>
<p>Once written to S3, the data is typically treated as immutable - data is not appended to existing files, nor is data normally updated in place. The exception here is when data is back-filled, in which case previous data may be overwritten.</p>
<p>There are a number of other types of storage used for more specialized applications, including relational databases (such as PostgreSQL for the <a href="https://github.com/mozilla/python_mozaggregator/#api">Telemetry Aggregates</a>) and NoSQL databases (DynamoDB is used for a backing store for the <a href="https://github.com/mozilla/python_mozetl/blob/master/mozetl/taar/taar_dynamo.py">TAAR project</a>). Reading data from a variety of RDBMS sources is also supported via Re:dash.</p>
<p>The data stored in Heka format is <a href="concepts/pipeline/../../tools/spark.html">readable from Spark</a> using libraries in <a href="https://github.com/mozilla/moztelemetry/blob/master/src/main/scala/com/mozilla/telemetry/heka/Dataset.scala">Scala</a> or <a href="https://mozilla.github.io/python_moztelemetry/api.html#dataset">Python</a>.</p>
<p>Parquet data can be read and written natively from Spark, and many datasets are indexed in a <a href="https://cwiki.apache.org/confluence/display/Hive/Home">Hive</a> Metastore, making them available through a SQL interface on Re:dash and in notebooks via Spark SQL. Many other SQL data sources are also made available via Re:dash, see <a href="concepts/pipeline/../../tools/stmo.html">this article</a> for more information on accessing data using SQL.</p>
<p>There is a separate data store for self-serve <strong>Analysis Outputs</strong>, intended to keep ad-hoc, temporary data out of the Data Lake. This is implemented as a separate S3 location, with personal output locations prefixed with each person's user id, similar to the layout of the <code>/home</code> directory on a Unix system.</p>
<p>Analysis outputs can also be made public using the <strong>Public Outputs</strong> bucket. This is a web-accessible S3 location for powering public dashboards. This public data is available at <code>https://analysis-output.telemetry.mozilla.org/&lt;job name&gt;/data/&lt;files&gt;</code>.</p>
<h2><a class="header" href="#stream-processing" id="stream-processing">Stream Processing</a></h2>
<p>Stream processing is done using <a href="https://github.com/mozilla-services/hindsight">Hindsight</a> and <a href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html">Spark Streaming</a>.</p>
<p>Hindsight allows you to run <a href="http://mozilla-services.github.io/lua_sandbox/">plugins written in Lua inside a sandbox</a>. This gives a safe, performant way to do self-serve streaming analysis. See <a href="concepts/pipeline/../../cookbooks/realtime_analysis_plugin.html">this article</a> for an introduction. Hindsight plugins do the initial data validation and decoding, as well as writing out to long-term storage in both <a href="https://hekad.readthedocs.io/en/dev/message/index.html#stream-framing">Heka-framed protobuf</a> and <a href="https://mozilla-services.github.io/lua_sandbox_extensions/parquet/">parquet</a> forms.</p>
<p>Spark Streaming is used to read from Kafka and perform <a href="https://github.com/mozilla/telemetry-streaming">low-latency ETL and aggregation tasks</a>. These aggregates are currently used by <a href="https://data-missioncontrol.dev.mozaws.net">Mission Control</a> and are also available for querying via <a href="https://sql.telemetry.mozilla.org">Re:dash</a>.</p>
<h2><a class="header" href="#batch-processing" id="batch-processing">Batch Processing</a></h2>
<p>Batch processing is done using <a href="https://spark.apache.org/docs/latest/index.html">Spark</a>. Production ETL code is written in both <a href="https://github.com/mozilla/python_mozetl">Python</a> and <a href="https://github.com/mozilla/telemetry-batch-view">Scala</a>.</p>
<p>There are <a href="https://mozilla.github.io/python_moztelemetry/api.html#dataset">Python</a> and <a href="https://github.com/mozilla/moztelemetry/blob/master/src/main/scala/com/mozilla/telemetry/heka/Dataset.scala">Scala</a> libraries for reading data from the Data Lake in <a href="https://hekad.readthedocs.io/en/dev/message/index.html#stream-framing">Heka-framed protobuf</a> form, though it is much easier and more performant to make use of a <a href="concepts/pipeline/../../concepts/choosing_a_dataset.html">derived dataset</a> whenever possible.</p>
<p>Datasets in parquet format can be read natively by Spark, either using Spark SQL or by reading data directly from S3.</p>
<p>Data produced by production jobs go into the Data Lake, while output from ad-hoc jobs go into Analysis Outputs.</p>
<p>Job scheduling and dependency management is done using <a href="https://github.com/mozilla/telemetry-airflow">Airflow</a>. Most jobs run once a day, processing data from &quot;yesterday&quot; on each run. A typical job launches a cluster, which fetches the specified ETL code as part of its bootstrap on startup, runs the ETL code, then shuts down upon completion. If something goes wrong, a job may time out or fail, and in this case it is retried automatically.</p>
<h2><a class="header" href="#self-serve-data-analysis" id="self-serve-data-analysis">Self Serve Data Analysis</a></h2>
<pre class="mermaid">graph TD
  subgraph Storage
    lake[Data Lake]
    s3_output_public[Public Outputs]
    s3_output_private[Analysis Outputs]
  end
  subgraph STMO
    redash[Re:dash] -->|read| lake
  end
  subgraph TMO
    evo[Evolution Dashboard]
    histo[Histogram Dashboard]
    agg[Telemetry Aggregates]
    evo -.- agg
    histo -.- agg
  end
  subgraph Databricks
    db_notebook[Notebook]
    db_notebook -->|read + write| lake
  end
</pre>
<p>Most of the data analysis tooling has been developed with the goal of being &quot;self-serve&quot;. This means that people should be able to access and analyze data on their own, without involving data engineers or operations. Thus can data access scale beyond a small set of people with specialized knowledge of the entire pipeline.</p>
<p>The use of these self-serve tools is described in the <a href="concepts/pipeline/../../concepts/analysis_intro.html">Getting Started</a> article. This section focuses on how these tools integrate with the platform infrastructure.</p>
<h5><a class="header" href="#stmo-sql-analysis" id="stmo-sql-analysis">STMO: SQL Analysis</a></h5>
<p><a href="concepts/pipeline/../../tools/stmo.html">STMO</a> is a customized <a href="https://sql.telemetry.mozilla.org">Re:dash</a> installation that provides self-serve access to a a variety of different <a href="concepts/pipeline/../../concepts/choosing_a_dataset.html">datasets</a>. From here, you can query data in the Parquet Data Lake as well as various RDBMS data sources.</p>
<p>STMO interfaces with the data lake using both <a href="http://prestosql.io/">Presto</a> and Amazon <a href="https://aws.amazon.com/athena/">Athena</a>. Each has its own data source in Re:dash. Since Athena does not support user-defined functions, datasets with HyperLogLog columns, such as <a href="concepts/pipeline/../../datasets/obsolete/client_count_daily/reference.html"><code>client_count_daily</code></a>, are only available via Presto..</p>
<p>Different <strong>Data Sources</strong> in STMO connect to different backends, and each backend might use a slightly different flavor of SQL. You should find a link to the documentation for the expected SQL variant next to the Data Sources list.</p>
<p>Queries can be run just once, or scheduled to run periodically to keep data up-to-date.</p>
<p>There is a command-line interface to STMO called <a href="https://github.com/mozilla/stmocli">St. Mocli</a>, if you prefer writing SQL using your own editor and tools.</p>
<h5><a class="header" href="#databricks-managed-spark-analysis" id="databricks-managed-spark-analysis">Databricks: Managed Spark Analysis</a></h5>
<p>Our <a href="https://dbc-caf9527b-e073.cloud.databricks.com">Databricks instance</a> (see <a href="https://docs.databricks.com/user-guide/notebooks/index.html">Databricks docs</a>) offers another notebook interface for doing analysis in Scala, SQL, Python and R.</p>
<p>Databricks provides an always-on shared server which is nice for quick data investigations.</p>
<h5><a class="header" href="#atmo-deprecated-spark-analysis" id="atmo-deprecated-spark-analysis">ATMO (deprecated): Spark Analysis</a></h5>
<p><a href="concepts/pipeline/BROKEN:https://analysis.telemetry.mozilla.org">ATMO</a> was a service for managing Spark clusters for data analysis on AWS. It was deprecated in Q3 2019 and removed in Q4.</p>
<h5><a class="header" href="#tmo-aggregate-graphs" id="tmo-aggregate-graphs">TMO: Aggregate Graphs</a></h5>
<p><a href="https://telemetry.mozilla.org">TMO</a> provides easy visualizations of histogram and scalar measures over time. Time can be in terms of either builds or submission dates. This is the most convenient interface to the Telemetry data, as it does not require any custom code.</p>
<h2><a class="header" href="#visualization" id="visualization">Visualization</a></h2>
<p>There are a number of visualization libraries and tools being used to display data.</p>
<h5><a class="header" href="#tmo-dashboards" id="tmo-dashboards">TMO Dashboards</a></h5>
<p>The landing page at <a href="https://telemetry.mozilla.org"><code>telemetry.mozilla.org</code></a> is a good place to look for existing graphs, notably the <a href="https://telemetry.mozilla.org/new-pipeline/dist.html">measurement dashboard</a> which gives a lot of information about histogram and scalar measures collected on pre-release channels.</p>
<h5><a class="header" href="#notebooks" id="notebooks">Notebooks</a></h5>
<p>Use of interactive notebooks has become a standard in the industry, and Mozilla makes heavy use of this approach. Databricks makes it easy to run, share, and schedule notebooks.</p>
<h5><a class="header" href="#others" id="others">Others</a></h5>
<p><a href="https://sql.telemetry.mozilla.org">Re:dash</a> lets you query the data using SQL, but it also supports a number of useful visualizations.</p>
<p><a href="http://pipeline-cep.prod.mozaws.net/">Hindsight's web interface</a> has the ability to visualize time-series data.</p>
<p><a href="https://data-missioncontrol.dev.mozaws.net">Mission Control</a> gives a low-latency view into release health.</p>
<p>Many bespoke visualizations are built using the <a href="http://metricsgraphicsjs.org/">Metrics Graphics</a> library as a display layer.</p>
<h2><a class="header" href="#monitoring-and-alerting" id="monitoring-and-alerting">Monitoring and Alerting</a></h2>
<p>There are multiple layers of monitoring and alerting.</p>
<p>At a low level, the system is monitored to ensure that it is functioning as expected. This includes things like machine-level resources (network capacity, disk space, available RAM, CPU load) which are typically monitored using <a href="http://datadoghq.com/">DataDog</a>.</p>
<p>Next, we monitor the &quot;transport&quot; functionality of the system. This includes monitoring incoming submission rates, payload sizes, traffic patterns, schema validation failure rates, and alerting if anomalies are detected. This type of anomaly detection and alerting is handled by <a href="https://github.com/mozilla-services/hindsight">Hindsight</a>.</p>
<p>Once data has been safely ingested and stored, we run some automatic regression detection on all Telemetry <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/histograms.html">histogram measures</a> using <a href="https://github.com/mozilla/cerberus">Cerberus</a>. This code looks for changes in the distribution of a measure, and emails probe owners if a significant change is observed.</p>
<p>Production ETL jobs are run via <a href="https://github.com/mozilla/telemetry-airflow">Airflow</a>, which monitors batch job progress and alerts if there are failures in any job. Self-serve batch jobs running via Databricks also generate alerts upon failure.</p>
<p>Scheduled <a href="https://sql.telemetry.mozilla.org">Re:dash</a> queries may also be configured to generate alerts, which is used to monitor the last-mile user facing status of derived datasets. Re:dash may also be used to monitor and alert on high-level characteristics of the data, or really anything you can think of.</p>
<h2><a class="header" href="#data-exports" id="data-exports">Data Exports</a></h2>
<p>Data is exported from the pipeline to a few other tools and systems. Examples include integration with <a href="https://amplitude.com/">Amplitude</a> for mobile and product analytics and shipping data to other parts of the Mozilla organization.</p>
<p>There are also a few data sets which are made publicly available, such as the <a href="https://hardware.metrics.mozilla.com/">Firefox Hardware Report</a>.</p>
<h2><a class="header" href="#bringing-it-all-together" id="bringing-it-all-together">Bringing it all together</a></h2>
<p>Finally, here is a more detailed view of the entire platform. Some connections are omitted for clarity.</p>
<pre class="mermaid">graph LR
 subgraph Data Producers
  Firefox
  more_producers[...]
 end
 subgraph Storage
  Landfill
  warehouse_heka[Heka Data Lake]
  warehouse_parquet[Parquet Data Lake]
  warehouse_analysis[Analysis Outputs]
  PostgreSQL
  Redshift
  MySQL
  hive[Hive] -.- warehouse_parquet
 end
 subgraph Stream Processing
  cep[Hindsight Streaming]
  dwl[Data Store Loader] --> warehouse_heka
  dwl --> warehouse_parquet
  sparkstreaming[Spark Streaming] --> warehouse_parquet
 end
 subgraph Ingestion
  Firefox --> lb[Load Balancer]
  more_producers --> lb
  lb --> tee
  tee --> mozingest
  mozingest --> kafka
  mozingest --> Landfill
  ZooKeeper -.- kafka[Kafka]
  kafka --> dwl
  kafka --> cep
  kafka --> sparkstreaming
 end
 subgraph Batch Processing
  Airflow -.->|spark|tbv[telemetry-batch-view]
  Airflow -.->|spark|python_mozetl
  warehouse_heka --> tbv
  warehouse_parquet --> tbv
  warehouse_heka --> python_mozetl
  warehouse_parquet --> python_mozetl
  tmo_agg[Telemetry Aggregates]
 end
 subgraph Visualization
  Hindsight
  Jupyter
  Zeppelin
  TMO
  redash_graphs[Re:dash]
  MissionControl
  bespoke_viz[Bespoke Viz]
 end
 subgraph Export
  tbv --> Amplitude
  sparkstreaming --> Amplitude
 end
 subgraph Self Serve
  redash[Re:dash] -.-> Presto
  Presto --> hive
  redash -.-> Athena
  Athena --> hive
  warehouse_heka --> spcluster
  warehouse_parquet --> spcluster
  spcluster --> warehouse_analysis
 end
 Schemas -.->|validation| dwl
</pre>
<h2><a class="header" href="#mozilla-firefox-data-analysis-tools" id="mozilla-firefox-data-analysis-tools">Mozilla Firefox Data Analysis Tools</a></h2>
<p>This is a starting point for making sense of (and gaining access to) all of the
Firefox-related data analysis tools. There are a number of different tools
available, all with their own strengths, tailored to a variety of use cases and
skill sets.</p>
<h4><a class="header" href="#a-hreftoolsstmohtmlsqltelemetrymozillaorga-stmo" id="a-hreftoolsstmohtmlsqltelemetrymozillaorga-stmo"><a href="tools/stmo.html"><code>sql.telemetry.mozilla.org</code></a> (STMO)</a></h4>
<p>The <a href="https://sql.telemetry.mozilla.org"><code>sql.telemetry.mozilla.org</code></a> (STMO) site
is an instance of the very fine <a href="https://redash.io/">Re:dash</a> software, allowing
for SQL-based exploratory analysis and visualization / dashboard
construction. Requires (surprise!) familiarity with SQL, and for your data to
be explicitly exposed as an STMO data source. Bugs or feature requests can be
reported in our <a href="https://github.com/mozilla/redash/issues">issue tracker</a>.</p>
<h4><a class="header" href="#a-hreftoolssparkhtmlanalysistelemetrymozillaorga-atmo" id="a-hreftoolssparkhtmlanalysistelemetrymozillaorga-atmo"><a href="tools/spark.html"><code>analysis.telemetry.mozilla.org</code></a> (ATMO)</a></h4>
<p><strong>As of 2019-11-08, ATMO is obsolete and has been decommissioned. Instead,
use STMO or Databricks for analysis.</strong></p>
<h4><a class="header" href="#a-hrefhttpsdbc-caf9527b-e073clouddatabrickscomdatabricksa" id="a-hrefhttpsdbc-caf9527b-e073clouddatabrickscomdatabricksa"><a href="https://dbc-caf9527b-e073.cloud.databricks.com/">Databricks</a></a></h4>
<p>Offers notebook interface with shared, always-on, autoscaling cluster
(attaching your notebooks to <code>shared_serverless_python3</code> is the best way to start).
Convenient for quick data investigations. Users can get help on <code>#databricks</code>
channel on IRC and are advised to join the
<a href="https://groups.google.com/a/mozilla.com/forum/#!forum/databricks-discuss"><code>databricks-discuss@mozilla.com</code></a> group.</p>
<h4><a class="header" href="#a-hreftoolsconceptsanalysis_introhtmltelemetrymozillaorga-tmo" id="a-hreftoolsconceptsanalysis_introhtmltelemetrymozillaorga-tmo"><a href="tools/../concepts/analysis_intro.html"><code>telemetry.mozilla.org</code></a> (TMO)</a></h4>
<p>Our <a href="https://telemetry.mozilla.org"><code>telemetry.mozilla.org</code></a> (TMO) site is the
'venerable standby' of Firefox telemetry analysis tools. It uses aggregate
telemetry data (as opposed to the collated data sets that are exposed to most
of the other tools) so it provides less latency than most but is unsuitable for
examining at the individual client level. It provides a powerful UI that allows
for sophisticated ad-hoc analysis without the need for any specialized
programming skills, but with so many options the UI can be a bit intimidating
for novice users.</p>
<h2><a class="header" href="#introduction-1" id="introduction-1">Introduction</a></h2>
<p><a href="https://spark.apache.org/">Apache Spark</a>
is a data processing engine designed to be fast and easy to use.</p>
<p>Spark can be used either from <a href="https://dbc-caf9527b-e073.cloud.databricks.com/#notebook/30598/command/30599">Databricks</a> or Dataproc, and works
with data stored in BigQuery.</p>
<p>The <a href="tools/../cookbooks/bigquery.html#from-spark">BigQuery cookbook</a> covers how to access
BigQuery data from Spark.</p>
<h2><a class="header" href="#notebooks-1" id="notebooks-1">Notebooks</a></h2>
<p>Notebooks can be easily shared and updated among colleagues
and, when combined with Spark, enable richer analysis than SQL alone.</p>
<p>Databricks has its own custom notebook environment, which has built-in
support for sharing, scheduling, collaboration, and commenting.</p>
<p>Dataproc uses standard <a href="https://jupyter.org/">Jupyter notebooks</a>.</p>
<h3><a class="header" href="#sharing-a-jupyter-notebook" id="sharing-a-jupyter-notebook">Sharing a Jupyter Notebook</a></h3>
<p>Jupyter notebooks can be shared in a few different ways.</p>
<h4><a class="header" href="#sharing-a-static-notebook" id="sharing-a-static-notebook">Sharing a Static Notebook</a></h4>
<p>An easy way to share is using a gist on Github. Jupyter notebook files checked
in to a Github repository will be rendered in the Github web UI, which makes
sharing convenient.</p>
<p>You can also upload the <code>.ipynb</code> file as a gist to share with your colleagues.</p>
<h2><a class="header" href="#using-spark" id="using-spark">Using Spark</a></h2>
<p>Spark is a general-purpose cluster computing system - it allows users to
run general execution graphs. APIs are available in Python, Scala, R, and
Java. The Jupyter notebook utilizes the Python API. In a nutshell, it
provides a way to run functional code (e.g. map, reduce, etc.) on large,
distributed data.</p>
<p>Check out
<a href="https://robertovitillo.com/2015/06/30/spark-best-practices/">Spark Best Practices</a>
for tips on using Spark to its full capabilities.</p>
<p>Other useful introductory materials:</p>
<ul>
<li><a href="https://spark.apache.org/docs/latest/programming-guide.html">Spark Programming Guide</a></li>
<li><a href="https://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL Programming Guide</a></li>
</ul>
<h3><a class="header" href="#reading-data-from-bigquery-into-spark" id="reading-data-from-bigquery-into-spark">Reading data from BigQuery into Spark</a></h3>
<p>There are two main ways to read data from BigQuery into Spark.</p>
<h4><a class="header" href="#storage-api" id="storage-api">Storage API</a></h4>
<p>First, using the Storage API - this bypasses BigQuery's execution engine and
directly reads from the underlying storage.</p>
<p>This is the preferred method of loading data from BigQuery into Spark.</p>
<p>It is more efficient for reading large amounts of data into Spark, and
supports basic column and partitioning filters.</p>
<p>Example of using the Storage API from Databricks:</p>
<pre><code class="language-python">dbutils.library.installPyPI(&quot;google-cloud-bigquery&quot;, &quot;1.16.0&quot;)
dbutils.library.restartPython()

# Read one day of pings and select a subset of columns.
core_pings_single_day = spark.read.format(&quot;bigquery&quot;) \
    .option(&quot;table&quot;, &quot;moz-fx-data-shared-prod.telemetry_stable.core_v10&quot;) \
    .load() \
    .where(&quot;submission_timestamp &gt;= to_date('2019-08-25') submission_timestamp &lt; to_date('2019-08-26')&quot;) \
    .select(&quot;client_id&quot;, &quot;experiments&quot;, &quot;normalized_channel&quot;)
</code></pre>
<p>A couple of things are worth noting in the above example.</p>
<ul>
<li>You must supply an actual <em>table</em> name to read from here, fully qualified
with project name and dataset name.
The Storage API does not support accessing <code>VIEW</code>s, so the convenience names
such as <code>telemetry.core</code> are not available via this API.
You can find the table corresponding to a given view using the BigQuery
console or using Data Catalog.</li>
<li>You must supply a filter on the table's date partitioning column, in this
case <code>submission_timestamp</code>.
Additionally, you must use the <code>to_date</code> function to make sure that predicate
push-down works properly for these filters.</li>
</ul>
<h4><a class="header" href="#query-api" id="query-api">Query API</a></h4>
<p>If you want to read the results of a query (rather than directly reading
tables), you may also use the Query API.</p>
<p>This pushes the execution of the query into BigQuery's computation engine,
and is typically suitable for reading smaller amounts of data. If you need
to read large amounts of data, prefer the Storage API as described above.</p>
<p>Example:</p>
<pre><code class="language-python">
from google.cloud import bigquery

bq = bigquery.Client()

query = &quot;&quot;&quot;
SELECT
  event_string_value,
  count(distinct client_id) AS client_count
FROM
  `moz-fx-data-derived-datasets.telemetry.events`
WHERE
  event_category = 'normandy'
  AND event_method = 'enroll'
  AND submission_date_s3 = '2019-06-01'
GROUP BY
  event_string_value
ORDER BY
  client_count DESC
LIMIT 20
&quot;&quot;&quot;
query_job = bq.query(query)
# Wait for query execution, then fetch results as a pandas dataframe.
rows = query_job.result().to_dataframe()

</code></pre>
<h3><a class="header" href="#persisting-data" id="persisting-data">Persisting data</a></h3>
<p>You can save data resulting from your Spark analysis as a <a href="tools/../cookbooks/bigquery.html#writing-query-results-to-a-permanent-table">BigQuery table</a>
or to <a href="tools/../cookbooks/bigquery.html#writing-results-to-gcs-object-store">Google Cloud Storage</a>.</p>
<p>You can also save data to the <a href="https://docs.databricks.com/user-guide/databricks-file-system.html#dbfs">Databricks Filesystem</a>.</p>
<h2><a class="header" href="#faq" id="faq">FAQ</a></h2>
<p>Please add more FAQ as questions are answered by you or for you.</p>
<h3><a class="header" href="#i-got-a-remote-host-identification-has-changed-error" id="i-got-a-remote-host-identification-has-changed-error">I got a REMOTE HOST IDENTIFICATION HAS CHANGED! error</a></h3>
<p>Cloud providers recycles hostnames, so this warning is expected.
Removing the offending key from <code>$HOME/.ssh/known_hosts</code> will remove the warning.
You can find the line to remove by finding the line in the output that says</p>
<p><code>Offendingkeyin/path/to/hosts/known_hosts:2</code></p>
<p>Where 2 is the line number of the key that can be deleted.
Just remove that line, save the file, and try again.</p>
<h3><a class="header" href="#why-is-my-notebook-hanging" id="why-is-my-notebook-hanging">Why is my notebook hanging?</a></h3>
<p>There are a few common causes for this:</p>
<ol>
<li>Currently, our Spark notebooks can only run a single Python kernel at
a time. If you open multiple notebooks on the same cluster and try to
run both, the second notebook will hang. Be sure to close notebooks
using &quot;Close and Halt&quot; under the &quot;File&quot; drop-down.</li>
<li>The connection from PySpark to the Spark driver might be lost.
Unfortunately the best way to recover from this for the moment seems to
be spinning up a new cluster.</li>
<li>Cancelling execution of a notebook cell doesn't cancel any spark jobs
that might be running in the background. If your spark commands seem to
be hanging, try running <code>sc.cancelAllJobs()</code>.</li>
</ol>
<h3><a class="header" href="#how-can-i-keep-running-after-closing-the-notebook" id="how-can-i-keep-running-after-closing-the-notebook">How can I keep running after closing the notebook?</a></h3>
<p>For long-running computation, it might be nice to close the notebook
(and the SSH session) and look at the results later.
Unfortunately, <strong>all cell output will be lost when a notebook is closed</strong>
(for the running cell).
To alleviate this, there are a few options:</p>
<ol>
<li>Have everything output to a variable. These values should still be
available when you reconnect.</li>
<li>Put %%capture at the beginning of the cell to store all output.
<a href="https://ipython.org/ipython-doc/3/interactive/magics.html#cellmagic-capture">See the documentation</a>.</li>
</ol>
<h3><a class="header" href="#how-do-i-load-an-external-library-into-the-cluster" id="how-do-i-load-an-external-library-into-the-cluster">How do I load an external library into the cluster?</a></h3>
<p>Assuming you've got a URL for the repo, you can create an egg for it
this way:</p>
<pre><code class="language-python">!gitclone`&lt;repo url&gt;`&amp;&amp;cd`&lt;repo-name&gt;`&amp;&amp;pythonsetup.pybdist_egg`\
sc.addPyFile('`&lt;repo-name&gt;`/dist/my-egg-file.egg')`
</code></pre>
<p>Alternately, you could just create that egg locally, upload it to a web
server, then download and install it:</p>
<pre><code class="language-python">importrequests`\
r=requests.get('`&lt;url-to-my-egg-file&gt;`')`\
withopen('mylibrary.egg','wb')asf:`\
f.write(r.content)`\
sc.addPyFile('mylibrary.egg')`
</code></pre>
<p>You will want to do this <strong>before</strong> you load the library. If the library
is already loaded, restart the kernel in the Jupyter notebook.</p>
<h1><a class="header" href="#sql-style-guide" id="sql-style-guide">SQL Style Guide</a></h1>
<h2><a class="header" href="#table-of-contents-1" id="table-of-contents-1">Table of Contents</a></h2>
<ul>
<li><a href="concepts/sql_style.html#consistency">Consistency</a></li>
<li><a href="concepts/sql_style.html#reserved-words">Reserved Words</a></li>
<li><a href="concepts/sql_style.html#variable-names">Variable Names</a></li>
<li><a href="concepts/sql_style.html#be-explicit">Be Explicit</a>
<ul>
<li><a href="concepts/sql_style.html#aliasing">Aliasing</a></li>
<li><a href="concepts/sql_style.html#joins">Joins</a></li>
<li><a href="concepts/sql_style.html#grouping-columns">Grouping Columns</a></li>
</ul>
</li>
<li><a href="concepts/sql_style.html#left-align-root-keywords">Left Align Root Keywords</a></li>
<li><a href="concepts/sql_style.html#code-blocks">Code Blocks</a></li>
<li><a href="concepts/sql_style.html#parentheses">Parentheses</a></li>
<li><a href="concepts/sql_style.html#boolean-at-the-beginning-of-line">Boolean at the Beginning of Line</a></li>
<li><a href="concepts/sql_style.html#nested-queries">Nested Queries</a></li>
<li><a href="concepts/sql_style.html#about-this-document">About this Document</a></li>
</ul>
<h2><a class="header" href="#consistency" id="consistency">Consistency</a></h2>
<p>From <a href="https://www.python.org/dev/peps/pep-0008/#a-foolish-consistency-is-the-hobgoblin-of-little-minds">Pep8</a>:</p>
<blockquote>
<p>A style guide is about consistency.
Consistency with this style guide is important.
Consistency within a project is more important.
Consistency within one module or function is the most important.</p>
<p>However, know when to be inconsistent --
sometimes style guide recommendations just aren't applicable.
When in doubt, use your best judgment.
Look at other examples and decide what looks best.
And don't hesitate to ask!</p>
</blockquote>
<h2><a class="header" href="#reserved-words" id="reserved-words">Reserved Words</a></h2>
<p>Always use uppercase for reserved keywords like <code>SELECT</code>, <code>WHERE</code>, or <code>AS</code>.</p>
<h2><a class="header" href="#variable-names" id="variable-names">Variable Names</a></h2>
<ol>
<li>Use consistent and descriptive identifiers and names.</li>
<li>Use lower case names with underscores, such as <code>first_name</code>.
Do not use CamelCase.</li>
<li>Functions, such as <code>cardinality</code>, <code>approx_distinct</code>, or <code>substr</code>,
<a href="https://www.postgresql.org/docs/10/static/sql-syntax-lexical.html#SQL-SYNTAX-IDENTIFIERS">are identifiers</a>
and should be treated like variable names.</li>
<li>Names must begin with a letter and may not end in an underscore.</li>
<li>Only use letters, numbers, and underscores in variable names.</li>
</ol>
<h2><a class="header" href="#be-explicit" id="be-explicit">Be Explicit</a></h2>
<p>When choosing between explicit or implicit syntax, prefer explicit.</p>
<h3><a class="header" href="#aliasing" id="aliasing">Aliasing</a></h3>
<p>Always include the <code>AS</code> keyword when aliasing a variable or table name,
it's easier to read when explicit.</p>
<p><strong>Good</strong></p>
<pre><code class="language-sql">SELECT
  date(submission_timestamp) AS day
FROM
  telemetry.main
LIMIT
  10
</code></pre>
<p><strong>Bad</strong></p>
<pre><code class="language-sql">SELECT
  date(submission_timestamp) day
FROM
  telemetry.main
LIMIT
  10
</code></pre>
<h3><a class="header" href="#joins" id="joins">Joins</a></h3>
<p>Always include the <code>JOIN</code> type rather than relying on the default join.</p>
<p><strong>Good</strong></p>
<pre><code class="language-sql">-- BigQuery Standard SQL Syntax
SELECT
  submission_date,
  experiment.key AS experiment_id,
  experiment.value AS experiment_branch,
  count(*) AS count
FROM
  telemetry.clients_daily
CROSS JOIN
  UNNEST(experiments.key_value) AS experiment
WHERE
  submission_date &gt; '2019-07-01'
  AND sample_id = '10'
GROUP BY
  submission_date,
  experiment_id,
  experiment_branch
</code></pre>
<p><strong>Bad</strong></p>
<pre><code class="language-sql">-- BigQuery Standard SQL Syntax
SELECT
  submission_date,
  experiment.key AS experiment_id,
  experiment.value AS experiment_branch,
  count(*) AS count
FROM
  telemetry.clients_daily,
  UNNEST(experiments.key_value) AS experiment -- Implicit JOIN
WHERE
  submission_date &gt; '2019-07-01'
  AND sample_id = '10'
GROUP BY
  1, 2, 3 -- Implicit grouping column names
</code></pre>
<h3><a class="header" href="#grouping-columns" id="grouping-columns">Grouping Columns</a></h3>
<p>In the previous example, implicit grouping columns were discouraged, but there are cases where it makes sense.</p>
<p>In some SQL flavors (such as <a href="https://prestodb.github.io/docs/current/sql/select.html">Presto</a>) grouping elements must refer to the expression before any aliasing is done. If you are grouping by a complex expression it may be desirable to use implicit grouping columns rather than repeating the expression.</p>
<p><strong>Good</strong></p>
<pre><code class="language-sql">-- BigQuery SQL Syntax
SELECT
  submission_date,
  normalized_channel IN ('nightly', 'aurora', 'beta') AS is_prerelease,
  count(*) AS count
FROM
  telemetry.clients_daily
WHERE
  submission_date &gt; '2019-07-01'
GROUP BY
  submission_date,
  is_prerelease -- Grouping by aliases is supported in BigQuery
</code></pre>
<p><strong>Good</strong></p>
<pre><code class="language-sql">-- Presto SQL Syntax
SELECT
  submission_date,
  normalized_channel IN ('nightly', 'aurora', 'beta') AS is_prerelease,
  count(*) AS count
FROM
  telemetry.clients_daily
WHERE
  submission_date &gt; '20190701'
GROUP BY
  1, 2 -- Implicit grouping avoids repeating expressions
</code></pre>
<p><strong>Bad</strong></p>
<pre><code class="language-sql">-- Presto SQL Syntax
SELECT
  submission_date,
  normalized_channel IN ('nightly', 'aurora', 'beta') AS is_prerelease,
  count(*) AS count
FROM
  telemetry.clients_daily
WHERE
  submission_date &gt; '20190701'
GROUP BY
  submission_date,
  normalized_channel IN ('nightly', 'aurora', 'beta')
</code></pre>
<h2><a class="header" href="#left-align-root-keywords" id="left-align-root-keywords">Left Align Root Keywords</a></h2>
<p>Root keywords should all start on the same character boundary.
This is counter to the common &quot;rivers&quot; pattern
<a href="https://www.sqlstyle.guide/#spaces">described here</a>.</p>
<p><strong>Good</strong>:</p>
<pre><code class="language-sql">SELECT
  client_id,
  submission_date
FROM
  main_summary
WHERE
  sample_id = '42'
  AND submission_date &gt; '20180101'
LIMIT
  10
</code></pre>
<p><strong>Bad</strong>:</p>
<pre><code class="language-sql">SELECT client_id,
       submission_date
  FROM main_summary
 WHERE sample_id = '42'
   AND submission_date &gt; '20180101'
</code></pre>
<h2><a class="header" href="#code-blocks" id="code-blocks">Code Blocks</a></h2>
<p>Root keywords should be on their own line.
For example:</p>
<p><strong>Good</strong>:</p>
<pre><code class="language-sql">SELECT
  client_id,
  submission_date
FROM
  main_summary
WHERE
  submission_date &gt; '20180101'
  AND sample_id = '42'
LIMIT
  10
</code></pre>
<p>It's acceptable to include an argument on the same line as the root keyword,
if there is exactly one argument.</p>
<p><strong>Acceptable</strong>:</p>
<pre><code class="language-sql">SELECT
  client_id,
  submission_date
FROM main_summary
WHERE
  submission_date &gt; '20180101'
  AND sample_id = '42'
LIMIT 10
</code></pre>
<p>Do not include multiple arguments on one line.</p>
<p><strong>Bad</strong>:</p>
<pre><code class="language-sql">SELECT client_id, submission_date
FROM main_summary
WHERE
  submission_date &gt; '20180101'
  AND sample_id = '42'
LIMIT 10
</code></pre>
<p><strong>Bad</strong></p>
<pre><code class="language-sql">SELECT
  client_id,
  submission_date
FROM main_summary
WHERE submission_date &gt; '20180101'
  AND sample_id = '42'
LIMIT 10
</code></pre>
<h2><a class="header" href="#parentheses" id="parentheses">Parentheses</a></h2>
<p>If parentheses span multiple lines:</p>
<ol>
<li>The opening parenthesis should terminate the line.</li>
<li>The closing parenthesis should be lined up under
the first character of the line that starts the multi-line construct.</li>
<li>The contents of the parentheses should be indented one level.</li>
</ol>
<p>For example:</p>
<p><strong>Good</strong></p>
<pre><code class="language-sql">WITH sample AS (
  SELECT
    client_id,
  FROM
    main_summary
  WHERE
    sample_id = '42'
)
</code></pre>
<p><strong>Bad</strong> (Terminating parenthesis on shared line)</p>
<pre><code class="language-sql">WITH sample AS (
  SELECT
    client_id,
  FROM
    main_summary
  WHERE
    sample_id = '42')
</code></pre>
<p><strong>Bad</strong> (No indent)</p>
<pre><code class="language-sql">WITH sample AS (
SELECT
  client_id,
FROM
  main_summary
WHERE
  sample_id = '42'
)
</code></pre>
<h2><a class="header" href="#boolean-at-the-beginning-of-line" id="boolean-at-the-beginning-of-line">Boolean at the Beginning of Line</a></h2>
<p><code>AND</code> and <code>OR</code> should always be at the beginning of the line.
For example:</p>
<p><strong>Good</strong></p>
<pre><code class="language-sql">...
WHERE
  submission_date &gt; 20180101
  AND sample_id = '42'
</code></pre>
<p><strong>Bad</strong></p>
<pre><code class="language-sql">...
WHERE
  submission_date &gt; 20180101 AND
  sample_id = '42'
</code></pre>
<h2><a class="header" href="#nested-queries" id="nested-queries">Nested Queries</a></h2>
<p>Do not use nested queries.
Instead, use common table expressions to improve readability.</p>
<p><strong>Good</strong>:</p>
<pre><code class="language-sql">WITH sample AS (
  SELECT
    client_id,
    submission_date
  FROM
    main_summary
  WHERE
    sample_id = '42'
)

SELECT *
FROM sample
LIMIT 10
</code></pre>
<p><strong>Bad</strong>:</p>
<pre><code class="language-sql">SELECT *
FROM (
  SELECT
    client_id,
    submission_date
  FROM
    main_summary
  WHERE
    sample_id = '42'
)
LIMIT 10
</code></pre>
<h2><a class="header" href="#about-this-document" id="about-this-document">About this Document</a></h2>
<p>This document was heavily influenced by https://www.sqlstyle.guide/</p>
<p>Changes to the style guide should be reviewed by at least one member of
both the Data Engineering team and the Data Science team.</p>
<h1><a class="header" href="#glean---product-analytics--telemetry" id="glean---product-analytics--telemetry">Glean - product analytics &amp; telemetry</a></h1>
<p>For Mozilla, getting reliable data from our products is critical to inform our decision making. Glean is our new product analytics &amp; telemetry solution that provides that data for our products.
It aims to be easy to integrate, reliable and transparent by providing an SDK and integrated tools.</p>
<p>It currently supports Android products, while iOS support is planned.
Note that this is different from Telemetry for Firefox Desktop (<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/index.html">library</a>, <a href="concepts/glean/../choosing_a_dataset.html">datasets</a>), although it provides similar capabilities.</p>
<p>Contents:</p>
<ul>
<li><a href="concepts/glean/glean.html#overview">Overview</a></li>
<li><a href="concepts/glean/glean.html#what-does-it-offer">What does it offer</a></li>
<li><a href="concepts/glean/glean.html#how-to-use-glean">How to use Glean</a></li>
</ul>
<h1><a class="header" href="#overview-1" id="overview-1">Overview</a></h1>
<p>Glean consists of different pieces:</p>
<ul>
<li>Product-side tools - <a href="https://mozilla.github.io/glean/">the Glean SDK</a> is what products integrate and record data into.</li>
<li>Services - this is where the data is stored and made available for analysis in our data platform.</li>
<li>Data Tools - these are used to look at the data, performing analysis and setting up dashboards.</li>
</ul>
<p><img src="concepts/glean/../../assets/Glean_overview.jpg" alt="drawing" /></p>
<h1><a class="header" href="#what-does-it-offer" id="what-does-it-offer">What does it offer</a></h1>
<p>Glean is designed to support typical product analytics use-cases and encourage best practices by requiring clearly defined metrics through the following:</p>
<p><strong>Basic product analytics are collected out-of-the-box in a standardized way.</strong>
A baseline of analysis is important for all our mobile applications, from counting active users to retention and session times. This is supported out-of-the-box by the library and works consistently across our mobile products.</p>
<p><strong>No custom code is required for adding new metrics to a product.</strong>
To make engineers more productive, the SDK keeps the amount of instrumentation code required for metrics as small as possible. Engineers only need to specify what they want to instrument, with which semantics and then record the data using the Glean SDK. The SDK takes care of storing &amp; sending that data reliably.</p>
<p><strong>Following <a href="https://leandatapractices.com/">lean data practices</a> through SDK design choices.</strong>
It's easy to limit data collection to what's necessary and documentation can be generated easily, aiding both transparency &amp; understanding for analysis.</p>
<p><strong>Better data tooling integration due to standardized data types &amp; registering them in machine-readable files.</strong>
By having collected data described in machine-readable files, our various data tools can read them and support metrics automatically, without manual work.</p>
<p><strong>Due to common high-level concepts for metrics, APIs &amp; data tools can better match the use-cases.</strong>
To make the choice easier for which metric type to use, we are introducing higher-level data types that offer clear and understandable semantics - for example, when you want to count something, you use the <em>&quot;count&quot;</em> type. This also gives us opportunities to offer better tooling for the data, both on the client and for data tooling.</p>
<p><strong>Basic semantics on how the data is collected are clearly defined by the library.</strong>
To make it easier to understand the general semantics of our data, the Glean SDK will define and document when which kind of data will get sent. This gives data analysis common basic semantics.</p>
<h1><a class="header" href="#how-to-use-glean" id="how-to-use-glean">How to use Glean</a></h1>
<ul>
<li><a href="https://mozilla.github.io/glean/book/user/adding-glean-to-your-project.html">Integrate the Glean SDK / library</a> into your product.</li>
<li><a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Data%20Platform%20and%20Tools&amp;component=General&amp;short_desc=Glean:%20Enable%20application%20id%20org.mozilla.myProduct">File a data engineering bug</a> to enable your products application id.</li>
<li><a href="https://sql.telemetry.mozilla.org/">Use Redash</a> to write SQL queries &amp; build dashboards using your products datasets, e.g.:
<ul>
<li><code>org_mozilla_fenix.baseline</code></li>
<li><code>org_mozilla_fenix.events</code></li>
<li><code>org_mozilla_fenix.metrics</code></li>
<li>Example query: ```
-- Count unique Client IDs observed on a given day
SELECT
count(distinct client_info.client_id)
FROM
org_mozilla_fenix.baseline
WHERE
date(submission_timestamp) = '2019-11-11'</li>
</ul>
</li>
</ul>
<pre><code>*   _(Work in progress)_ Use events and [Amplitude](https://sso.mozilla.com/amplitude) for product analytics.
*   [Use Databricks](https://sso.mozilla.com/databricks) for deep-dive analysis.
*   [Use the Glean debug ping viewer](debug_ping_view.md) for QA &amp; development.
*   For experimentation, you will be able to use [Android experiments library](https://github.com/mozilla-mobile/android-components/blob/master/components/service/experiments/README.md), which integrates with Glean.

# Contact

*   `#glean` &amp; `#fx-metrics` on slack
*   [`glean-team@mozilla.com`](mailto:glean-team@mozilla.com) to reach out
*   [`fx-data-dev@mozilla.com`](mailto:fx-data-dev@mozilla.com) for announcements etc.

# References

* The [Glean SDK](https://github.com/mozilla/glean/) implementation.
* [Reporting issues &amp; bugs for the Glean SDK](https://bugzilla.mozilla.org/enter_bug.cgi?product=Data%20Platform%20and%20Tools&amp;component=Glean%3A%20SDK).
* Datasets documentation (TBD)
* [Glean Debug pings viewer](https://debug-ping-preview.firebaseapp.com/)
</code></pre>
<h1><a class="header" href="#using-the-glean-debug-ping-view" id="using-the-glean-debug-ping-view">Using the Glean debug ping view</a></h1>
<ul>
<li><a href="concepts/glean/debug_ping_view.html#what-is-this-good-for">What is this good for?</a></li>
<li><a href="concepts/glean/debug_ping_view.html#what-setup-is-needed-for-applications">What setup is needed for applications?</a>
<ul>
<li><a href="concepts/glean/debug_ping_view.html#supported-applications">Supported applications</a></li>
</ul>
</li>
<li><a href="concepts/glean/debug_ping_view.html#where-can-i-see-the-data">Where can I see the data?</a></li>
<li><a href="concepts/glean/debug_ping_view.html#can-you-give-me-an-example">Can you give me an example?</a>
<ul>
<li><a href="concepts/glean/debug_ping_view.html#caveats">Caveats</a></li>
</ul>
</li>
<li><a href="concepts/glean/debug_ping_view.html#troubleshooting">Troubleshooting</a></li>
<li><a href="concepts/glean/debug_ping_view.html#questions-problems">Questions? Problems?</a></li>
<li><a href="concepts/glean/debug_ping_view.html#references">References</a></li>
</ul>
<h2><a class="header" href="#what-is-this-good-for" id="what-is-this-good-for">What is this good for?</a></h2>
<p>Glean Debug Ping View enables you to easily see in real-time what data your
mobile application is sending through <a href="concepts/glean/glean.html">Glean</a>.</p>
<p>This data is what actually arrives in our data pipeline, shown in a web
interface that is automatically updated when new data arrives.</p>
<h2><a class="header" href="#what-setup-is-needed-for-applications" id="what-setup-is-needed-for-applications">What setup is needed for applications?</a></h2>
<p>You can use the debug view for all our mobile applications that use Glean (and
enable it), including those installed from the app store.
To enable this you need to run a command in adb that tags the outgoing data as
&quot;debug data&quot;.
You will provide a debug tag, which makes it easier to identify your device in
the web interface.</p>
<pre><code>adb shell am start -n &lt;application-id&gt;/mozilla.components.service.glean.debug.GleanDebugActivity \
  --ez logPings true \
  --es sendPing baseline \
  --es tagPings my-debug-tag
</code></pre>
<p><em>my-debug-tag</em> is what will help you identify your data in the web interface,
while <code>&lt;application-id&gt;</code>  is the application identifier as declared in the
<a href="https://developer.android.com/studio/build/application-id">manifest</a> (e.g. <code>org.mozilla.reference.browser</code>).
The debug commands are documented in more detail
<a href="https://mozilla.github.io/glean/book/user/debugging.html">in the Glean documentation</a>.</p>
<h3><a class="header" href="#supported-applications" id="supported-applications">Supported applications</a></h3>
<p>As for now, the following application ids are supported:</p>
<ul>
<li><code>org.mozilla.fenix</code></li>
<li><code>org.mozilla.reference.browser</code></li>
<li><code>org.mozilla.samples.glean</code></li>
<li><code>org.mozilla.tv.firefox</code></li>
<li>... and some debug versions of the above applications.</li>
</ul>
<h2><a class="header" href="#where-can-i-see-the-data" id="where-can-i-see-the-data">Where can I see the data?</a></h2>
<p>The data is provided in <a href="https://debug-ping-preview.firebaseapp.com/">this web interface</a>.
It lists all recently active devices and updates automatically.
You can use your debug identifier to quickly identify your own testing data.</p>
<p>Any data sent from a mobile device usually shows up within 10 seconds,
updating the pages automatically.</p>
<h2><a class="header" href="#can-you-give-me-an-example" id="can-you-give-me-an-example">Can you give me an example?</a></h2>
<p>For example to send a baseline ping immediately from the Reference Browser,
with a debug identifier of <code>johndoe-test1</code>:</p>
<pre><code>adb shell am start -n org.mozilla.reference.browser/mozilla.components.service.glean.debug.GleanDebugActivity \
  --es sendPing baseline \
  --es tagPings johndoe-test1
</code></pre>
<p><code>baseline</code> pings are also sent automatically by Glean when the application goes
to the background.
So to check these you can set the tag:</p>
<pre><code>adb shell am start -n org.mozilla.reference.browser/mozilla.components.service.glean.debug.GleanDebugActivity \
  --es tagPings johndoe-test1
</code></pre>
<p>Now whenever you put the application in the background, a <code>baseline</code> ping
should show up in the web interface.</p>
<p>If you triggered some event recording and want to confirm them you can use
the <code>events</code></p>
<pre><code>adb shell am start -n org.mozilla.reference.browser/mozilla.components.service.glean.debug.GleanDebugActivity \
  --es sendPing events \
  --es tagPings johndoe-test1
</code></pre>
<p><strong>Note</strong>: Glean will always attempt to collect data for the ping that was
requested using the <code>sendPing</code> command line switch.
However, if no data is recorded by the application, nothing will be sent.
The <code>baseline</code> ping is <em>guaranteed</em> to always be sent, since its populated
by Glean itself.</p>
<h3><a class="header" href="#caveats" id="caveats">Caveats</a></h3>
<p>Some important things to watch out for (see also the <a href="https://github.com/mozilla-mobile/android-components/tree/master/components/service/glean#important-gleandebugactivity-notes">Glean SDK documentation</a>):</p>
<ul>
<li>
<p>Options that are set using the <code>adb</code> flags are not immediately reset and will
persist until the application is closed or manually reset.</p>
</li>
<li>
<p>There are a couple of different ways in which to send pings through the
<code>GleanDebugActivity</code>:</p>
<ol>
<li>You can use the <code>GleanDebugActivity</code> in order to tag pings and trigger
them manually using the UI.  This should always produce a ping with all
required fields.</li>
<li>You can use the <code>GleanDebugActivity</code> to tag <em>and</em> send pings.
This has the side effect of potentially sending a ping which does not
include all fields because <code>sendPings</code> triggers pings to be sent before
certain application behaviors can occur which would record that
information.
For example, <code>duration</code> is not calculated or included in a baseline
ping sent with <code>sendPing</code> because it forces the ping to be sent before
the <code>duration</code> metric has been recorded.</li>
</ol>
</li>
</ul>
<h2><a class="header" href="#troubleshooting" id="troubleshooting">Troubleshooting</a></h2>
<p>If nothing is showing up on the dashboard, it would be useful to check the following:</p>
<ul>
<li>If <code>adb logcat</code> reports <em>Glean must be enabled before sending pings.</em>
right after calling the <code>GleanDebugActivity</code>, then the application has
disabled Glean.
Please check with the application team on how to fix that.</li>
<li>If no error is reported when triggering tagged pings, but the data won't
show up on the dashboard, check if the used <code>&lt;application-id&gt;</code> is the same
expected by the Glean pipeline (i.e. the one used to publish the
application on the Play Store).</li>
<li>Fenix and the reference-browser debug builds currently don't enable Glean.
You could override this in local builds.</li>
</ul>
<h2><a class="header" href="#questions-problems" id="questions-problems">Questions? Problems?</a></h2>
<p>Reach out to Alessio Placitelli (<code>:dexter</code>) or
Arkadiusz Komarzewski (<code>:akomar</code>) in <a href="https://mozilla.slack.com/messages/CEE12R4E8/">#glean on slack</a> or send an email
to <a href="mailto:glean-team@mozilla.com"><code>glean-team@mozilla.com</code></a>.</p>
<h2><a class="header" href="#references" id="references">References</a></h2>
<ul>
<li><a href="https://mozilla.github.io/glean/book/user/debugging.html">Glean debug commands in Glean documentation.</a></li>
<li><a href="https://debug-ping-preview.firebaseapp.com/">Glean Debug ping view web interface.</a></li>
</ul>
<h1><a class="header" href="#telemetry-alerts" id="telemetry-alerts">Telemetry Alerts</a></h1>
<p>Many Telemetry probes were created to show performance trends over time.
Sudden changes happening in Nightly could be the sign of an
unintentional performance regression, so we introduced a system to
automatically detect and alert developers about such changes.</p>
<p>Thus we created Telemetry Alerts. It comes in two pieces:
<a href="https://github.com/mozilla/cerberus/">Cerberus</a> the Detector and
<a href="https://github.com/mozilla/medusa/">Medusa</a> the Front-end.</p>
<h3><a class="header" href="#cerberus" id="cerberus">Cerberus</a></h3>
<p>Every day Cerberus grabs the latest aggregated information about all
non-keyed Telemetry probes from <code>aggregates.telemetry.mozilla.org</code> and
compares the distribution of values from the <strong>Nightly</strong> builds of the
past two days to the distribution of values from the Nightly builds of
the past seven days.</p>
<p>It does this by calculating the <a href="https://en.wikipedia.org/wiki/Bhattacharyya_distance">Bhattacharyya
distance</a> between
the two distributions and guessing whether or not they are <a href="https://github.com/mozilla/cerberus/blob/master/alert/alert.py#L72">significant
and
narrow</a>.</p>
<p>It places all detected changes in a file for ingestion by Medusa.</p>
<h3><a class="header" href="#medusa" id="medusa">Medusa</a></h3>
<p>Medusa is in charge of emailing people when distributions change and for
displaying the website <a href="https://alerts.telemetry.mozilla.org">https://alerts.telemetry.mozilla.org</a> which
contains pertinent information about each detected regression.</p>
<p>Medusa also checks for expiring histograms and sends emails notifying of
their expiry.</p>
<h2><a class="header" href="#what-it-can-do" id="what-it-can-do">What it can do</a></h2>
<p>Telemetry Alerts is very good at identifying sudden changes in the
shapes of normalized distributions of Telemetry probes. If you can see
the distribution of <a href="https://mzl.la/2vdMRax"><code>GC_MS</code></a> shift from one day
to the next, then likely so can Cerberus.</p>
<h2><a class="header" href="#what-cant-it-do" id="what-cant-it-do">What can't it do</a></h2>
<p>Telemetry Alerts is not able to see sudden shifts in volume. It is also
very easily fooled if a change happens over a long period of time or
doesn't fundamentally alter the shape of the probe's histogram.</p>
<p>So if you have a probe like
<a href="https://mzl.la/2vdiuRx"><code>SCALARS_BROWSER.ENGAGEMENT.MAX_CONCURRENT_TAB_COUNT</code></a>,
Cerberus won't notice if:</p>
<ul>
<li>The number of pings reporting this value decreased in half, but
otherwise reported the same spread of numbers</li>
<li>The value increases very slowly over time (which I'd expect it to do
given how good Session Restore is these days)</li>
<li>We suddenly received twice as many pings from 200-tab subsessions
(the dominance of 1-tab pings would likely ensure the overall shape
of the distribution changed insufficiently much for Cerberus to pick
up on it)</li>
</ul>
<h2><a class="header" href="#telemetry-alert-emails" id="telemetry-alert-emails">Telemetry Alert Emails</a></h2>
<p>One of the main ways humans interact with Telemetry Alerts is through
the emails sent by Medusa.</p>
<p>At present the email contains a link to the alert's page on
<a href="https://alerts.telemetry.mozilla.org">https://alerts.telemetry.mozilla.org</a> and a link to a pushlog on
<a href="https://hg.mozilla.org">https://hg.mozilla.org</a> detailing the changes newly-present in the
Nightly build that exhibited the change.</p>
<h2><a class="header" href="#triaging-a-telemetry-alert-email" id="triaging-a-telemetry-alert-email">Triaging a Telemetry Alert Email</a></h2>
<p>Congratulations! You have just received a Telemetry Alert!</p>
<p>Now what?</p>
<p><strong>Assumption:</strong> Alerts happen because of changes in probes. Changes in
probes happen because of changes in related code. If we can identify the
code change, we can find the bug that introduced the code change. If we
can find the bug, we can ni? the person who made the change.</p>
<p><strong>Goal:</strong> Identify the human responsible for the Alert so they can
identify if it is
good/bad/intentional/exceptional/temporary/permanent/still
relevant/having its alerts properly looked after.</p>
<p><strong>Guide:</strong></p>
<ol>
<li>Is this alert just one of a group of similar changes by topic? By
build?</li>
</ol>
<ul>
<li>If there's a group by topic (<code>SPDY</code>, <code>URLCLASSIFIER</code>, ...) check to see
if the changes are similar in direction/magnitude. They usually are.</li>
<li>If there's a group by build but not topic, maybe a large merge
kicked things over. Unfortunate, as that will make finding the source
more difficult.</li>
</ul>
<ol start="2">
<li>Open the <code>hg.mozilla.org</code> and <code>alerts.telemetry.mozilla.org</code> links in
tabs</li>
</ol>
<ul>
<li>On <code>alerts.tmo</code>, does it look like an improvement or regression? (This
is just a first idea and might change. There are often extenuating
circumstances that make something that looks bad into an
improvement, and vice versa.)</li>
<li>On <code>hg.mo</code>, does the topic of the changed probe exist in the pushlog?
In other words, does any part of the probe's name show up in the
summaries of any of the commits?</li>
</ul>
<ol start="3">
<li>From <code>alerts.tmo</code>, open the <a href="https://telemetry.mozilla.org">https://telemetry.mozilla.org</a> link by
clicking on the plot's title. Open another tab to the Evolution View.</li>
</ol>
<ul>
<li>Is the change temporary? (might have been noticed elsewhere and
backed out)</li>
<li>Is the change up or down?</li>
<li>Has it happened before?</li>
<li>Was it accompanied by a decrease in submission volume? (the second
graph at the bottom of the Evolution View)</li>
<li>On the Distribution View, did the Sample Count increase? Decrease?
(this signifies that the change could be because of the addition or
subtraction of a population of values. For instance, we could
suddenly stop sending 0 values which would shift the graph to
the right. This could be a good thing (we're not handling useless
things any longer) a bad thing (something broke and we're no longer
measuring the same thing we used to measure) or indifferent)</li>
</ul>
<ol start="4">
<li>If you still don't have a cause</li>
</ol>
<ul>
<li>Use DXR or searchfox to find where the probe is accumulated.</li>
<li>Click &quot;Log&quot; in that view.</li>
<li>Are there any changesets in the resultant <code>hg.mo</code> list that ended up
in the build we received the Alert for?</li>
</ul>
<ol start="5">
<li>If you <em>still</em> don't know what's going on</li>
</ol>
<ul>
<li>find a domain expert on IRC and bother them to help you out. Domain
knowledge is awesome.</li>
</ul>
<p>From pursuing these steps or sub-steps you should now have two things: a
bug that likely caused the alert, and an idea of what the alert is
about.</p>
<p>Now comment on the bug. Feel free to use this script:</p>
<pre><code class="language-text">ThisbugmayhavecontributedtoasuddenchangeintheTelemetryprobe&lt;PROBE_NAME&gt;[1]whichseemstohaveoccurredinNightly&lt;builddate&gt;[2][3].

Therewasa&lt;describethechange:increase/decrease,populationaddition/subtraction,regression/improvement,changeinsubmission/samplevolume...&gt;.
Thismightmean&lt;wildspeculation.It'llencouragetheni?torefuteit:)&gt;

Isthisanimprovement?Aregression?

Isthisintentional?Isthisexpected?

Isthisprobestillmeasuringsomethinguseful?

[1]:&lt;the alerts.tmo link&gt;
[2]:&lt;the hg.mo link for the pushlog&gt;
[3]:&lt;the telemetry.mozilla.org link showing the Evolution View&gt;
</code></pre>
<p>Then ni? the person who pushed the change. Reply-all to the
<code>dev-telemetry-alerts</code> mail with a link to the bug and some short notes on
what you found.</p>
<p>From here the user on ni? should get back to you in fairly short order
and either help you find the real bug that caused it, or help explain
what the Alert was all about. More often than not it is an expected
change from a probe that is still operating correctly and there is no
action to take...</p>
<p>...except making sure you never have to respond to an Alert for this
probe again, that is. File a bug in that bug's component to update the
Alerting probe to have a valid, monitored <code>alert_emails</code> field so that
the next time it misbehaves <em>they</em> can be the ones to explain themselves
without you having to spend all this time tracking them down.</p>
<h1><a class="header" href="#cookbooks" id="cookbooks">Cookbooks</a></h1>
<p>A Cookbook is a focused tutorial to guide you through a focused task.
For example, a Cookbook could:</p>
<ul>
<li>Introduce you to what types of analyses are common for (e.g.) Search or Crash data</li>
<li>Guide you through an example analysis to demonstrate
the basic principles behind a new statistical technique</li>
</ul>
<h1><a class="header" href="#accessing-and-working-with-bigquery" id="accessing-and-working-with-bigquery">Accessing and working with BigQuery</a></h1>
<p>This guide will give you a quick introduction to working with data stored
in <a href="https://cloud.google.com/bigquery/">BigQuery</a></p>
<p>BigQuery uses a columnar data storage format called <a href="https://cloud.google.com/blog/products/gcp/inside-capacitor-bigquerys-next-generation-columnar-storage-format">Capacitor</a> which supports semi-structured data.</p>
<p>There is a cost associated with using BigQuery based on operations. As of right now we pay an on-demand pricing for queries based on how much data a query scans. To minimize costs see <a href="cookbooks/bigquery.html#query-optimizations"><em>Query Optimizations</em></a>. More detailed pricing information can be found <a href="https://cloud.google.com/bigquery/pricing">here</a>.</p>
<p>With the transition to <a href="https://cloud.google.com">GCP</a> in 2019, BigQuery has become our primary data warehouse and
SQL Query engine.
Our previous SQL Query Engines, Presto and Athena, and our Parquet data lake will no longer be accessible
by the end of 2019.
Specific guidance for transitioning off of the AWS data
infrastructure, including up-to-date timelines of data availability, is
maintained in the <a href="https://docs.google.com/document/d/1nlzhRGGwAaClwbotd0oWnnkB5GcvpodIxN3Dk5vWvNI/edit#">Data Access Continuity Guide</a> Google Doc.</p>
<h2><a class="header" href="#table-of-contents-2" id="table-of-contents-2">Table of Contents</a></h2>
<ul>
<li><a href="cookbooks/bigquery.html#access">Access</a>
<ul>
<li><a href="cookbooks/bigquery.html#interfaces">Interfaces</a></li>
<li><a href="cookbooks/bigquery.html#access-request">Access Request</a></li>
<li><a href="cookbooks/bigquery.html#from-redash">From re:dash</a></li>
<li><a href="cookbooks/bigquery.html#gcp-bigquery-console">GCP BigQuery Console</a></li>
<li><a href="cookbooks/bigquery.html#gcp-bigquery-api-access">GCP BigQuery API Access</a>
<ul>
<li><a href="cookbooks/bigquery.html#from-">From </a></li>
<li><a href="cookbooks/bigquery.html#bq"><code>bq</code></a></li>
<li><a href="cookbooks/bigquery.html#-command-line-tool"> Command-line Tool</a>
<ul>
<li><a href="cookbooks/bigquery.html#bq"><code>bq</code></a></li>
<li><a href="cookbooks/bigquery.html#-examples"> Examples</a></li>
</ul>
</li>
<li><a href="cookbooks/bigquery.html#from-client-sdks">From client SDKs</a></li>
</ul>
</li>
<li><a href="cookbooks/bigquery.html#from-spark">From Spark</a>
<ul>
<li><a href="cookbooks/bigquery.html#on-databricks">On Databricks</a></li>
<li><a href="cookbooks/bigquery.html#on-dataproc">On Dataproc</a></li>
</ul>
</li>
<li><a href="cookbooks/bigquery.html#from-colaboratory">From Colaboratory</a></li>
</ul>
</li>
<li><a href="cookbooks/bigquery.html#querying-tables">Querying Tables</a>
<ul>
<li><a href="cookbooks/bigquery.html#projects-datasets-and-tables-in-bigquery">Projects, Datasets and Tables in BigQuery</a>
<ul>
<li><a href="cookbooks/bigquery.html#caveats">Caveats</a></li>
<li><a href="cookbooks/bigquery.html#projects-with-bigquery-datasets">Projects with BigQuery datasets</a></li>
<li><a href="cookbooks/bigquery.html#table-layout-and-naming">Table Layout and Naming</a></li>
<li><a href="cookbooks/bigquery.html#structure-of-ping-tables-in-bigquery">Structure of Ping Tables in BigQuery</a></li>
<li><a href="cookbooks/bigquery.html#writing-queries">Writing Queries</a></li>
<li><a href="cookbooks/bigquery.html#writing-query-results-to-a-permanent-table">Writing query results to a permanent table</a></li>
<li><a href="cookbooks/bigquery.html#writing-results-to-gcs-object-store">Writing results to GCS (object store)</a></li>
<li><a href="cookbooks/bigquery.html#creating-a-view">Creating a View</a></li>
<li><a href="cookbooks/bigquery.html#using-udfs">Using UDFs</a>
<ul>
<li><a href="cookbooks/bigquery.html#accessing-map-like-fields">Accessing map-like fields</a></li>
<li><a href="cookbooks/bigquery.html#accessing-histograms">Accessing histograms</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="cookbooks/bigquery.html#query-optimizations">Query Optimizations</a></li>
</ul>
<h1><a class="header" href="#access" id="access">Access</a></h1>
<p>There are multiple ways to access BigQuery. For most users the primary interface will be <a href="https://sql.telemetry.mozilla.org/">re:dash</a>.</p>
<p>See below for additional interfaces. All other interfaces will require access to be provisioned.</p>
<h2><a class="header" href="#interfaces" id="interfaces">Interfaces</a></h2>
<p>BigQuery datasets and tables can be accessed by the following methods:</p>
<ul>
<li><a href="cookbooks/bigquery.html#from-redash">re:dash</a></li>
<li><a href="cookbooks/bigquery.html#gcp-bigquery-console">GCP BigQuery Console</a>
<ul>
<li>For advanced use cases including managing query outputs, table management. Requires GCP access to be granted by Data Operations.</li>
</ul>
</li>
<li><a href="cookbooks/bigquery.html#gcp-bigquery-api-access">GCP BigQuery API Access</a>
<ul>
<li>For advanced use cases including automated workloads, ETL, <a href="https://cloud.google.com/bigquery/docs/reference/storage/">BigQuery Storage API</a>. Requires GCP access to be granted by Data Operations.</li>
<li>Allows access to BigQuery via <a href="https://cloud.google.com/bigquery/docs/bq-command-line-tool"><code>bq</code> command-line tool</a></li>
</ul>
</li>
<li><a href="cookbooks/bigquery.html#from-spark">Spark</a>
<ul>
<li><a href="cookbooks/bigquery.html#on-databricks">Databricks</a></li>
<li><a href="cookbooks/bigquery.html#on-dataproc">Dataproc</a></li>
</ul>
</li>
<li><a href="cookbooks/bigquery.html#from-colaboratory">Colaboratory</a></li>
</ul>
<h2><a class="header" href="#access-request" id="access-request">Access Request</a></h2>
<p>For access to BigQuery via GCP Console and API please file a bug <a href="https://bugzilla.mozilla.org/enter_bug.cgi?assigned_to=jthomas%40mozilla.com&amp;bug_file_loc=https%3A%2F%2Fmana.mozilla.org%2Fwiki%2Fx%2FiIPeB&amp;bug_ignored=0&amp;bug_severity=normal&amp;bug_status=NEW&amp;bug_type=task&amp;cf_fx_iteration=---&amp;cf_fx_points=---&amp;comment=Please%20grant%20me%20access%20to%20the%20BigQuery%20GCP%20console%20and%20API%20Access.%20I%20work%20on%20%3Cteam%3E.%0D%0A%0D%0AMy%20mozilla.com%20ldap%20login%20is%20%3Cyour%20ldap%20login%3E%40mozilla.com.&amp;component=Operations&amp;contenttypemethod=list&amp;contenttypeselection=text%2Fplain&amp;defined_groups=1&amp;flag_type-4=X&amp;flag_type-607=X&amp;flag_type-800=X&amp;flag_type-803=X&amp;flag_type-936=X&amp;form_name=enter_bug&amp;maketemplate=Remember%20values%20as%20bookmarkable%20template&amp;op_sys=Unspecified&amp;priority=--&amp;product=Data%20Platform%20and%20Tools&amp;qa_contact=jthomas%40mozilla.com&amp;rep_platform=Unspecified&amp;short_desc=BigQuery%20GCP%20Console%20and%20API%20Access%20for%20%3Cyour%20ldap%20login%3E%40mozilla.com&amp;target_milestone=---&amp;version=unspecified">here</a>. As part of this request we will add you to the appropriate Google Groups and provision a GCP Service Account.</p>
<h2><a class="header" href="#from-redash" id="from-redash">From re:dash</a></h2>
<p>All Mozilla users will be able to access BigQuery via <a href="https://sql.telemetry.mozilla.org/">re:dash</a> through the following Data Sources:</p>
<ul>
<li><code>Telemetry (BigQuery)</code></li>
<li><code>Telemetry Search (BigQuery)</code>
<ul>
<li>This group is restricted to users in the re:dash <code>search</code> group.</li>
</ul>
</li>
</ul>
<p>Access via re:dash is read-only. You will not be able to create views or tables via re:dash.</p>
<h2><a class="header" href="#gcp-bigquery-console" id="gcp-bigquery-console">GCP BigQuery Console</a></h2>
<ul>
<li>File a <a href="cookbooks/bigquery.html#access-request">bug</a> with Data Operations for access to GCP Console.</li>
<li>Visit <a href="https://console.cloud.google.com/bigquery">GCP BigQuery Console</a></li>
<li>Switch to the project provided to you during your access request e.g <code>moz-fx-data-bq-&lt;team-name&gt;</code></li>
</ul>
<p>See <a href="https://cloud.google.com/bigquery/docs/bigquery-web-ui">Using the BigQuery web UI in the GCP Console</a> for more details.</p>
<h2><a class="header" href="#gcp-bigquery-api-access" id="gcp-bigquery-api-access">GCP BigQuery API Access</a></h2>
<ul>
<li>File a <a href="cookbooks/bigquery.html#access-request">bug</a> with Data Operations for access to GCP BigQuery API Access.</li>
</ul>
<p>A list of supported BigQuery client libraries can be found <a href="https://cloud.google.com/bigquery/docs/reference/libraries">here</a>.</p>
<p>Detailed REST reference can be found <a href="https://cloud.google.com/bigquery/docs/reference/rest/">here</a>.</p>
<h3><a class="header" href="#from-bq-command-line-tool" id="from-bq-command-line-tool">From <code>bq</code> Command-line Tool</a></h3>
<ul>
<li>Install the <a href="https://cloud.google.com/sdk/">GCP SDK</a></li>
<li>Authorize <code>gcloud</code> with either your user account or provisioned service account. See documentation <a href="https://cloud.google.com/sdk/docs/authorizing">here</a>.
<ul>
<li><code>gcloud auth login</code></li>
</ul>
</li>
<li>Set your google project to your team project
<ul>
<li><code>gcloud config set project moz-fx-data-bq-&lt;team-name&gt;</code></li>
<li>project name will be provided for you when your account is provisioned.</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#bq-examples" id="bq-examples"><code>bq</code> Examples</a></h4>
<p>List tables and views in a BigQuery dataset</p>
<pre><code class="language-bash">bq ls moz-fx-data-derived-datasets:telemetry
</code></pre>
<p>Query a table or view</p>
<pre><code class="language-bash">bq query --nouse_legacy_sql 'select count(*) from `moz-fx-data-derived-datasets.telemetry.main` where submission_date = &quot;2019-08-22&quot; LIMIT 10'
</code></pre>
<p>Additional examples and documentation can be found <a href="https://cloud.google.com/bigquery/docs/bq-command-line-tool">here</a>.</p>
<h3><a class="header" href="#from-client-sdks" id="from-client-sdks">From client SDKs</a></h3>
<p>Client SDKs for various programming languages don't access credentials the
same way as the <code>gcloud</code> and <code>bq</code> command-line tools. The client SDKs
generally assume that the machine is configured with a service account and
will look for JSON-based credentials in several well-known locations rather
than looking for user credentials.</p>
<p>If you have service account credentials, you can point client SDKs at them
by setting:</p>
<pre><code>export GOOGLE_APPLICATION_CREDENTIALS=/path/to/creds.json
</code></pre>
<p>If you don't have appropriate service account credentials, but your GCP user
account has sufficient access, you can have your user credentials mimic a
service account by running:</p>
<pre><code>gcloud auth application-default login
</code></pre>
<p>Once you've followed the browser flow to grant access, you should be able to,
for example, access BigQuery from Python:</p>
<pre><code>pip install google-cloud-bigquery
python -c 'from google.cloud import bigquery; print([d.dataset_id for d in bigquery.Client().list_datasets()])'
</code></pre>
<h2><a class="header" href="#from-spark" id="from-spark">From Spark</a></h2>
<p>We recommend the <a href="https://github.com/GoogleCloudPlatform/spark-bigquery-connector">Storage API Connector</a> for accessing
BigQuery tables in Spark as it is the most modern and actively developed connector. It works well with the BigQuery
client library which is useful if you need to run arbitrary SQL queries (see example Databricks notebook) and load their
results into Spark.</p>
<h3><a class="header" href="#on-databricks" id="on-databricks">On Databricks</a></h3>
<p>The <code>shared_serverless_python3</code> cluster is configured with shared default GCP credentials that will be automatically picked
up by BigQuery client libraries. It also has the Storage API Connector library added as seen in the example
<a href="https://dbc-caf9527b-e073.cloud.databricks.com/#notebook/141939">Python notebook</a>.</p>
<h3><a class="header" href="#on-dataproc" id="on-dataproc">On Dataproc</a></h3>
<p>Dataproc is Google's managed Spark cluster service. Accessing BigQuery from there will be faster than from Databricks
because it will not involve cross-cloud data transfers.</p>
<p>You can spin up a Dataproc cluster with Jupyter using the following command. Insert your values for <code>cluster-name</code>, <code>bucket-name</code>, and <code>project-id</code> there. Your notebooks will be stored in Cloud Storage under <code>gs://bucket-name/notebooks/jupyter</code>:</p>
<pre><code class="language-bash">gcloud beta dataproc clusters create cluster-name \
    --optional-components=ANACONDA,JUPYTER \
    --image-version=1.4 \
    --enable-component-gateway \
    --properties=^#^spark:spark.jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar \
    --num-workers=3 \
    --max-idle=3h \
    --bucket bucket-name \
    --region=us-west1 \
    --project project-id
</code></pre>
<p>Jupyter URL can be retrieved with the following command:</p>
<pre><code class="language-bash">gcloud beta dataproc clusters describe cluster-name --region=us-west1 --project project-id | grep Jupyter
</code></pre>
<p>After you've finished your work, it's a good practice to delete your cluster:</p>
<pre><code class="language-bash">gcloud beta dataproc clusters delete cluster-name --region=us-west1 --project project-id --quiet
</code></pre>
<h2><a class="header" href="#from-colaboratory" id="from-colaboratory">From Colaboratory</a></h2>
<p><a href="https://colab.research.google.com">Colaboratory</a> is Jupyter notebook environment, managed by Google and running in the cloud. Notebooks are stored in Google Drive and can be shared in a similar way to Google Docs.</p>
<p>Colaboratory can be used to easily access BigQuery and perform interactive analyses. See <a href="https://colab.research.google.com/drive/1uXmrPnqzDATiCVH2RNJKD8obIZuofFHx"><code>Telemetry Hello World</code> notebook</a>.</p>
<p>Note: this is very similar to <a href="cookbooks/bigquery.html#gcp-bigquery-api-access">API Access</a>, so you will need access to your team's GCP project - file a request as described <a href="cookbooks/bigquery.html#access-request">above</a>.</p>
<h1><a class="header" href="#querying-tables" id="querying-tables">Querying Tables</a></h1>
<h2><a class="header" href="#projects-datasets-and-tables-in-bigquery" id="projects-datasets-and-tables-in-bigquery">Projects, Datasets and Tables in BigQuery</a></h2>
<p>In GCP a <a href="https://cloud.google.com/resource-manager/docs/creating-managing-projects">project</a> is a way to organize cloud resources. We use multiple
projects to maintain our BigQuery <a href="https://cloud.google.com/bigquery/docs/datasets-intro">datasets</a>.</p>
<p>Note that we have historically used the term <em>dataset</em> to describe a set of
records all following the same schema, but this idea corresponds to a <em>table</em>
in BigQuery. In BigQuery terminology,
datasets are a top-level container used to organize and
control access to tables and views.</p>
<h3><a class="header" href="#caveats-1" id="caveats-1">Caveats</a></h3>
<ul>
<li>The date partition field (e.g. <code>submission_date_s3</code>, <code>submission_date</code>) is mostly used as a partitioning column,
but it has changed from <code>YYYYMMDD</code> string form to a proper <code>DATE</code> type that accepts string literals in the more standards-friendly <code>YYYY-MM-DD</code> form.</li>
<li>Unqualified queries can become very costly very easily. We've placed restrictions on large tables from accidentally querying &quot;all data for all time&quot;,
namely that you must make use of the date partition fields for large tables (like <code>main_summary</code> or <code>clients_daily</code>).</li>
<li>Please read <a href="cookbooks/bigquery.html#query-optimizations"><em>Query Optimizations</em></a> section that contains advice on how to reduce cost and improve query performance.</li>
<li>re:dash BigQuery data sources will have a 10 TB data scanned limit per query. Please let us know in <code>#fx-metrics</code> on Slack if you run into issues!</li>
<li>There is no native map support in BigQuery. Instead, we are using structs with fields [key, value]. We have provided convenience functions to access these like key-value maps (described <a href="cookbooks/bigquery.html#accessing-map-like-fields">below</a>.)</li>
</ul>
<h3><a class="header" href="#projects-with-bigquery-datasets" id="projects-with-bigquery-datasets">Projects with BigQuery datasets</a></h3>
<table><thead><tr><th>Project</th><th>Dataset</th><th>Purpose</th></tr></thead><tbody>
<tr><td><code>moz-fx-data-shared-prod</code></td><td></td><td>All production data including full pings, imported parquet data, <a href="https://github.com/mozilla/bigquery-etl">BigQuery ETL</a>, and ad-hoc analysis</td></tr>
<tr><td></td><td><code>&lt;namespace&gt;_live</code></td><td>See <em>live datasets</em> below</td></tr>
<tr><td></td><td><code>&lt;namespace&gt;_stable</code></td><td>See <em>stable datasets</em> below</td></tr>
<tr><td></td><td><code>&lt;namespace&gt;_derived</code></td><td>See <em>derived datasets</em> below</td></tr>
<tr><td></td><td><code>&lt;namespace&gt;</code></td><td>See <em>user-facing (unsuffixed) datasets</em> below</td></tr>
<tr><td></td><td><code>analysis</code></td><td>User generated tables for analysis</td></tr>
<tr><td></td><td><code>backfill</code></td><td>Temporary staging area for back-fills</td></tr>
<tr><td></td><td><code>blpadi</code></td><td>Blocklist ping derived data(<em>restricted</em>)</td></tr>
<tr><td></td><td><code>payload_bytes_raw</code></td><td>Raw JSON payloads as received from clients, used for reprocessing scenarios, a.k.a. &quot;landfill&quot; (<em>restricted</em>)</td></tr>
<tr><td></td><td><code>payload_bytes_decoded</code></td><td><code>gzip</code>-compressed decoded JSON payloads, used for reprocessing scenarios</td></tr>
<tr><td></td><td><code>payload_bytes_error</code></td><td><code>gzip</code>-compressed JSON payloads that were rejected in some phase of the pipeline; particularly useful for investigating schema validation errors</td></tr>
<tr><td></td><td><code>search</code></td><td>Search data imported from parquet (<em>restricted</em>)</td></tr>
<tr><td></td><td><code>static</code></td><td>Static tables, often useful for data-enriching joins</td></tr>
<tr><td></td><td><code>tmp</code></td><td>Temporary staging area for parquet data loads</td></tr>
<tr><td></td><td><code>udf</code></td><td>Persistent user-defined functions defined in SQL; see <a href="cookbooks/bigquery.html#using-udfs">Using UDFs</a></td></tr>
<tr><td></td><td><code>udf_js</code></td><td>Persistent user-defined functions defined in JavaScript; see <a href="cookbooks/bigquery.html#using-udfs">Using UDFs</a></td></tr>
<tr><td></td><td><code>validation</code></td><td>Temporary staging area for validation</td></tr>
<tr><td><code>moz-fx-data-derived-datasets</code></td><td></td><td>Legacy project that contains mostly views to data in <code>moz-fx-data-shared-prod</code> during a transition period; STMO currently points at this project but we will announce a transition to <code>moz-fx-data-shared-prod</code> by end of 2019</td></tr>
<tr><td></td><td><code>analysis</code></td><td>User generated tables for analysis; note that this dataset is separate from <code>moz-fx-data-shared-prod:analysis</code> and users are responsible for migrating or cloning data during the transition period</td></tr>
<tr><td><code>moz-fx-data-shar-nonprod-efed</code></td><td></td><td>Non-production data produced by stage ingestion infrastructure</td></tr>
</tbody></table>
<h3><a class="header" href="#table-layout-and-naming" id="table-layout-and-naming">Table Layout and Naming</a></h3>
<p>Under the single <code>moz-fx-data-shared-prod</code> project,
each document namespace (corresponding to folders underneath the <a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/tree/master/schemas">schemas directory of <code>mozilla-pipeline-schemas</code></a>) has four BigQuery datasets provisioned with the following properties:</p>
<ul>
<li><em>Live datasets</em> (<code>telemetry_live</code>, <code>activity_stream_live</code>, etc.) contain live ping tables (see definitions of table types in the next paragraph)</li>
<li><em>Stable datasets</em> (<code>telemetry_stable</code>, <code>activity_stream_stable</code>, etc.) contain historical ping tables</li>
<li><em>Derived datasets</em> (<code>telemetry_derived</code>, <code>activity_stream_derived</code>, etc.) contain derived tables, primarily populated via nightly queries defined in <a href="https://github.com/mozilla/bigquery-etl">BigQuery ETL</a> and managed by Airflow</li>
<li><em>User-facing (unsuffixed) datasets</em> (<code>telemetry</code>, <code>activity_stream</code>, etc.) contain user-facing views on top of the tables in the corresponding stable and derived datasets.</li>
</ul>
<p>The table and view types referenced above are defined as follows:</p>
<ul>
<li><em>Live ping tables</em> are the final destination for the <a href="https://mozilla.github.io/gcp-ingestion/">telemetry ingestion pipeline</a>. Dataflow jobs process incoming ping payloads from clients, batch them together by document type, and load the results to these tables approximately every five minutes, although a few document types are opted in to a more expensive streaming path that makes records available in BigQuery within seconds of ingestion. These tables are partitioned by date according to <code>submission_timestamp</code> and are also clustered on that same field, so it is possible to make efficient queries over short windows of recent data such as the last hour. They have a rolling expiration period of 30 days, but that window may be shortened in the future. Analyses should only use these tables if they need results for the current (partial) day.</li>
<li><em>Historical ping tables</em> have exactly the same schema as their corresponding live ping tables, but they are populated only once per day via an Airflow job and have a 25 month retention period. These tables are superior to the live ping tables for historical analysis because they never contain partial days, they have additional deduplication applied, and they are clustered on <code>sample_id</code>, allowing efficient queries on a 1% sample of clients. It is guaranteed that <code>document_id</code> is distinct within each UTC day of each historical ping table, but it is still possible for a document to appear multiple times if a client sends the same payload across multiple days. Note that this requirement is relaxed for older telemetry ping data that was backfilled from AWS; approximately 0.5% of documents are duplicated in <code>telemetry.main</code> and other historical ping tables for 2019-04-30 and earlier dates.</li>
<li><em>Derived tables</em> are populated by nightly <a href="https://workflow.telemetry.mozilla.org/home">Airflow</a> jobs and are considered an implementation detail; their structure may change at any time at the discretion of the data platform team to allow refactoring or efficiency improvements.</li>
<li><em>User-facing views</em> are the schema objects that users are primarily expected to use in analyses. Many of these views correspond directly to an underlying historical ping table or derived table, but they provide the flexibility to hide deprecated columns or present additional calculated columns to users. These views are the schema contract with users and they should not change in backwards-incompatible ways without a version increase or an announcement to users about a breaking change.</li>
</ul>
<p>Spark and other applications relying on the BigQuery Storage API for data access need to reference derived tables or historical ping tables directly rather than user-facing views. Unless the query result is relatively large, we  recommend instead that users run a query on top of user-facing views with the output saved in a destination table, which can then be accessed from Spark.</p>
<h3><a class="header" href="#structure-of-ping-tables-in-bigquery" id="structure-of-ping-tables-in-bigquery">Structure of Ping Tables in BigQuery</a></h3>
<p>Unlike with the previous AWS-based data infrastructure, we don't have different mechanisms for accessing entire pings vs. &quot;summary&quot; tables. As such, there are no longer special libraries or infrastructure necessary for accessing full pings, rather each document type maps to a user-facing view that can be queried in STMO. For example:</p>
<ul>
<li>&quot;main&quot; pings are accessible from view <code>telemetry.main</code></li>
<li>&quot;crash&quot; pings are accessible from view <code>telemetry.crash</code></li>
<li>&quot;baseline&quot; pings for Fenix are accessible from view <code>org_mozilla_fenix.baseline</code></li>
</ul>
<p>All fields in the incoming pings are accessible in these views, and (where possible) match the nested data structures of the original JSON. Field names are converted from <code>camelCase</code> form to <code>snake_case</code> for consistency and SQL compatibility.</p>
<p>Any fields not present in the ping schemas are present in an <code>additional_properties</code> field containing leftover JSON. BigQuery provides <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/json_functions">functions for parsing and manipulating JSON data via SQL</a>.</p>
<p>Later in this document, we demonstrate the use of a few Mozilla-specific
functions that we have defined to allow ergonomic querying of
<a href="cookbooks/bigquery.html#accessing-map-like-fields">map-like fields</a> (which are represented as arrays of structs in BigQuery) and
<a href="cookbooks/bigquery.html#accessing-histograms">histograms</a> (which are encoded as raw JSON strings).</p>
<h3><a class="header" href="#writing-queries" id="writing-queries">Writing Queries</a></h3>
<p>To query a BigQuery table you will need to specify the dataset and table name. It is good practice to specify the project however depending on which project the query
originates from this is optional.</p>
<pre><code class="language-sql">SELECT
    col1,
    col2
FROM
    `project.dataset.table`
WHERE
    -- data_partition_field will vary based on table
    date_partition_field &gt;= DATE_SUB(CURRENT_DATE, INTERVAL 1 MONTH)
</code></pre>
<p>An example query from <a href="cookbooks/../datasets/bigquery/clients_last_seen/reference.html">Clients Last Seen Reference</a></p>
<pre><code class="language-sql">SELECT
    submission_date,
    os,
    COUNT(*) AS count
FROM
    telemetry.clients_last_seen
WHERE
    submission_date &gt;= DATE_SUB(CURRENT_DATE, INTERVAL 1 WEEK)
    AND days_since_seen = 0
GROUP BY
    submission_date,
    os
HAVING
    count &gt; 10 -- remove outliers
    AND lower(os) NOT LIKE '%windows%'
ORDER BY
    os,
    submission_date DESC
</code></pre>
<p>Check out the <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators">BigQuery Standard SQL Functions &amp; Operators</a> for detailed documentation.</p>
<h3><a class="header" href="#writing-query-results-to-a-permanent-table" id="writing-query-results-to-a-permanent-table">Writing query results to a permanent table</a></h3>
<p>You can write query results to a BigQuery table you have access via <a href="cookbooks/bigquery.html#gcp-bigquery-console">GCP BigQuery Console</a> or <a href="cookbooks/bigquery.html#gcp-bigquery-api-access">GCP BigQuery API Access</a></p>
<ul>
<li>Use <code>moz-fx-data-shared-prod.analysis</code> dataset.
<ul>
<li>Prefix your table with your username. If your username is <code>username@mozilla.com</code> create a table with <code>username_my_table</code>.</li>
</ul>
</li>
<li>See <a href="https://cloud.google.com/bigquery/docs/writing-results">Writing query results</a> documentation for detailed steps.</li>
</ul>
<h3><a class="header" href="#writing-results-to-gcs-object-store" id="writing-results-to-gcs-object-store">Writing results to GCS (object store)</a></h3>
<p>If a BigQuery table is not a suitable destination for your analysis results,
we also have a GCS bucket available for storing analysis results. It is usually
Spark jobs that will need to do this.</p>
<ul>
<li>Use bucket <code>gs://moz-fx-data-prod-analysis/</code>
<ul>
<li>Prefix object paths with your username. If your username is <code>username@mozilla.com</code>, you might store a file to <code>gs://moz-fx-data-prod-analysis/username/myresults.json</code>.</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#creating-a-view" id="creating-a-view">Creating a View</a></h3>
<p>You can create views in BigQuery if you have access via <a href="cookbooks/bigquery.html#gcp-bigquery-console">GCP BigQuery Console</a> or <a href="cookbooks/bigquery.html#gcp-bigquery-api-access">GCP BigQuery API Access</a>.</p>
<ul>
<li>Use <code>moz-fx-data-shared-prod.analysis</code> dataset.
<ul>
<li>Prefix your view with your username. If your username is <code>username@mozilla.com</code> create a table with <code>username_my_view</code>.</li>
</ul>
</li>
<li>See <a href="https://cloud.google.com/bigquery/docs/views">Creating Views</a> documentation for detailed steps.</li>
</ul>
<h3><a class="header" href="#using-udfs" id="using-udfs">Using UDFs</a></h3>
<p>BigQuery offers <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/user-defined-functions">user-defined functions</a> (UDFs) that can be defined in SQL or JavaScript as part of a query or as a persistent function stored in a dataset. We have defined a suite of persistent functions to enable transformations specific to our data formats, available in datasets <code>udf</code> (for functions defined in SQL) and <code>udf_js</code> (for functions defined in JavaScript). Note that JavaScript functions are potentially much slower than those defined in SQL, so use functions in <code>udf_js</code> with some caution, likely only after performing aggregation in your query.</p>
<p>We document a few of the most broadly useful UDFs below, but you can see the full list of UDFs with source code in <a href="https://github.com/mozilla/bigquery-etl/tree/master/udf"><code>bigquery-etl/udf</code></a> and <a href="https://github.com/mozilla/bigquery-etl/tree/master/udf_js"><code>bigquery-etl/udf_js</code></a>. Publishing a full reference page for our persistent UDFs is a planned improvement, tracked in <a href="https://github.com/mozilla/bigquery-etl/issues/228"><code>bigquery-etl#228</code></a>.</p>
<h4><a class="header" href="#accessing-map-like-fields" id="accessing-map-like-fields">Accessing map-like fields</a></h4>
<p>BigQuery currently lacks native map support and our workaround is to use a STRUCT type with fields named [key, value]. We've created a UDF that provides key-based access with the signature: <code>udf.get_key(&lt;struct&gt;, &lt;key&gt;)</code>. The example below generates a count per <code>reason</code> key in the <code>event_map_values</code> field in the telemetry events table for Normandy unenrollment events from yesterday.</p>
<pre><code class="language-sql">SELECT udf.get_key(event_map_values, 'reason') AS reason,
       COUNT(*) AS EVENTS
FROM telemetry.events
WHERE submission_date = DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)
  AND event_category='normandy'
  AND event_method='unenroll'
GROUP BY 1
ORDER BY 2 DESC
</code></pre>
<h4><a class="header" href="#accessing-histograms" id="accessing-histograms">Accessing histograms</a></h4>
<p>We considered many potential ways to represent histograms as BigQuery fields
and found the most efficient encoding was actually to leave them as raw JSON
strings. To make these strings easier to use for analysis, you can convert them
into nested structures using <code>udf.json_extract_histogram</code>:</p>
<pre><code class="language-sql">WITH
  extracted AS (
  SELECT
    submission_timestamp,
    udf.json_extract_histogram(payload.histograms.a11y_consumers) AS a11y_consumers
  FROM
    telemetry.main )
  --
SELECT
  a11y_consumers.bucket_count,
  a11y_consumers.sum,
  a11y_consumers.range[ORDINAL(1)] AS range_low,
  udf.get_key(a11y_consumers.values, 11) AS value_11
FROM
  extracted
WHERE
  a11y_consumers.bucket_count IS NOT NULL
  AND DATE(submission_timestamp) = &quot;2019-08-09&quot;
LIMIT
  10
</code></pre>
<h1><a class="header" href="#query-optimizations" id="query-optimizations">Query Optimizations</a></h1>
<p>To improve query performance and minimize the cost associated with using BigQuery please see the following query optimizations:</p>
<ul>
<li>Avoid <code>SELECT *</code> by selecting only the columns you need
<ul>
<li>Using <code>SELECT *</code> is the most expensive way to query data. When you use <code>SELECT *</code> <em>BigQuery does a full scan of every column in the table.</em></li>
<li>Applying a <code>LIMIT</code> clause to a <code>SELECT *</code> query might not affect the amount of data read, depending on the table structure.
<ul>
<li>Many of our tables are configured to use <em>clustering</em> in which case a <code>LIMIT</code> clause does effectively limit the amount of data that needs to be scanned.</li>
<li>Tables that include a <code>sample_id</code> field will usually have that as one of the clustering fields and you can efficiently scan random samples of users by specifying <code>WHERE sample_id = 0</code> (1% sample), <code>WHERE sample_id &lt; 10</code> (10% sample), etc. This can be especially helpful with <code>main_summary</code>, <code>clients_daily</code>, and <code>clients_last_seen</code> which are very large tables and are all clustered on <code>sample_id</code>.</li>
<li>To check whether your <code>LIMIT</code> and <code>WHERE</code> clauses are actually improving performance, you should see a lower value reported for actual &quot;Data Scanned&quot; by a query compared to the prediction (&quot;This query will process X bytes&quot;) in STMO or the BigQuery UI.</li>
</ul>
</li>
<li>If you are experimenting with data or exploring data, use one of the <a href="https://cloud.google.com/bigquery/docs/best-practices-costs#preview-data">data preview options</a> instead of <code>SELECT *</code>.
<ul>
<li>Preview support is coming soon to BigQuery data sources in <a href="https://sql.telemetry.mozilla.org/">re:dash</a></li>
</ul>
</li>
</ul>
</li>
<li>Limit the amount of data scanned by using a date partition filter
<ul>
<li>Tables that are larger than 1 TB will require that you provide a date partition filter as part of the query.</li>
<li>You will receive an error if you attempt to query a table that requires a partition filter.
<ul>
<li><code>Cannot query over table 'moz-fx-data-shared-prod.telemetry_derived.main_summary_v4' without a filter over column(s) 'submission_date' that can be used for partition elimination</code></li>
</ul>
</li>
<li>See <a href="cookbooks/bigquery.html#writing-queries"><em>Writing Queries</em></a> for examples.</li>
</ul>
</li>
<li>Reduce data before using a JOIN
<ul>
<li>Trim the data as early in the query as possible, before the query performs a JOIN. If you reduce data early in the processing cycle, shuffling and other complex operations only execute on the data that you need.</li>
<li>Use sub queries with filters or intermediate tables or views as a way of decreasing sides of a join, prior to the join itself.</li>
</ul>
</li>
<li>Do not treat WITH clauses as prepared statements
<ul>
<li>WITH clauses are used primarily for readability because they are not materialized. For example, placing all your queries in WITH clauses and then running UNION ALL is a misuse of the WITH clause. If a query appears in more than one WITH clause, it executes in each clause.</li>
</ul>
</li>
<li>Use approximate aggregation functions
<ul>
<li>If the SQL aggregation function you're using has an equivalent approximation function, the approximation function will yield faster query performance. For example, instead of using <code>COUNT(DISTINCT)</code>, use <code>APPROX_COUNT_DISTINCT()</code>.</li>
<li>See <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators#approximate-aggregate-functions">approximate aggregation functions</a> in the standard SQL reference.</li>
</ul>
</li>
<li>Reference the data size prediction (&quot;This query will process X bytes&quot;) in STMO and the BigQuery UI to help gauge the efficiency of your queries. You should see this number go down as you limit the range of <code>submission_date</code>s or include fewer fields in your <code>SELECT</code> statement. For clustered tables, this estimate won't take into account benefits from <code>LIMIT</code>s and <code>WHERE</code> clauses on clustering fields, so you'll need to compare to the actual &quot;Data Scanned&quot; after the query is run. <a href="https://cloud.google.com/bigquery/pricing#on_demand_pricing">Queries are charged by data scanned at $5/TB</a> so each 200 GB of data scanned will cost $1; it can be useful to keep the data estimate below 200 GB while developing and testing a query to limit cost and query time, then open up to the full range of data you need when you have confidence in the results.</li>
</ul>
<p>A complete list of optimizations can be found <a href="https://cloud.google.com/bigquery/docs/best-practices-performance-overview">here</a> and cost optimizations <a href="https://cloud.google.com/bigquery/docs/best-practices-costs">here</a></p>
<h1><a class="header" href="#scheduling-bigquery-queries-in-airflow" id="scheduling-bigquery-queries-in-airflow">Scheduling BigQuery Queries in Airflow</a></h1>
<p>Queries in <a href="https://github.com/mozilla/bigquery-etl"><code>bigquery-etl</code></a> can be scheduled in 
<a href="https://github.com/mozilla/telemetry-airflow">Airflow</a> to be run regularly with the results written to a table.</p>
<ul>
<li><a href="cookbooks/bigquery-airflow.html#in-bigquery-etl">In bigquery-etl</a></li>
<li><a href="cookbooks/bigquery-airflow.html#in-telemetry-airflow">In telemetry-airflow</a></li>
<li><a href="cookbooks/bigquery-airflow.html#other-considerations">Other considerations</a></li>
</ul>
<h2><a class="header" href="#in-bigquery-etl" id="in-bigquery-etl">In bigquery-etl</a></h2>
<p>In the <a href="https://github.com/mozilla/bigquery-etl"><code>bigquery-etl</code></a> project, queries are written in <code>/templates</code>.
The directory structure is based on the destination table: <code>/templates/{dataset_id}/{table_name}</code>.
For example, <a href="https://github.com/mozilla/bigquery-etl/blob/8822b522aad4a5199a56f5b6143804a91228ad86/templates/telemetry/core_clients_last_seen_raw_v1/query.sql"><code>/templates/telemetry/core_clients_last_seen_raw_v1/query.sql</code></a>
is a query that will write results to the <code>core_clients_last_seen_raw_v1</code> table in the <code>telemetry</code> dataset.
This can be overridden in Airflow.</p>
<p>If we want to create a new table of just <code>client_id</code>'s each day called <code>client_ids</code> in the <code>example</code> dataset, 
we should create <code>/templates/example/client_ids/query.sql</code>:</p>
<pre><code class="language-sql">SELECT
  DISTINCT(client_id),
  submission_date
FROM
    telemetry_derived.main_summary_v4
WHERE
  submission_date = @submission_date
</code></pre>
<p><code>@submission_date</code> is a parameter that will be filled in by Airflow.</p>
<p>After <code>/templates/example/client_ids/query.sql</code> is created, 
<code>/script/generate_sql</code> can be run to generate the associated query in <code>/sql/examples/client_ids/query.sql</code>
which is the query that will be run by the Airflow task.</p>
<p>Commit both changes in <code>templates/</code> and <code>/sql</code>. 
When a commit is made to master in <code>bigquery-etl</code>, the Docker image is pushed and available to Airflow.</p>
<h2><a class="header" href="#in-telemetry-airflow" id="in-telemetry-airflow">In telemetry-airflow</a></h2>
<p>The next step is to create a DAG or add a task to an existing DAG that will run the query.<br />
In <a href="https://github.com/mozilla/telemetry-airflow">telemetry-airflow</a>, BigQuery related functions are found in <code>/dags/utils/gcp.py</code>.
The function we are interested in is <a href="https://github.com/mozilla/telemetry-airflow/blob/c103f3eee4ddc653316325d0ee0deab0bb35ee57/dags/utils/gcp.py#L390"><code>bigquery_etl_query</code></a>.</p>
<p>For our <code>client_ids</code> example, we could create a new DAG, <code>/dags/client_ids.py</code>:</p>
<pre><code class="language-python">from airflow import models
from utils.gcp import bigquery_etl_query

default_args = {
    ...
}

dag_name = 'client_ids'

with models.DAG(dag_name, schedule_interval='0 1 * * *', default_args=default_args) as dag:
    client_ids = bigquery_etl_query(
        task_id='client_ids',
        destination_table='client_ids',
        dataset_id='example'
    )
</code></pre>
<p>By default, <code>bigquery_etl_query</code> will execute the query in <code>/sql/{dataset_id}/{destination_table}/query.sql</code> 
and write to the <code>derived-datasets</code> project but this can be changed via the function arguments.</p>
<p>This DAG will then execute <code>/sql/example/client_ids/query.sql</code> every day, 
writing results to the <code>client_ids</code> table in the <code>example</code> dataset in the <code>derived-datasets</code> project.</p>
<h2><a class="header" href="#other-considerations-1" id="other-considerations-1">Other considerations</a></h2>
<ul>
<li>The Airflow task will overwrite the destination table partition
<ul>
<li>Destination table should be partitioned by <code>submission_date</code></li>
<li><code>date_partition_parameter</code> argument in <code>bigquery_etl_query</code> can be set to <code>None</code> to overwrite the whole table</li>
</ul>
</li>
<li>Airflow can be tested locally following instructions here: 
<a href="https://github.com/mozilla/telemetry-airflow#testing-gke-jobs-including-bigquery-etl-changes">https://github.com/mozilla/telemetry-airflow#testing-gke-jobs-including-bigquery-etl-changes</a></li>
<li>It's possible to change the Docker image that Airflow uses to test changes to <code>bigquery-etl</code> before merging changes to master
<ul>
<li>Supply a value to the <code>docker_image</code> argument in <code>bigquery_etl_query</code></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#dataset-specific" id="dataset-specific">Dataset Specific</a></h1>
<h1><a class="header" href="#working-with-normandy-events" id="working-with-normandy-events">Working with Normandy events</a></h1>
<p>A common request is to count the number of users who have
enrolled or unenrolled from a SHIELD experiment.</p>
<p>The <a href="cookbooks/../datasets/batch_view/events/intro.html"><code>events</code> table</a>
includes Normandy enrollment and unenrollment events
for both pref-flip and add-on studies.
Note that the events table is updated nightly.</p>
<p>Normandy events have <code>event_category</code> <code>normandy</code>.
The <code>event_string_value</code> will contain the experiment slug (for pref-flip experiments)
or name (for add-on experiments).</p>
<p>Normandy events are described in detail in the
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/normandy/normandy/data-collection.html#enrollment">Firefox source tree docs</a>.</p>
<p>Note that addon studies do not have branch information in the events table,
since addons, not Normandy, are responsible for branch assignment.
For studies built with the <a href="https://github.com/mozilla/shield-studies-addon-utils">add-on utilities</a>,
branch assignments are published to the
<a href="https://docs.telemetry.mozilla.org/datasets/shield.html#telemetry_shield_study_parquet"><code>telemetry_shield_study_parquet</code></a> dataset.</p>
<h2><a class="header" href="#counting-pref-flip-enrollment-events-by-branch" id="counting-pref-flip-enrollment-events-by-branch">Counting pref-flip enrollment events by branch</a></h2>
<p>The <code>event_map_values</code> column of enroll events contains a <code>branch</code> key,
describing which branch the user enrolled in.</p>
<p>To fetch a count of events by branch in PySpark:</p>
<pre><code class="language-python">import pyspark.sql.functions as f
events = spark.table(&quot;events&quot;)

# For example...
EXPERIMENT_SLUG = &quot;prefflip-webrender-v1-2-1492568&quot;
EXPERIMENT_START = &quot;20180920&quot;

enrollments_by_day = (
  events
  .filter(events.event_category == &quot;normandy&quot;)
  .filter(events.event_method == &quot;enroll&quot;)
  .filter(events.event_string_value == EXPERIMENT_SLUG)
  .filter(events.submission_date_s3 &gt;= EXPERIMENT_START)
  .withColumn(&quot;branch&quot;, events.event_map_values.getItem(&quot;branch&quot;))
  .groupBy(events.submission_date_s3, &quot;branch&quot;)
  .agg(f.count(&quot;*&quot;).alias(&quot;n&quot;))
  .toPandas()
)
</code></pre>
<p>Equivalently, in BigQuery SQL:</p>
<pre><code class="language-sql">SELECT
  submission_date_s3,
  udf.get_key(event_map_values, 'branch') AS branch,
  COUNT(*) AS n
FROM telemetry.events
WHERE
  event_category = 'normandy'
  AND event_method = 'enroll'
  AND event_string_value = '{{experiment_slug}}'
  AND submission_date_s3 &gt;= '{{experiment_start}}'
GROUP BY 1, 2
ORDER BY 1, 2
</code></pre>
<h2><a class="header" href="#counting-pref-flip-unenrollment-events-by-branch" id="counting-pref-flip-unenrollment-events-by-branch">Counting pref-flip unenrollment events by branch</a></h2>
<p>The <code>event_map_values</code> column of unenroll events includes a <code>reason</code> key.
Reasons are described in the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/normandy/normandy/data-collection.html#enrollment">Normandy docs</a>.
Normal unenroll events at the termination of a study will occur for the reason <code>recipe-not-seen</code>.</p>
<p>To fetch a count of events by reason and branch in PySpark:</p>
<pre><code class="language-python">unenrollments_by_reason = (
  events
  .filter(events.event_category == &quot;normandy&quot;)
  .filter(events.event_method == &quot;unenroll&quot;)
  .filter(events.event_string_value == EXPERIMENT_SLUG)
  .filter(events.submission_date_s3 &gt;= EXPERIMENT_START)
  .withColumn(&quot;branch&quot;, events.event_map_values.getItem(&quot;branch&quot;))
  .withColumn(&quot;reason&quot;, events.event_map_values.getItem(&quot;reason&quot;))
  .groupBy(events.submission_date_s3, &quot;branch&quot;, &quot;reason&quot;)
  .agg(f.count(&quot;*&quot;).alias(&quot;n&quot;))
  .toPandas()
)

</code></pre>
<h1><a class="header" href="#real-time" id="real-time">Real-time</a></h1>
<h1><a class="header" href="#creating-a-real-time-analysis-plugin" id="creating-a-real-time-analysis-plugin">Creating a Real-time Analysis Plugin</a></h1>
<blockquote>
<p>This technique relies on the AWS ingestion pipeline.
In <a href="cookbooks/bigquery.html">BigQuery</a>, the tables in the <code>moz-fx-data-shared-prod:telemetry_live</code> dataset
have only a few minutes of latency, so you can query those from STMO or the BigQuery console
for near real-time data access instead of writing an analysis plugin.</p>
</blockquote>
<h2><a class="header" href="#getting-started-1" id="getting-started-1">Getting Started</a></h2>
<p>Creating an analysis plugin consists of three steps:</p>
<ol>
<li>
<p>Writing a message matcher</p>
<p>The message matcher allows one to select specific data from the data stream.</p>
</li>
<li>
<p>Writing the analysis code/business logic</p>
<p>The analysis code allows one to aggregate, detect anomalies, apply machine
learning algorithms etc.</p>
</li>
<li>
<p>Writing the output code</p>
<p>The output code allows one to structure the analysis results in an easy to
consume format.</p>
</li>
</ol>
<h3><a class="header" href="#step-by-step-setup" id="step-by-step-setup">Step by Step Setup</a></h3>
<ol>
<li>
<p>Go to the CEP site: https://pipeline-cep.prod.mozaws.net/</p>
</li>
<li>
<p>Login/Register using your Google <code>@mozilla.com</code> account</p>
</li>
<li>
<p>Click on the <code>Plugin Deployment</code> tab</p>
</li>
<li>
<p>Create a message matcher</p>
<ol>
<li>
<p>Edit the <code>message_matcher</code> variable in the <code>Heka Analysis Plugin Configuration</code>
text area. For this example we are selecting all telemetry messages. The
full syntax of the message matcher can be found here:
http://mozilla-services.github.io/lua_sandbox/util/message_matcher.html</p>
<pre><code class="language-lua">message_matcher = &quot;Type == 'telemetry'&quot;
</code></pre>
</li>
</ol>
</li>
<li>
<p>Test the message matcher</p>
<ol>
<li>
<p>Click the <code>Run Matcher</code> button.</p>
<p>Your results or error message will appear to the right.  You can browse
the returned messages to examine their structure and the data they
contain; this is very helpful when developing the analysis code but is
also useful for data exploration even when not developing a plugin.</p>
</li>
</ol>
</li>
<li>
<p>Delete the code in the <code>Heka Analysis Plugin</code> text area</p>
</li>
<li>
<p>Create the Analysis Code (<code>process_message</code>)</p>
<p>The <code>process_message</code> function is invoked every time a message is matched and
should return 0 for success and -1 for failure. Full interface documentation:
http://mozilla-services.github.io/lua_sandbox/heka/analysis.html</p>
<ol>
<li>
<p>Here is the minimum  implementation; type it into the
<code>Heka Analysis Plugin</code> text area:</p>
<pre><code class="language-lua">function process_message()
    return 0 -- success
end
</code></pre>
</li>
</ol>
</li>
<li>
<p>Create the Output Code (<code>timer_event</code>)</p>
<p>The <code>timer_event</code> function is invoked every <code>ticker_interval</code> seconds.</p>
<ol>
<li>
<p>Here is the minimum implementation; type it into the <code>Heka Analysis Plugin</code>
text area:</p>
<pre><code class="language-lua">function timer_event()
end
</code></pre>
</li>
</ol>
</li>
<li>
<p>Test the Plugin</p>
<ol>
<li>
<p>Click the <code>Test Plugin</code> button.</p>
<p>Your results or error message will appear to the right. If an error is
output, correct it and test again.</p>
</li>
</ol>
</li>
<li>
<p>Extend the Code to Perform a Simple Message Count Analysis/Output</p>
<ol>
<li>
<p>Replace the code in the <code>Heka Analysis Plugin</code> text area with the
following:</p>
<pre><code class="language-lua">local cnt = 0
function process_message()
    cnt = cnt + 1                       -- count the number of messages that matched
    return 0
end

function timer_event()
    inject_payload(&quot;txt&quot;, &quot;types&quot;, cnt) -- output the count
end
</code></pre>
</li>
</ol>
</li>
<li>
<p>Test the Plugin</p>
<ol>
<li>
<p>Click the <code>Test Plugin</code> button.</p>
<p>Your results or error message will appear to the right. If an error is
output, correct it and test again.</p>
</li>
</ol>
</li>
<li>
<p>Extend the Code to Perform a More Complex Count by Type Analysis/Output</p>
<ol>
<li>
<p>Replace the code in the <code>Heka Analysis Plugin</code> text area with the
following:</p>
<pre><code class="language-lua">types = {}
function process_message()
    -- read the docType from the message, if it doesn't exist set it to &quot;unknown&quot;
    local dt = read_message(&quot;Fields[docType]&quot;) or &quot;unknown&quot;

    -- look up the docType in the types hash
    local cnt = types[dt]
    if cnt then
        types[dt] = cnt + 1   -- if the type cnt exists, increment it by one
    else
        types[dt] = 1         -- if the type cnt didn't exist, initialize it to one
    end
    return 0
end

function timer_event()
    add_to_payload(&quot;docType = Count\n&quot;)   -- add a header to the output
    for k, v in pairs(types) do           -- iterate over all the key/values (docTypes/cnt in the hash)
        add_to_payload(k, &quot; = &quot;, v, &quot;\n&quot;) -- add a line to the output
    end
    inject_payload(&quot;txt&quot;, &quot;types&quot;)        -- finalize all the data written to the payload
end
</code></pre>
</li>
</ol>
</li>
<li>
<p>Test the Plugin</p>
<ol>
<li>
<p>Click the <code>Test Plugin</code> button.</p>
<p>Your results or error message will appear to the right. If an error is
output, correct it and test again.</p>
</li>
</ol>
</li>
<li>
<p>Deploy the plugin</p>
<ol>
<li>Click the <code>Deploy Plugin</code> button and dismiss the successfully deployed
dialog.</li>
</ol>
</li>
<li>
<p>View the running plugin</p>
<ol>
<li>Click the <code>Plugins</code> tab and look for the plugin that was just deployed
<code>{user}.example</code></li>
<li>Right click on the plugin to active the context menu allowing you to view
the source or stop the plugin.</li>
</ol>
</li>
<li>
<p>View the plugin output</p>
<ol>
<li>Click on the <code>Dashboards</code> tab</li>
<li>Click on the <code>Raw Dashboard Output</code> link</li>
<li>Click on <code>analysis.{user}.example.types.txt</code> link</li>
</ol>
</li>
</ol>
<h3><a class="header" href="#where-to-go-from-here" id="where-to-go-from-here">Where to go from here</a></h3>
<ul>
<li>Lua Reference: http://www.lua.org/manual/5.1/manual.html</li>
<li>Available Lua Modules: https://mozilla-services.github.io/lua_sandbox_extensions/</li>
<li>Support
<ul>
<li>IRC: <a href="irc://irc.mozilla.org/hindsight">#hindsight on <code>irc.mozilla.org</code></a></li>
<li>Mailing list: https://mail.mozilla.org/listinfo/hindsight</li>
</ul>
</li>
</ul>
<h1><a class="header" href="#see-my-pings" id="see-my-pings">See My Pings</a></h1>
<p>So you want to see what you're sending the telemetry pipeline, huh?
Well follow these steps and we'll have you perusing your own data in no time.</p>
<h2><a class="header" href="#steps-to-viewing-your-pings" id="steps-to-viewing-your-pings">Steps to Viewing Your Pings</a></h2>
<ol>
<li>
<p>Get your <code>clientId</code> from whatever product you're using. For desktop, it's available in <code>about:telemetry</code>.</p>
</li>
<li>
<p>Go <a href="https://sql.telemetry.mozilla.org">STMO</a>.</p>
</li>
<li>
<p>Enter the following query: ```sql
SELECT
submission_timestamp,
document_id --FIXME
FROM
telemetry_live.main_v4 -- or crash, event, core, etc
WHERE
submission_timestamp &gt; TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 3 HOUR)
AND client_id = '&lt;your_client_id&gt;'
ORDER BY
submission_timestamp DESC
LIMIT 10</p>
</li>
</ol>
<pre><code>
This will show you the timestamp and document id of the ten most recent
`main` pings you've sent in the last 3 hours.
You may include any other fields here that might be of interest to you.

The tables in the `telemetry_live` dataset have only a few minutes of
latency, so you can query those tables for pings from your `client_id`
with minimal additional waiting.

One thing to note is that BigQuery has its own query cache, so if you
run the same query several times in a row, it may fetch results from
its cache. You can make any change at all (such as adding a comment)
to force the query to run again and fetch updated results.
</code></pre>
<h1><a class="header" href="#cep-matcher" id="cep-matcher">CEP Matcher</a></h1>
<blockquote>
<p>This technique relies on the AWS ingestion pipeline.
In <a href="tools/../cookbooks/bigquery.html">BigQuery</a>, the tables in the <code>moz-fx-data-shared-prod:telemetry_live</code> dataset
have only a few minutes of latency, so you can query those from STMO or the BigQuery console
for near real-time data access instead of writing an analysis plugin.</p>
</blockquote>
<p>The CEP Matcher tab lets you easily view some current pings of any ping type. To access it, follow
<a href="tools/../cookbooks/realtime_analysis_plugin.html">these first few directions</a> for accessing the CEP. Once there,
click on the &quot;Matcher&quot; tab. The message-matcher is set by default to <code>TRUE</code>, meaning all pings will
be matched. Click &quot;Run Matcher&quot; and a few pings will show up.</p>
<h2><a class="header" href="#editing-the-message-matcher" id="editing-the-message-matcher">Editing the Message Matcher</a></h2>
<p>Changing the message matcher will filter down the accepted pings, letting you hone in on a certain type.
Generally, you can filter on any fields in a ping. For example, <code>docType</code>:</p>
<pre><code>Fields[docType] == &quot;main&quot;
</code></pre>
<p>Or OS:</p>
<pre><code>Fields[os] == &quot;Android&quot;
</code></pre>
<p>We can also combine matchers together:</p>
<pre><code>Fields[docType] == &quot;core&quot; &amp;&amp; Fields[os] == &quot;Android&quot; &amp;&amp; Fields[appName] == &quot;Focus&quot;
</code></pre>
<p>Note that most of the time, you want just proper telemetry pings, so include this in your matcher:</p>
<pre><code>Type == &quot;telemetry&quot;
</code></pre>
<p>Which would get us a sample of Focus Android core pings.</p>
<p>The <a href="https://hekad.readthedocs.io/en/v0.10.0/message_matcher.html">Message Matcher documentation</a> has
more information on the syntax.</p>
<p>To see the available fields that you can filter on for any <code>docType</code>, see <a href="https://pipeline-cep.prod.mozaws.net/dashboard_output/analysis.moz_telemetry_parquet_schema.parquet.txt">this document</a>.
For example, look under the <code>telemetry</code> top-level field at <code>system-addon-deployment-diagnostics</code>. The available fields to filter on are:</p>
<pre><code>required binary Logger;
required fixed_len_byte_array(16) Uuid;
optional int32 Pid;
optional int32 Severity;
optional binary EnvVersion;
required binary Hostname;
required int64 Timestamp;
optional binary Payload;
required binary Type;
required group Fields {
    required binary submission;
    required binary Date;
    required binary appUpdateChannel;
    required double sourceVersion;
    required binary documentId;
    required binary docType;
    required binary os;
    optional binary environment.addons;
    optional binary DNT;
    required binary environment.partner;
    required binary sourceName;
    required binary appVendor;
    required binary environment.profile;
    required binary environment.settings;
    required binary normalizedChannel;
    required double sampleId;
    required binary Host;
    required binary geoCountry;
    required binary geoCity;
    required boolean telemetryEnabled;
    required double creationTimestamp;
    required binary appVersion;
    required binary appBuildId;
    required binary environment.system;
    required binary environment.build;
    required binary clientId;
    required binary submissionDate;
    required binary appName;
}
</code></pre>
<p>So, for example, you could have a message matcher like:</p>
<pre><code>Type == &quot;telemetry&quot; &amp;&amp; Fields[geoCountry] == &quot;US&quot;
</code></pre>
<h1><a class="header" href="#metrics" id="metrics">Metrics</a></h1>
<h1><a class="header" href="#daily-and-monthly-active-users-dau-and-mau" id="daily-and-monthly-active-users-dau-and-mau">Daily and Monthly Active Users (DAU and MAU)</a></h1>
<p>For the purposes of DAU, a profile is considered active if it sends any main ping.</p>
<ul>
<li>Dates are defined by <code>submission_date_s3</code> or <code>submission_date</code>.</li>
</ul>
<p><strong>DAU</strong> is the number of clients sending a main ping on a given day.</p>
<p><strong>MAU</strong> is the number of unique clients who have been a DAU on any day in the last <strong>28 days</strong>. In other words, any client that contributes to DAU in the last 28 days would also contribute to MAU for that day. Note that this is not simply the sum of DAU over 28 days, since any particular client could be active on many days.</p>
<p><strong>WAU</strong> is the number of unique clients who have been a DAU on any day in the last <strong>7 days</strong>. Caveats above for MAU also apply to WAU.</p>
<p>To make the time boundaries more clear, let's consider a particular date 2019-01-28. The DAU number assigned to 2019-01-28 should consider all main pings received during 2019-01-28 UTC. We cannot observe the full data until 2019-01-28 closes (and in practice we need to wait a bit longer since we are usually referencing derived datasets like <code>clients_daily</code> that are updated once per day over several hours following midnight UTC), so the earliest we can calculate this value is on 2019-01-29. If plotted as a time series, this value should always be plotted at the point labeled 2019-01-28. Likewise, MAU for 2019-01-28 should consider a 28 day range that includes main pings received on 2019-01-28 and back to beginning of day UTC 2019-01-01. Again, the earliest we can calculate the value is on 2019-01-29.</p>
<p>For quick analysis, using <a href="cookbooks/../datasets/bigquery/exact_mau/reference.html"><code>firefox_desktop_exact_mau28_by_dimensions</code></a> is recommended. Below is an example query for getting MAU, WAU, and DAU for 2018 using <code>firefox_desktop_exact_mau28_by_dimensions</code>.</p>
<pre><code class="language-sql">SELECT
  submission_date,
  SUM(mau) AS mau,
  SUM(wau) AS wau,
  SUM(dau) AS dau
FROM
  telemetry.firefox_desktop_exact_mau28_by_dimensions
WHERE
  submission_date_s3 &gt;= '2018-01-01'
  AND submission_date_s3 &lt; '2019-01-01'
GROUP BY
  submission_date
ORDER BY
  submission_date
</code></pre>
<p>For analysis of dimensions not available in <code>firefox_desktop_exact_mau28_by_dimensions</code>, using <a href="cookbooks/../datasets/bigquery/clients_last_seen/reference.html"><code>clients_last_seen</code></a> is recommended. Below is an example query for getting MAU, WAU, and DAU by <code>app_version</code> for 2018 using <code>clients_last_seen</code>.</p>
<pre><code class="language-sql">SELECT
  submission_date,
  app_version,
  -- days_since_seen is always between 0 and 28, so MAU could also be
  -- calculated with COUNT(days_since_seen) or COUNT(*)
  COUNTIF(days_since_seen &lt; 28) AS mau,
  COUNTIF(days_since_seen &lt; 7) AS wau,
  -- days_since_* values are always between 0 and 28 or null, so DAU could also
  -- be calculated with COUNTIF(days_since_seen = 0)
  COUNTIF(days_since_seen &lt; 1) AS dau
FROM
  telemetry.clients_last_seen
WHERE
  submission_date_s3 &gt;= '2018-01-01'
  AND submission_date_s3 &lt; '2019-01-01'
GROUP BY
  submission_date,
  app_version
ORDER BY
  submission_date,
  app_version
</code></pre>
<p>For analysis of only DAU, using <a href="cookbooks/../datasets/batch_view/clients_daily/reference.html"><code>clients_daily</code></a> is more efficient than <code>clients_last_seen</code>. Getting MAU and WAU from <code>clients_daily</code> is not recommended. Below is an example query for getting DAU for 2018 using <code>clients_daily</code>.</p>
<pre><code class="language-sql">SELECT
  submission_date_s3,
  COUNT(*) AS dau
FROM
  telemetry.clients_daily
WHERE
  -- In BigQuery use yyyy-MM-DD, e.g. '2018-01-01'
  submission_date_s3 &gt;= '20180101'
  AND submission_date_s3 &lt; '20190101'
GROUP BY
  submission_date_s3
ORDER BY
  submission_date_s3
</code></pre>
<p><a href="cookbooks/../datasets/batch_view/main_summary/reference.html"><code>main_summary</code></a> can also be used for getting DAU. Below is an example query using a 1% sample over March 2018 using <code>main_summary</code>:</p>
<pre><code class="language-sql">SELECT
  submission_date_s3,
  -- Note: this does not include NULL client_id in count where above methods do
  COUNT(DISTINCT client_id) * 100 AS DAU
FROM
  telemetry.main_summary
WHERE
  sample_id = '51'
  -- In BigQuery use yyyy-MM-DD, e.g. '2018-03-01'
  AND submission_date_s3 &gt;= '20180301'
  AND submission_date_s3 &lt; '20180401'
GROUP BY
  submission_date_s3
ORDER BY
  submission_date_s3
</code></pre>
<h1><a class="header" href="#active-dau-and-active-mau" id="active-dau-and-active-mau">Active DAU and Active MAU</a></h1>
<p>An <strong>Active User</strong> is defined as a client who has <code>total_daily_uri</code> &gt;= 5 URI for a given date.</p>
<ul>
<li>Dates are defined by <code>submission_date</code> (<em>not</em> by <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1422892">client activity date</a>).</li>
<li>A client's <code>total_daily_uri</code> is defined as their sum of <code>scalar_parent_browser_engagement_total_uri_count</code> for a given date<sup><a href="cookbooks/active_dau.html#total_uri_count">1</a></sup>.</li>
</ul>
<p><strong>Active DAU</strong> (aDAU) is the number of Active Users on a given day.</p>
<p><strong>Active MAU</strong> (aMAU) is the number of unique clients who have been an Active User on any day in the last <strong>28 days</strong>. In other words, any client that contributes to aDAU in the last 28 days would also contribute to aMAU for that day. Note that this is not simply the sum of aDAU over 28 days, since any particular client could be active on many days.</p>
<p><strong>Active WAU</strong> (aWAU) is the number of unique clients who have been an Active User on any day in the last <strong>7 days</strong>. Caveats above for aMAU also apply to aWAU.</p>
<p>To make the time boundaries more clear, let's consider a particular date 2019-01-28. The aDAU number assigned to 2019-01-28 should consider all main pings received during 2019-01-28 UTC. We cannot observe the full data until 2019-01-28 closes (and in practice we need to wait a bit longer since we are usually referencing derived datasets like <code>clients_daily</code> that are updated once per day over several hours following midnight UTC), so the earliest we can calculate this value is on 2019-01-29. If plotted as a time series, this value should always be plotted at the point labeled 2019-01-28. Likewise, aMAU for 2019-01-28 should consider a 28 day range that includes main pings received on 2019-01-28 and back to beginning of day UTC 2019-01-01. Again, the earliest we can calculate the value is on 2019-01-29.</p>
<p>For quick analysis, using <a href="cookbooks/../datasets/bigquery/exact_mau/reference.html"><code>firefox_desktop_exact_mau28_by_dimensions</code></a> is recommended. Below is an example query for getting MAU, WAU, and DAU for 2018 using <code>firefox_desktop_exact_mau28_by_dimensions</code>.</p>
<pre><code class="language-sql">SELECT
  submission_date,
  SUM(visited_5_uri_mau) AS visited_5_uri_mau,
  SUM(visited_5_uri_wau) AS visited_5_uri_wau,
  SUM(visited_5_uri_dau) AS visited_5_uri_dau
FROM
  telemetry.firefox_desktop_exact_mau28_by_dimensions
WHERE
  submission_date_s3 &gt;= '2018-01-01'
  AND submission_date_s3 &lt; '2019-01-01'
GROUP BY
  submission_date
ORDER BY
  submission_date
</code></pre>
<p>For analysis of dimensions not available in <code>firefox_desktop_exact_mau28_by_dimensions</code>, using <a href="cookbooks/../datasets/bigquery/clients_last_seen/reference.html"><code>clients_last_seen</code></a> is recommended. Below is an example query for getting aMAU, aWAU, and aDAU by <code>app_version</code> for 2018 using <code>clients_last_seen</code>.</p>
<pre><code class="language-sql">SELECT
  submission_date,
  app_version,
  -- days_since_* values are always &lt; 28 or null, so aMAU could also be
  -- calculated with COUNT(days_since_visited_5_uri)
  COUNTIF(days_since_visited_5_uri &lt; 28) AS visited_5_uri_mau,
  COUNTIF(days_since_visited_5_uri &lt; 7) AS visited_5_uri_wau,
  -- days_since_* values are always &gt;= 0 or null, so aDAU could also be
  -- calculated with COUNTIF(days_since_visited_5_uri = 0)
  COUNTIF(days_since_visited_5_uri &lt; 1) AS visited_5_uri_dau
FROM
  telemetry.clients_last_seen
WHERE
  submission_date_s3 &gt;= '2018-01-01'
  AND submission_date_s3 &lt; '2019-01-01'
GROUP BY
  submission_date,
  app_version
ORDER BY
  submission_date,
  app_version
</code></pre>
<p>For analysis of only aDAU, using <a href="cookbooks/../datasets/batch_view/clients_daily/reference.html"><code>clients_daily</code></a> is more efficient than <code>clients_last_seen</code>. Getting aMAU and aWAU from <code>clients_daily</code> is not recommended. Below is an example query for getting aDAU for 2018 using <code>clients_daily</code>.</p>
<pre><code class="language-sql">SELECT
  submission_date_s3,
  COUNT(*) AS visited_5_uri_dau
FROM
  telemetry.clients_daily
WHERE
  scalar_parent_browser_engagement_total_uri_count_sum &gt;= 5
  -- In BigQuery use yyyy-MM-DD, e.g. '2018-01-01'
  AND submission_date_s3 &gt;= '20180101'
  AND submission_date_s3 &lt; '20190101'
GROUP BY
  submission_date_s3
ORDER BY
  submission_date_s3
</code></pre>
<p><a href="cookbooks/../datasets/batch_view/main_summary/reference.html"><code>main_summary</code></a> can also be used for getting aDAU. Below is an example query using a 1% sample over March 2018 using <code>main_summary</code>:</p>
<pre><code class="language-sql">SELECT
  submission_date_s3,
  COUNT(*) * 100 AS visited_5_uri_dau
FROM (
  SELECT
    submission_date_s3,
    client_id,
    SUM(scalar_parent_browser_engagement_total_uri_count) &gt;= 5 AS visited_5_uri
  FROM
    telemetry.main_summary
  WHERE
    sample_id = '51'
    -- In BigQuery use yyyy-MM-DD, e.g. '2018-03-01'
    AND submission_date_s3 &gt;= '20180301'
    AND submission_date_s3 &lt; '20180401'
  GROUP BY
    submission_date_s3,
    client_id)
WHERE
  visited_5_uri
GROUP BY
  submission_date_s3
ORDER BY
  submission_date_s3
</code></pre>
<p><span id="total_uri_count"><strong>1</strong></span>: Note, the probe measuring <code>scalar_parent_browser_engagement_total_uri_count</code> only exists in clients with Firefox 50 and up. Clients on earlier versions of Firefox won't be counted as an Active User (regardless of their use). Similarly, <code>scalar_parent_browser_engagement_total_uri_count</code> doesn't increment when a client is in Private Browsing mode, so that won't be included as well.</p>
<p><em>Authored by the Product Data Science Team. Please direct questions/concerns to Ben Miroglio (<code>bmiroglio</code>).</em></p>
<h1><a class="header" href="#retention-1" id="retention-1">Retention</a></h1>
<p>Retention measures the rate at which users are <em>continuing</em> to use Firefox, making it one of the more important metrics we track. We commonly measure retention between releases, experiment cohorts, and various Firefox subpopulations to better understand how a change to the user experience or use of a specific feature affect behavior.</p>
<h2><a class="header" href="#n-week-retention" id="n-week-retention">N Week Retention</a></h2>
<p>Time is an embedded component of retention. Most retention analysis starts with some anchor, or action that is associated with a date (experiment enrollment date, profile creation date, button clicked on date <em>d</em>, etc.). We then look 1, 2, , N weeks beyond the anchor to see what percent of users have submitted a ping (signaling their continued use of Firefox).</p>
<p>For example, lets say we are calculating retention for new Firefox users. Each user can then be anchored by their <code>profile_creation_date</code>, and we can count the number of users who submitted a ping between 7-13 days after profile creation (1 Week retention), 14-20 days after profile creation (2 Week Retention), etc.</p>
<h3><a class="header" href="#example-methodology" id="example-methodology">Example Methodology</a></h3>
<p>Given a dataset in Spark, we can construct a field <code>retention_period</code> that uses <code>submission_date</code> to determine the period to which a ping belongs (i.e. if a user created their profile on April 1st, all pings submitted between April 8th and April 14th are assigned to week 1). 1-week retention can then be simplified to the percent of users with a 1 value for <code>retention_period</code>, 2-week retention simplifies to the percent of users with a 2 value for <code>retention_period</code>, ..., etc. Note that each retention period is independent of the others, so it is possible to have higher 2-week retention than 1-week retention (especially during holidays).</p>
<p>First let's map 1, 2, ..., N week retention the the amount of days elapsed after the anchor point:</p>
<pre><code class="language-python">PERIODS = {}
N_WEEKS = 6
for i in range(1, N_WEEKS + 1):
    PERIODS[i] = {
        'start': i * 7,
        'end': i * 7 + 6
    }
</code></pre>
<p>Which gives us</p>
<pre><code class="language-python">{1: {'end': 13, 'start': 7},
 2: {'end': 20, 'start': 14},
 3: {'end': 27, 'start': 21},
 4: {'end': 34, 'start': 28},
 5: {'end': 41, 'start': 35},
 6: {'end': 48, 'start': 42}}

</code></pre>
<p>Next, let's define some helper functions:</p>
<pre><code class="language-python">import datetime as dt
import pandas as pd
import pyspark.sql.types as st
import pyspark.sql.functions as F

udf = F.udf

def date_diff(d1, d2, fmt='%Y-%m-%d'):
    &quot;&quot;&quot;
    Returns days elapsed from d2 to d1 as an integer

    Params:
    d1 (str)
    d2 (str)
    fmt (str): format of d1 and d2 (must be the same)

    &gt;&gt;&gt; date_diff('2017-02-05', '2017-02-01')
    4

    &gt;&gt;&gt; date_diff('2017-02-01', '2017-02-05)
    -4
    &quot;&quot;&quot;
    try:
        return (pd.to_datetime(d1, format=fmt) -
                pd.to_datetime(d2, format=fmt)).days
    except:
        return None


@udf(returnType=st.IntegerType())
def get_period(anchor, submission_date):
    &quot;&quot;&quot;
    Given an anchor and a submission_date,
    returns what period a ping belongs to. This
    is a spark UDF.

    Params:
    anchor (col): anchor date
    submission_date (col): a ping's submission_date

    Global:
    PERIODS (dict): defined globally based on n-week method

    Returns an integer indicating the retention period
    &quot;&quot;&quot;
    if anchor is not None:
        diff = date_diff(submission_date, anchor)
        if diff &gt;= 7: # exclude first 7 days
            for period in sorted(PERIODS):
                if diff &lt;= PERIODS[period]['end']:
                    return period

@udf(returnType=st.StringType())
def from_unixtime_handler(ut):
    &quot;&quot;&quot;
    Converts unix time (in days) to a string in %Y-%m-%d format.
    This is a spark UDF.

    Params:
    ut (int): unix time in days

    Returns a date as a string if it is parsable by datetime, otherwise None
    &quot;&quot;&quot;
    if ut is not None:
        try:
            return (dt.datetime.fromtimestamp(ut * 24 * 60 * 60).strftime(&quot;%Y-%m-%d&quot;))
        except:
            return None

</code></pre>
<p>Now we can load in a subset of <code>main_summary</code> and construct the necessary fields for retention calculations:</p>
<pre><code class="language-python">ms = spark.read.format(&quot;bigquery&quot;) \
    .option(&quot;table&quot;, &quot;moz-fx-data-derived-datasets.telemetry_derived.main_summary_v4&quot;) \
    .load() \
    .where(&quot;submission_date &gt;= to_date('2018-04-01') AND submission_date &lt;= to_date('2018-06-03')&quot;) \
    .where(&quot;sample_id = 42&quot;) \
    .where(&quot;app_name = 'Firefox'&quot;) \
    .where(&quot;normalized_channel = 'release'&quot;) \
    .where(&quot;os in ('Darwin', 'Windows_NT', 'Linux')&quot;) \
    .select(&quot;client_id&quot;, &quot;submission_date&quot;, &quot;profile_creation_date&quot;, &quot;os&quot;)

PCD_CUTS = ('2018-04-01', '2018-04-15')

ms = (
    ms.withColumn(&quot;pcd&quot;, from_unixtime_handler(&quot;profile_creation_date&quot;)) # i.e. 17500 -&gt; '20171130'
      .filter(&quot;pcd &gt;= '{}'&quot;.format(PCD_CUTS[0]))
      .filter(&quot;pcd &lt;= '{}'&quot;.format(PCD_CUTS[1]))
      .withColumn(&quot;period&quot;, get_period(&quot;pcd&quot;, &quot;submission_date&quot;))
)
</code></pre>
<p>Note that we filter to profiles that were created in the first half of April so that we have sufficient time to observe 6 weeks of behavior. Now we can calculate retention!</p>
<pre><code class="language-python">os_counts = (
    ms
    .groupby(&quot;os&quot;)
    .agg(F.countDistinct(&quot;client_id&quot;).alias(&quot;total_clients&quot;))
)

weekly_counts = (
    ms
    .groupby(&quot;period&quot;, &quot;os&quot;)
    .agg(F.countDistinct(&quot;client_id&quot;).alias(&quot;n_week_clients&quot;))
)

retention_by_os = (
    weekly_counts
    .join(os_counts, on='os')
    .withColumn(&quot;retention&quot;, F.col(&quot;n_week_clients&quot;) / F.col(&quot;total_clients&quot;))
    # Add a 95% confidence interval based on the normal approximation for a binomial distribution,
    # p  z * sqrt(p*(1-p)/n).
    # The 95% CI spans the range `retention  ci_95_semi_interval`.
    .withColumn(
      &quot;ci_95_semi_interval&quot;,
      F.lit(1.96) * F.sqrt(F.col(&quot;retention&quot;) * (F.lit(1) - F.col(&quot;retention&quot;)) / F.col(&quot;total_clients&quot;))
    )
)
</code></pre>
<p>Peeking at 6-Week Retention</p>
<pre><code class="language-python">retention_by_os.filter(&quot;period = 6&quot;).show()
</code></pre>
<pre><code>+----------+------+--------------+-------------+-------------------+--------------------+
|        os|period|n_week_clients|total_clients| retention         | ci_95_semi_interval|
+----------+------+--------------+-------------+-------------------+--------------------+
|     Linux|     6|          1495|        22422|0.06667558647756668|0.003265266498407...|
|    Darwin|     6|          1288|         4734|0.27207435572454586|0.012677372722376635|
|Windows_NT|     6|         29024|       124872|0.23243000832852842|0.002342764476746...|
+----------+------+--------------+-------------+-------------------+--------------------+


</code></pre>
<p>we observe that 6.7%  0.3% of Linux users whose profile was created in the first half of April submitted a ping 6 weeks later, and so forth. The example code snippets are consolidated in <a href="https://dbc-caf9527b-e073.cloud.databricks.com/#notebook/61351/command/61352">this notebook</a>.</p>
<h3><a class="header" href="#new-vs-existing-user-retention" id="new-vs-existing-user-retention">New vs. Existing User Retention</a></h3>
<p>The above example calculates <strong>New User Retention</strong>, which is distinct from <strong>Existing User Retention</strong>. This distinction is important when understanding retention baselines (i.e. does this number make sense?). Existing users typically have much higher retention numbers than new users.</p>
<p>Note that is more common in industry to refer to Existing User Retention as &quot;Churn&quot; (Churn = 1 - Retention), however, we use retention across the board for the sake of consistency and interpretability.</p>
<p><strong>Please be sure to specify whether or not your retention analysis is for new or existing users.</strong></p>
<h3><a class="header" href="#what-if-theres-no-anchor-point" id="what-if-theres-no-anchor-point">What If There's No Anchor Point?</a></h3>
<p>Sometimes there isn't a clear anchor point like <code>profile_creation_date</code> or <code>enrollment_date</code>.</p>
<p>For example, imagine you are tasked with reporting retention numbers for users that enabled sync (<code>sync_configured</code>) compared to users that haven't. Being a boolean pref, there is no straightforward way to determine <em>when</em> <code>sync_enabled</code> flipped from <code>false</code> to <code>true</code> aside from looking at a client's entire history (which is not recommended!). What now?</p>
<p>We can construct an artificial anchor point using fixed weekly periods; the retention concepts then remain unchanged. The process can be summarized by the following steps:</p>
<ul>
<li>Define a baseline week cohort
<ul>
<li>For this example let's define the baseline as users that submitted pings between 2018-01-01 and 2018-01-07</li>
</ul>
</li>
<li>Count all users with/without sync enabled in this period</li>
<li>Assign these users to an anchor point of 2018-01-01 (the <strong>beginning</strong> of the baseline week)</li>
<li>Count the number of users in the baseline week that submitted a ping between 7-13 days after 2018-01-01 (1 Week retention), 14-20 days after 2018-01-01 (2 Week Retention), etc.</li>
<li>Shift the baseline week up 7 days (and all other dates) and repeat as necessary</li>
</ul>
<p>This method is also valid in the presence of an anchor point, however, it is recommended the anchor point method is employed when possible.</p>
<h3><a class="header" href="#confounding-factors" id="confounding-factors">Confounding Factors</a></h3>
<p>When performing retention analysis between two or more groups, it is important to look at other usage metrics to get an understanding of other influential factors.</p>
<p>For example (borrowing the sync example from the previous section) you find that users with and without sync have a 1 week retention of 0.80 and 0.40, respectively. Wow--we should really be be promoting sync as it could double retention numbers!</p>
<p><em>Not quite</em>. Turns out you next look at <code>active_ticks</code> and <code>total_uri_count</code> and find that sync users report much higher numbers for these measures as well. Now how can we explain this difference in retention?</p>
<p>There could be an entirely separate cookbook devoted to answering this question, however this contrived example is meant to demonstrate that simply comparing retention numbers between two groups isn't capturing the full story. Sans an experiment or model-based approach, all we can say is &quot;enabling sync is <strong>associated</strong> with higher retention numbers.&quot; There is still value in this assertion, however it should be stressed that <strong>association/correlation != causation!</strong></p>
<h1><a class="header" href="#collecting-new-data" id="collecting-new-data">Collecting New Data</a></h1>
<h2><a class="header" href="#guidelines" id="guidelines">Guidelines</a></h2>
<p>For information about what sorts of data may be collected,
and for information on getting a data collection request reviewed,
please read the <a href="https://wiki.mozilla.org/Firefox/Data_Collection">Data Collection Guidelines.</a></p>
<h2><a class="header" href="#mechanics" id="mechanics">Mechanics</a></h2>
<p>The mechanics of how to instrument new data collection in Firefox are covered in
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/start/adding-a-new-probe.html">Adding a new Telemetry probe</a>.</p>
<p>For non-Telemetry data collection, we have a mechanism for streamlining
ingestion of structured (JSON) data that utilizes the same underlying
infrastructure. See <a href="datasets/../cookbooks/new_ping.html">this cookbook</a> for details on using it.</p>
<h1><a class="header" href="#client-implementation-guidelines-for-experiments" id="client-implementation-guidelines-for-experiments">Client Implementation Guidelines for Experiments</a></h1>
<p>There are three supported approaches for enabling experimental features for Firefox:</p>
<ul>
<li><a href="cookbooks/client_guidelines.html#prefs">Firefox Prefs</a>
<ul>
<li>Prefs can be used to control features that <strong>land in-tree</strong>.
<a href="cookbooks/client_guidelines.html#feature-gates">Feature Gates</a> provide a wrapper around prefs that can be used from JavaScript.</li>
</ul>
</li>
<li><a href="cookbooks/client_guidelines.html#extensions">Firefox Extensions</a> AKA &quot;<strong>Add-ons</strong>&quot;.
<ul>
<li>If the feature being tested should not land in the tree, or if it will ultimately ship as an extension, then an extension should be used.</li>
</ul>
</li>
</ul>
<p>New features go through the standard Firefox review, testing, and deployment processes, and are then enabled experimentally in the field using <a href="https://github.com/mozilla/normandy">Normandy</a>.</p>
<h2><a class="header" href="#prefs" id="prefs">Prefs</a></h2>
<p>Firefox Preferences (AKA &quot;prefs&quot;) are commonly used to enable and disable features. However, prefs are more complex to implement correctly than <a href="cookbooks/client_guidelines.html#feature-gates">feature gates</a>.</p>
<p><strong>Each pref should represent a different experimental treatment</strong>. If your experimental feature requires multiple prefs, then Normandy does not currently support this but will soon. In the meantime, an <a href="cookbooks/client_guidelines.html#extensions">extension</a> such as <a href="https://github.com/nhnt11/multipreffer">multipreffer</a> may be used.</p>
<p>There are three types of Prefs:</p>
<ol>
<li>Built-in prefs - shipped with Firefox, in <code>firefox.js</code>.</li>
<li><code>user branch</code> - set by the user, overriding built-in prefs.</li>
<li><code>default branch</code> - Overrides both built-in and <code>user branch</code> prefs. Only persists until the browser session ends, next restart will revert to either built-in or <code>user branch</code> (if set).</li>
</ol>
<p><a href="https://github.com/mozilla/normandy">Normandy</a> supports overriding both the <code>user</code> and <code>default</code> branches, although the latter is preferred as it does not permanently override user settings. <code>default</code> branch prefs are simple to reset since they do not persist past a restart.</p>
<p><strong>In order for features to be activated experimentally using <code>default branch</code> prefs</strong>:</p>
<ul>
<li>The feature must not start up before <code>final-ui-startup</code> is observed.</li>
</ul>
<p>For instance, to set an observer:</p>
<pre><code>Services.obs.addObserver(this, &quot;final-ui-startup&quot;, true);
</code></pre>
<p>In this example, <code>this</code> would implement an <code>observe(subject, topic, data)</code> function which will be called when <code>final-ui-startup</code> is observed. See the <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Tech/XPCOM/Reference/Interface/nsIObserverService#addObserver()">Observer documentation</a> for more information.</p>
<ul>
<li>It must be possible to enable/disable the feature at runtime, via a pref change.</li>
</ul>
<p>This is similar to the observer pattern above:</p>
<pre><code>Services.prefs.addObserver(&quot;pref_name&quot;, this);
</code></pre>
<p>More information is available in the <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Tech/XPCOM/Reference/Interface/nsIPrefService">Preference service documentation</a>.</p>
<ul>
<li>
<p>Never use <code>Services.prefs.prefHasUserValue()</code>, or any other function specific to <code>user branch</code> prefs.</p>
</li>
<li>
<p>Prefs should be set by default in <code>firefox.js</code></p>
</li>
</ul>
<p>If your feature cannot abide by one or more of these rules (for instance, it needs to run at startup and/or cannot be toggled at runtime) then experimental preferences can be set on the <code>user branch</code>. This is more complex than using the methods described above; user branch prefs override the users choice, which is a really complex thing to try to support when flipping prefs experimentally. We also need to be careful to back up and reset the pref, and then figure out how to resolve conflicts if the user has changed the pref in the meantime.</p>
<h2><a class="header" href="#feature-gates" id="feature-gates">Feature Gates</a></h2>
<p>A new Feature Gate library for Firefox Desktop is now available.</p>
<p><strong>Each feature gate should represent a different experimental treatment</strong>. If your experimental feature requires multiple flags, then Normandy will not be able to support this directly and an <a href="cookbooks/client_guidelines.html#extensions">extension</a> may be used.</p>
<h3><a class="header" href="#feature-gate-caveats" id="feature-gate-caveats">Feature Gate caveats</a></h3>
<p>The current Feature Gate library comes with a few caveats, and may not be appropriate for your situation:</p>
<ul>
<li>Only JS is supported.</li>
<li>Always asynchronous.</li>
</ul>
<p>Future versions of the Feature Gate API will include C++/Rust support and a synchronous API.</p>
<h3><a class="header" href="#using-the-feature-gate-library" id="using-the-feature-gate-library">Using the Feature Gate library</a></h3>
<p>Read <a href="https://firefox-source-docs.mozilla.org/toolkit/components/featuregates/featuregates/index.html">the documentation</a> to get started.</p>
<h2><a class="header" href="#extensions" id="extensions">Extensions</a></h2>
<p>Firefox currently supports the <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions">Web Extensions API</a>.</p>
<p><strong>If new WebExtension APIs are needed, they should land in-tree</strong>. Extensions which are signed by Mozilla can load privileged code using the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/extensions/webextensions/index.html">WebExtension Experiments</a>, but this is not preferred.</p>
<p>WebExtensions go through the same correctness and performance tests as other features. This is possible using the Mozilla tryserver by dropping your XPI into <code>testing/profiles/common/extensions</code> in <code>mozilla-central</code> and pushing to Tryserver - see the <a href="cookbooks/client_guidelines.html#testing-extensions">Testing Extensions</a> section below.</p>
<p>NOTE - it is ideal to test against the version of Firefox which the extension will release against, but there is a <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1435403">bug related to artifact builds on release channels</a> which must be worked around. The workaround is pretty simple (modify an <code>artifacts.py</code> file), but this bug being resolved will make it much simpler.</p>
<p><strong>Each extension can represent a different experimental treatment (preferred), or the extension can choose the branch internally</strong>.</p>
<h3><a class="header" href="#shield-studies" id="shield-studies">SHIELD studies</a></h3>
<p>The previous version of the experiments program, SHIELD, always bundled privileged code with extensions and would do things such as mock UI features in Firefox.</p>
<p>This sort of approach is discouraged for new features - land these (or the necessary WebExtension APIs) in-tree instead.</p>
<p>For the moment, the <a href="https://github.com/mozilla/shield-studies-addon-utils/">SHIELD Study Add-on Utilities</a> may be used if the extension needs to control the lifecycle of the study, but using one extension per experimental treatment makes this unnecessary and is preferred. The APIs provided by the SHIELD Study Add-on Utilities will be available as privileged APIs shipped with Firefox soon.</p>
<h1><a class="header" href="#development-and-testing" id="development-and-testing">Development and Testing</a></h1>
<h2><a class="header" href="#testing-built-in-features" id="testing-built-in-features">Testing Built-in Features</a></h2>
<p>Firefox features go through standard development and testing processes. See the <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Developer_guide">Firefox developer guide</a> for more information.</p>
<h2><a class="header" href="#testing-extensions" id="testing-extensions">Testing Extensions</a></h2>
<p>Extensions do not need to go through the same process, but should take advantage of Mozilla CI and bug tracking systems:</p>
<ol>
<li>Use the Mozilla CI to test changes (tryserver).</li>
<li>Performance tests (<strong>this step is required</strong>) - extension XPI files should be placed in <code>testing/profiles/common/extensions/</code>, which will cause test harnesses to load the XPI.</li>
<li>Custom unit/functional tests (AKA <code>xpcshell</code>/<code>mochitest</code>) may be placed in <code>testing/extensions</code>, although running these tests outside Mozilla CI is acceptable so these are <strong>optional</strong>.</li>
<li>Receive reviewer approval. A Firefox peer <strong>must sign off</strong> if this extension contains privileged code, aka WebExtension Experiments.</li>
</ol>
<ul>
<li>Any <a href="https://wiki.mozilla.org/Modules/All#Firefox">Firefox Peer</a> should be able to do the review, or point you to someone who can.</li>
</ul>
<ol start="5">
<li>Extension is signed.</li>
<li>Email to <code>pi-request@mozilla.com</code> is sent to request QA</li>
<li>QA approval signed off in Bugzilla.</li>
<li>Extension is shipped via <a href="https://github.com/mozilla/normandy">Normandy</a>.</li>
</ol>
<h2><a class="header" href="#example-extensions-testing-workflow" id="example-extensions-testing-workflow">Example Extensions Testing Workflow</a></h2>
<p>Note that for the below to work you only need <a href="https://www.mercurial-scm.org/">Mercurial</a> installed, but if you want to do local testing you must be set up to <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Developer_guide/Build_Instructions">build Firefox</a>. You don't need to build Firefox from source; <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Developer_guide/Build_Instructions/Artifact_builds">artifact builds</a> are sufficient.</p>
<p>In order to use Mozilla CI (AKA &quot;<a href="https://firefox-source-docs.mozilla.org/tools/try/">Tryserver</a>&quot;), you must have a full clone of the <code>mozilla-central</code> repository:</p>
<pre><code>hg clone https://hg.mozilla.org/mozilla-central
cd mozilla-central
</code></pre>
<p>Copy in unsigned XPI, and commit it to your local Mercurial repo:</p>
<pre><code>cp ~/src/my-extension.xpi testing/profiles/common/extensions/
hg add testing/profiles/common/extensions/my-extension.xpi
hg commit -m &quot;Bug nnn - Testing my extension&quot; testing/profiles/common/extensions/my-extension.xpi
</code></pre>
<p>Push to Try:</p>
<pre><code>./mach try -p linux64,macosx64,win64 -b do -u none -t all --artifact
</code></pre>
<p>This will run Mozilla CI tests on all platforms</p>
<p>Note that you must have Level 1 commit access to use tryserver. If you are interested in interacting with Mozilla CI from Github (which only requires users to be in the Mozilla GitHub org), check out the <a href="https://github.com/biancadanforth/taskcluster-integration-poc/">Taskcluster Integration proof-of-concept</a>.</p>
<p>Also note that this requires an investment time to set up just as CircleCI or Travis-CI would, so it's not really appropriate for short-term projects. Use tryserver directly instead.</p>
<h1><a class="header" href="#telemetry-events-best-practices" id="telemetry-events-best-practices">Telemetry Events Best Practices</a></h1>
<h2><a class="header" href="#overview-2" id="overview-2">Overview:</a></h2>
<p><a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/events.html">The Telemetry Events API</a> allows users to define and record events in the browser.</p>
<p>Events are defined in <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/events.html#the-yaml-definition-file"><code>Events.yaml</code></a> and each events creates records with the following properties:</p>
<ul>
<li>timestamp</li>
<li>category</li>
<li>method</li>
<li>object</li>
<li>value</li>
<li>extra</li>
</ul>
<p>With the following restrictions and features:</p>
<ul>
<li>The category, method, and object properties of any record produced by an event must have a value.</li>
<li>All combinations of values from the category, method, and object properties must be unique to that particular event (no other event can produce events with the same combination).</li>
<li>Events can be 'turned on' or 'turned off' by it's category value. i.e. we can instruct the browser to &quot;stop sending us events from the <code>devtools</code> category.&quot;</li>
</ul>
<p>These records are then stored in <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/data/event-ping.html">event pings</a> and available in the <a href="https://docs.telemetry.mozilla.org/datasets/batch_view/events/reference.html">events dataset</a>.</p>
<h2><a class="header" href="#identifying-events" id="identifying-events">Identifying Events</a></h2>
<p>One challenge with this data is it can be difficult to identify all the records from a particular event. Unlike Scalars and Histograms, which keep data in individual locations (like <code>scalar_parent_browser_engagement_total_uri_count</code> for <a href="https://dxr.mozilla.org/mozilla-central/source/toolkit/components/telemetry/Scalars.yaml#99"><code>total_uri_count</code></a>), all event records are stored together, regardless of which event generated them. The records themselves don't have a field identifying which event produced it[1].</p>
<p>Take, for example, the <a href="https://dxr.mozilla.org/mozilla-central/source/toolkit/components/telemetry/Events.yaml#105"><code>manage</code></a>
event in the <code>addonsManager</code> category.</p>
<pre><code>addonsManager: # category
  manage: # event name
    description: &gt;
      ...
    objects: [&quot;extension&quot;, &quot;theme&quot;, &quot;locale&quot;, &quot;dictionary&quot;, &quot;other&quot;] # object values
    methods: [&quot;disable&quot;, &quot;enable&quot;, &quot;sideload_prompt&quot;, &quot;uninstall&quot;] # method values
    extra_keys: # extra values
      ...
    notification_emails: ...
    expiry_version: ...
    record_in_processes: ...
    bug_numbers: ...
    release_channel_collection: ...
</code></pre>
<p>This event will produce records that look like:</p>
<table><thead><tr><th>timestamp</th><th>category</th><th>method</th><th>object</th><th>value</th><th>extra</th></tr></thead><tbody>
<tr><td>...</td><td><code>addonsManager</code></td><td><code>install</code></td><td><code>extension</code></td><td></td><td>...</td></tr>
<tr><td>...</td><td><code>addonsManager</code></td><td><code>update</code></td><td><code>locale</code></td><td></td><td>...</td></tr>
<tr><td>...</td><td><code>addonsManager</code></td><td><code>sideload_prompt</code></td><td><code>other</code></td><td></td><td>...</td></tr>
</tbody></table>
<p>But none of these records will indicate that it was produced by the <code>manage</code> event. To find all records produced by <code>manage</code>, one would have to query all records where</p>
<pre><code>category = ...
AND method in [...,]
AND object in [...,]
</code></pre>
<p>which is not ideal.</p>
<p>Furthermore, if one encounters this data without knowledge of how the <code>manage</code> event works, they need to look up the event based on the category, method, and object values in order to find the event, and then query the data again to find all the related events. It's not immediately clear from the data if this record:</p>
<table><thead><tr><th>timestamp</th><th>category</th><th>method</th><th>object</th><th>value</th><th>extra</th></tr></thead><tbody>
<tr><td>...</td><td><code>addonsManager</code></td><td><code>update</code></td><td><code>locale</code></td><td></td><td>...</td></tr>
</tbody></table>
<p>and and this record:</p>
<table><thead><tr><th>timestamp</th><th>category</th><th>method</th><th>object</th><th>value</th><th>extra</th></tr></thead><tbody>
<tr><td>...</td><td><code>addonsManager</code></td><td><code>install</code></td><td><code>extension</code></td><td></td><td>...</td></tr>
</tbody></table>
<p>are related or not.</p>
<p>Another factor that can add to confusion is the fact that other events can share similar values for methods or objects (or even the combination of method and object). For example:</p>
<table><thead><tr><th>timestamp</th><th>category</th><th>method</th><th>object</th><th>value</th><th>extra</th></tr></thead><tbody>
<tr><td>...</td><td><code>normandy</code></td><td><code>update</code></td><td><code>preference_rollout</code></td><td></td><td>...</td></tr>
</tbody></table>
<p>which can further confuser users.</p>
<p>[1]: Events do have name fields, but they aren't included in the event records and thus are not present in the resulting dataset. Also, If a user defines an event in <code>Events.yaml</code> without specifying a list of acceptable methods, the method will default to the name of the event for records created by that event.</p>
<h4><a class="header" href="#suggested-convention" id="suggested-convention">Suggested Convention:</a></h4>
<p>To simplify things in the future, we suggest adding the event name to the category field using dot notation when designing new events:</p>
<pre><code>&quot;category.event_name&quot;
</code></pre>
<p>For example:</p>
<ul>
<li><code>&quot;navigation.search&quot;</code></li>
<li><code>&quot;addonsManager.manage&quot;</code></li>
<li><code>&quot;frame.tab&quot;</code></li>
</ul>
<p>This provides 3 advantages:</p>
<ol>
<li>Records produced by this event will be easily identifiable. Also, the event which produced the record will be easier to locate in the code.</li>
<li>Events can be controlled more easily. The category field is what we use to &quot;turn on&quot; and &quot;turn off&quot; events. By creating a 1 to 1 mapping between categories and events, we can control events on an individual level.</li>
<li>By having the category field act as the event identifier, it makes it easier to pass on events to Amplitude and other platforms.</li>
</ol>
<h1><a class="header" href="#sending-a-custom-ping" id="sending-a-custom-ping">Sending a Custom Ping</a></h1>
<p>Got some new data you want to send to us? How in the world do you send a new ping? Follow this guide
to find out.</p>
<p><strong>Note</strong>: Most new data collection in Firefox via Telemetry or Glean does not require creating a new
ping document type. To add a histogram, scalar, or event collection to Firefox, please see the
documentation on <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/start/adding-a-new-probe.html">adding a new
probe</a>.</p>
<h2><a class="header" href="#write-your-questions" id="write-your-questions">Write Your Questions</a></h2>
<p>Do not try and implement new pings unless you know specifically what questions you're trying to
answer. General questions about &quot;How do users use our product?&quot; won't cut it - these need to be
specific, concrete asks that can be translated to data points. This will also make it easier down
the line as you start data review.</p>
<p>More detail on how to design and implement new pings for Firefox Desktop <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/custom-pings.html">can be found
here</a>.</p>
<h2><a class="header" href="#choose-a-namespace-and-doctype" id="choose-a-namespace-and-doctype">Choose a Namespace and DocType</a></h2>
<p>Choose a namespace that uniquely identifies the product that will be generating the data. The
<code>telemetry</code> namespace is reserved for pings added by the Firefox Desktop Telemetry team.</p>
<p>The DocType is used to differentiate pings within a namespace. It can be as simple as <code>event</code>, but
should generally be descriptive of the data being collected.</p>
<p>Both namespace and DocType are limited to the pattern <code>[a-z-]</code>. In other words, hyphens and
lowercase letters from the <a href="https://en.wikipedia.org/wiki/ISO_basic_Latin_alphabet">ISO basic Latin alphabet</a>.</p>
<h2><a class="header" href="#create-a-schema" id="create-a-schema">Create a Schema</a></h2>
<p>Write a JSON Schema. See the <a href="https://github.com/mozilla-services/mozilla-pipeline-schemas#adding-a-new-schema">&quot;Adding a new schema&quot;
documentation</a> and
examples schemas in the <a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/">Mozilla Pipeline Schemas
repo</a>. This schema is used to
validate the incoming data; any ping that doesn't match the schema will be removed. This schema will
also be transformed into a BigQuery table schema via the <a href="https://github.com/mozilla/mozilla-schema-generator">Mozilla Schema
Generator</a>. Note that parquet schemas are no
longer necessary because of the generated schemas. Validate your JSON Schema using a <a href="https://jsonschemalint.com/#/version/draft-04/markup/json">validation
tool</a>.</p>
<h2><a class="header" href="#start-a-data-review" id="start-a-data-review">Start a Data Review</a></h2>
<p>Data review for new pings is often more complicated than adding new probes. See <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1347266">Data Review for
Focus-Event Ping</a> as an example.
Consider where the data falls under the
<a href="https://wiki.mozilla.org/Firefox/Data_Collection">Data Collection Categories</a>.</p>
<h2><a class="header" href="#submit-schema-to-mozilla-servicesmozilla-pipeline-schemas" id="submit-schema-to-mozilla-servicesmozilla-pipeline-schemas">Submit Schema to <code>mozilla-services/mozilla-pipeline-schemas</code></a></h2>
<p>Create a pull request including both a template and rendered schema to <code>mozilla-pipeline-schemas</code>.
Add at least one validation ping that exercises the structure of schema as a test.
These pings are validated during the build and help catch mistakes during the writing process.</p>
<h3><a class="header" href="#example-a-rendered-schema-for-response-times" id="example-a-rendered-schema-for-response-times">Example: A rendered schema for response times</a></h3>
<p>Imagine we want to collect a set of response measurements in milliseconds on a per-client basis.
The pings take on the following shape:</p>
<pre><code class="language-json">{&quot;id&quot;: &quot;08317b11-85f7-4688-9b35-48af10c3ccdf&quot;, &quot;clientId&quot;: &quot;1d5ce2fc-a554-42f0-ab21-2ad8ada9bb88&quot;, &quot;payload&quot;: {&quot;response_ms&quot;: 324}}
{&quot;id&quot;: &quot;a97108ac-483b-40be-9c64-3419326f5113&quot;, &quot;clientId&quot;: &quot;3f1b2e1c-c241-464f-aa46-576f5795e488&quot;, &quot;payload&quot;: {&quot;response_ms&quot;: 221}}
{&quot;id&quot;: &quot;b8a7e3f9-38c0-4a13-b42a-c969feb454f6&quot;, &quot;clientId&quot;: &quot;14f27409-5f6f-46e0-9f9d-da5cd716ee42&quot;, &quot;payload&quot;: {&quot;response_ms&quot;: 549}}
</code></pre>
<p>This document can be described in the following way:</p>
<pre><code class="language-json">{
    &quot;$schema&quot;: &quot;http://json-schema.org/draft-04/schema#&quot;,
    &quot;type&quot;: &quot;object&quot;,
    &quot;properties&quot;: {
        &quot;id&quot;: {
            &quot;type&quot;: &quot;string&quot;,
            &quot;description&quot;: &quot;The document identifier&quot;
        },
        &quot;clientId&quot;: {
            &quot;type&quot;: &quot;string&quot;,
            &quot;description&quot;: &quot;The client identifier&quot;
        },
        &quot;payload&quot;: {
            &quot;type&quot;: &quot;object&quot;,
            &quot;properties&quot;: {
                &quot;response_ms&quot;: {
                    &quot;type&quot;: &quot;integer&quot;,
                    &quot;minimum&quot;: 0,
                    &quot;description&quot;: &quot;Response time of the client, in milliseconds&quot;
                }
            }
        }
    }
}
</code></pre>
<p>Fields like <code>id</code> and <code>clientId</code> have template components as part of the build-system. These would be
included as <code>@TELEMETRY_ID_1_JSON@</code> and <code>@TELEMETRY_CLIENTID_1_JSON@</code> respectively. The best way to
become familiar with template schemas is to browse the repository; the
<a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/blob/master/templates/telemetry/main/main.4.schema.json"><code>telemetry/main/main.4.schema.json</code>
document</a>
a good starting place.</p>
<p>As part of the automated deployment process, the JSON schemas are translated into a table schema
used by BigQuery. These schemas closely reflect the schemas used for data validation.</p>
<pre><code class="language-json">[
  {
    &quot;mode&quot;: &quot;NULLABLE&quot;,
    &quot;name&quot;: &quot;clientId&quot;,
    &quot;type&quot;: &quot;STRING&quot;
  },
  {
    &quot;mode&quot;: &quot;NULLABLE&quot;,
    &quot;name&quot;: &quot;id&quot;,
    &quot;type&quot;: &quot;STRING&quot;
  },
  {
    &quot;fields&quot;: [
      {
        &quot;mode&quot;: &quot;NULLABLE&quot;,
        &quot;name&quot;: &quot;response_ms&quot;,
        &quot;type&quot;: &quot;INT64&quot;
      }
    ],
    &quot;mode&quot;: &quot;NULLABLE&quot;,
    &quot;name&quot;: &quot;payload&quot;,
    &quot;type&quot;: &quot;RECORD&quot;
  }
]
</code></pre>
<h3><a class="header" href="#ingestion-metadata" id="ingestion-metadata">Ingestion Metadata</a></h3>
<p>The generated schemas contain metadata added to the schema before deployment to the ingestion
service. These are fields added to the ping at ingestion time; they might come from the URL
submitted to the edge server, or the IP Address used to make the request. <a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/blob/master/schemas/metadata/telemetry-ingestion/telemetry-ingestion.1.schema.json">This
document</a>
lists available metadata fields for the telemetry-ingestion pings, which are largely shared across
all namespaces.</p>
<p>A list of metadata fields are included here for reference, but refer to the above document or the
schema explorer for an up-to-date list of metadata fields.</p>
<!-- table generated via `scripts/new_ping_metadata_table.py > src/cookbooks/new_ping_metadata_table.md` -->
<table><thead><tr><th>field</th><th>description</th></tr></thead><tbody>
<tr><td><code>additional_properties</code></td><td>A JSON string containing any payload properties not present in the schema</td></tr>
<tr><td><code>document_id</code></td><td>The document ID specified in the URI when the client sent this message</td></tr>
<tr><td><code>normalized_app_name</code></td><td>Set to &quot;Other&quot; if this message contained an unrecognized app name</td></tr>
<tr><td><code>normalized_channel</code></td><td>Set to &quot;Other&quot; if this message contained an unrecognized channel name</td></tr>
<tr><td><code>normalized_country_code</code></td><td>An ISO 3166-1 alpha-2 country code</td></tr>
<tr><td><code>normalized_os</code></td><td>Set to &quot;Other&quot; if this message contained an unrecognized OS name</td></tr>
<tr><td><code>normalized_os_version</code></td><td>N/A</td></tr>
<tr><td><code>sample_id</code></td><td>Hashed version of client_id (if present) useful for partitioning; ranges from 0 to 99</td></tr>
<tr><td><code>submission_timestamp</code></td><td>Time when the ingestion edge server accepted this message</td></tr>
<tr><td><code>metadata.user_agent.browser</code></td><td>N/A</td></tr>
<tr><td><code>metadata.user_agent.os</code></td><td>N/A</td></tr>
<tr><td><code>metadata.user_agent.version</code></td><td>N/A</td></tr>
<tr><td><code>metadata.uri.app_build_id</code></td><td>N/A</td></tr>
<tr><td><code>metadata.uri.app_name</code></td><td>N/A</td></tr>
<tr><td><code>metadata.uri.app_update_channel</code></td><td>N/A</td></tr>
<tr><td><code>metadata.uri.app_version</code></td><td>N/A</td></tr>
<tr><td><code>metadata.header.date</code></td><td>Date HTTP header</td></tr>
<tr><td><code>metadata.header.dnt</code></td><td>DNT (Do Not Track) HTTP header</td></tr>
<tr><td><code>metadata.header.x_debug_id</code></td><td>X-Debug-Id HTTP header</td></tr>
<tr><td><code>metadata.header.x_pingsender_version</code></td><td>X-PingSender-Version HTTP header</td></tr>
<tr><td><code>metadata.geo.city</code></td><td>N/A</td></tr>
<tr><td><code>metadata.geo.country</code></td><td>An ISO 3166-1 alpha-2 country code</td></tr>
<tr><td><code>metadata.geo.db_version</code></td><td>The specific geo database version used for this lookup</td></tr>
<tr><td><code>metadata.geo.subdivision1</code></td><td>First major country subdivision, typically a state, province, or county</td></tr>
<tr><td><code>metadata.geo.subdivision2</code></td><td>Second major country subdivision; not applicable for most countries</td></tr>
</tbody></table>
<h3><a class="header" href="#testing-the-schema" id="testing-the-schema">Testing The Schema</a></h3>
<p>For new data, use the <a href="https://github.com/mozilla-services/edge-validator">edge validator</a> to test
your schema.</p>
<h2><a class="header" href="#deployment" id="deployment">Deployment</a></h2>
<p>Schemas are automatically deployed once a day around 00:00 UTC, scheduled after the probe scraper in
the following <a href="https://github.com/mozilla/telemetry-airflow/blob/master/dags/probe_scraper.py">Airflow
DAG</a>. The latest
schemas can be viewed at
<a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/tree/generated-schemas"><code>mozilla-pipeline-schemas/generated-schemas</code></a>.</p>
<h2><a class="header" href="#start-sending-data" id="start-sending-data">Start Sending Data</a></h2>
<p>Use the built-in Telemetry APIs when possible. A few examples are the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/custom-pings.html">Gecko Telemetry
APIs</a>,
or the <a href="https://github.com/mozilla-mobile/telemetry-ios">iOS Telemetry APIs</a>.</p>
<p><strong>Users on Android should use <a href="cookbooks/../concepts/glean/glean.html">Glean</a></strong>, which does not require building out custom pings.</p>
<p>For all other use-cases, send documents to the ingestion endpoint:</p>
<pre><code class="language-text">https://incoming.telemetry.mozilla.org
</code></pre>
<p>See <a href="cookbooks/../concepts/pipeline/http_edge_spec.html">the HTTP edge server specification</a> for documentation
about the expected format.</p>
<h2><a class="header" href="#access-your-data" id="access-your-data">Access Your Data</a></h2>
<p>First confirm with the reviewers of <a href="cookbooks/new_ping.html#submit-schema-to-mozilla-servicesmozilla-pipeline-schemas">your schema pull
request</a> that your schemas have been
deployed. You may also check the diff of the latest commit to <a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/tree/generated-schemas"><code>mozilla-pipeline-schemas/generated schemas</code></a>.</p>
<p>In the following links, replace <code>&lt;namespace&gt;</code>, <code>&lt;doctype&gt;</code> And <code>&lt;docversion&gt;</code> with appropriate
values. Also replace <code>-</code> with <code>_</code> in <code>&lt;namespace&gt;</code> if your namespace contains <code>-</code> characters.</p>
<h3><a class="header" href="#stmo--bigquery" id="stmo--bigquery">STMO / BigQuery</a></h3>
<p>In the <code>Telemetry (BigQuery)</code> data source, several new tables will be created for your data.</p>
<p>The first table is the <code>live</code> table found under
<code>moz-fx-data-shared-prod.&lt;namespace&gt;_live.&lt;doctype&gt;_v&lt;docversion&gt;</code>. This table is updated on a 5
minute interval, partitioned on <code>submission_timestamp</code>, and may contain partial days of data.</p>
<pre><code class="language-sql">SELECT
    count(*) AS n_rows
FROM
  `moz-fx-data-shared-prod.telemetry_live.main_v4`
WHERE
  submission_timestamp &gt; TIMESTAMP_SUB(current_timestamp, INTERVAL 30 minute)
</code></pre>
<p>The second table that is created is the <code>stable</code> clustered table (and corresponding view) under
<code>moz-fx-data-shared-prod.&lt;namespace&gt;.&lt;doctype&gt;</code>. This view will only contain complete
days of submissions. The data is clustered by <code>normalized_channel</code> and <code>sample_id</code> to improve the
efficiency of queries.</p>
<pre><code class="language-sql">SELECT
  COUNT(DISTINCT client_id)*100 AS dau
FROM
  `moz-fx-data-shared-prod.telemetry.main`
WHERE
  submission_timestamp &gt; TIMESTAMP_SUB(current_timestamp, INTERVAL 1 day)
  AND sample_id = 1
</code></pre>
<p>This table may take up to a day to appear in the BigQuery source; if you still don't see a table for
your new ping after 24 hours, <a href="https://mana.mozilla.org/wiki/display/SVCOPS/Contacting+Data+Operations">contact Data
Operations</a> so that they
can investigate. Once the table is available, it should contain all the pings sent during that first
day, regardless of how long it takes for the table to appear.</p>
<h3><a class="header" href="#spark-1" id="spark-1">Spark</a></h3>
<p>Refer to the <a href="cookbooks/../cookbooks/bigquery.html#from-spark">Spark notes</a> for details on accessing the data
via Spark.</p>
<h2><a class="header" href="#build-dashboards-using-spark-or-stmo" id="build-dashboards-using-spark-or-stmo">Build Dashboards Using Spark or STMO</a></h2>
<p>Last steps! What are you using this data for anyway?</p>
<h1><a class="header" href="#dataset-reference" id="dataset-reference">Dataset Reference</a></h1>
<p>After completing <a href="datasets/../concepts/choosing_a_dataset.html">Choosing a Dataset</a>
you should have a high level understanding of what questions each dataset is able to answer.
This section contains references that focus on a single dataset each.
Reading this section front to back is not recommended.
Instead, identify a dataset you'd like to understand better and read through
the relevant documentation.
After reading the tutorial, you should know all you need about the dataset.</p>
<p>Each tutorial should include:</p>
<ul>
<li>Introduction
<ul>
<li>A short overview of why we built the dataset and what need it's meant to solve</li>
<li>What data source the data is collected from,
and a high level overview of how the data is organized</li>
<li>How it is stored and how to access the data</li>
</ul>
</li>
<li>Reference
<ul>
<li>An example query to give the reader an idea of what the data looks like
and how it is meant to be used</li>
<li>How the data is processed and sampled</li>
<li>How frequently it's updated, and how it's scheduled</li>
<li>An up-to-date schema for the dataset</li>
<li>How to augment or modify the dataset</li>
</ul>
</li>
</ul>
<h1><a class="header" href="#raw-ping-data" id="raw-ping-data">Raw Ping Data</a></h1>
<ul>
<li><a href="datasets/pings.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/pings.html#main-ping">&quot;main&quot; ping</a></li>
<li><a href="datasets/pings.html#first-shutdown-ping">&quot;first-shutdown&quot; ping</a></li>
<li><a href="datasets/pings.html#event-ping">&quot;event&quot; ping</a></li>
<li><a href="datasets/pings.html#update-ping">&quot;update&quot; ping</a></li>
<li><a href="datasets/pings.html#new-profile-ping">&quot;new-profile&quot; ping</a></li>
<li><a href="datasets/pings.html#crash-ping">&quot;crash&quot; ping</a></li>
<li><a href="datasets/pings.html#deletion-request-ping">&quot;deletion request&quot; ping</a></li>
<li><a href="datasets/pings.html#pingsender">Pingsender</a></li>
<li><a href="datasets/pings.html#analysis">Analysis</a>
<ul>
<li><a href="datasets/pings.html#accessing-the-data">Accessing the Data</a></li>
<li><a href="datasets/pings.html#further-reading">Further Reading</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="datasets/pings.html#data-reference">Data Reference</a></li>
<li><a href="datasets/pings.html#ping-metadata">Ping Metadata</a></li>
</ul>
<h1><a class="header" href="#introduction-2" id="introduction-2">Introduction</a></h1>
<p>We receive data from our users via <strong>pings</strong>.
There are several types of pings,
each containing different measurements and sent for different purposes.
To review a complete list of ping types and their schemata, see
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/index.html">this section of the Mozilla Source Tree Docs</a>.</p>
<p>Pings are also described by a JSONSchema specification which can be found in <a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/tree/master/schemas/telemetry">the <code>mozilla-pipeline-schemas</code> repository</a>.</p>
<p>There are a few pings that are central to delivering our core data collection
primitives (Histograms, Events, Scalars) and for keeping an eye on Firefox
behaviour (Environment, New Profiles, Updates, Crashes).</p>
<p>For instance, a user's first session in Firefox might have four pings like this:</p>
<p><img src="datasets//datasets/images/first_session_pings.png" alt="Flowchart of pings in the user's first session" /></p>
<h3><a class="header" href="#main-ping-1" id="main-ping-1">&quot;main&quot; ping</a></h3>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html">&quot;main&quot; ping</a> is the workhorse of the Firefox Telemetry system.
It delivers the Telemetry Environment as well as Histograms and Scalars for all
process types that collect data in Firefox. It has several variants each with
specific delivery characteristics:</p>
<table><thead><tr><th>Reason</th><th>Sent when</th><th>Notes</th></tr></thead><tbody>
<tr><td>shutdown</td><td>Firefox session ends cleanly</td><td>Accounts for about <a href="https://sql.telemetry.mozilla.org/queries/3434">80%</a> of all &quot;main&quot; pings. Sent by Pingsender immediately after Firefox shuts down, subject to conditions: Firefox 55+, if the OS isn't also shutting down, and if this isn't the client's first session. If Pingsender fails or isn't used, the ping is sent by Firefox at the beginning of the next Firefox session.</td></tr>
<tr><td>daily</td><td>It has been more than 24 hours since the last &quot;main&quot; ping, and it is around local midnight</td><td>In long-lived Firefox sessions we might go days without receiving a &quot;shutdown&quot; ping. Thus the &quot;daily&quot; ping is sent to ensure we occasionally hear from long-lived sessions.</td></tr>
<tr><td>environment-change</td><td>Telemetry Environment changes</td><td>Is sent immediately when triggered by Firefox (Installing or removing an addon or changing a monitored user preference are common ways for the Telemetry Environment to change)</td></tr>
<tr><td>aborted-session</td><td>Firefox session doesn't end cleanly</td><td>Sent by Firefox at the beginning of the next Firefox session.</td></tr>
</tbody></table>
<p>It was introduced in Firefox 38.</p>
<h3><a class="header" href="#first-shutdown-ping-1" id="first-shutdown-ping-1">&quot;first-shutdown&quot; ping</a></h3>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/first-shutdown-ping.html">&quot;first-shutdown&quot; ping</a> is identical to the &quot;main&quot;
ping with reason &quot;shutdown&quot; created at the end of the user's first session,
but sent with a different ping type. This was introduced when we started
using Pingsender to send shutdown pings as there would be a lot of
first-session &quot;shutdown&quot; pings that we'd start receiving all of a sudden.</p>
<p>It is sent using Pingsender.</p>
<p>It was introduced in Firefox 57.</p>
<h3><a class="header" href="#event-ping-1" id="event-ping-1">&quot;event&quot; ping</a></h3>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/event-ping.html">&quot;event&quot; ping</a> provides low-latency eventing support to Firefox
Telemetry. It delivers the Telemetry Environment, Telemetry Events from all
Firefox processes, and some diagnostic information about Event Telemetry. It is
sent every hour if there have been events recorded, and up to once every 10
minutes (governed by a <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/internals/preferences.html">preference</a>) if the maximum event limit
for the ping (default to 1000 per process, governed by a
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/internals/preferences.html">preference</a>) is reached before the hour is up.</p>
<p>It was introduced in Firefox 62.</p>
<h3><a class="header" href="#update-ping-1" id="update-ping-1">&quot;update&quot; ping</a></h3>
<p>Firefox Update is the most important means we have of reaching our users with
the latest fixes and features. The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/update-ping.html">&quot;update&quot; ping</a> notifies us
when an update is downloaded and ready to be applied (reason: &quot;ready&quot;) and when
the update has been successfully applied (reason: &quot;success&quot;). It contains the
Telemetry Environment and information about the update.</p>
<p>It was introduced in Firefox 56.</p>
<h3><a class="header" href="#new-profile-ping-1" id="new-profile-ping-1">&quot;new-profile&quot; ping</a></h3>
<p>When a user starts up Firefox for the first time, a profile is created.
Telemetry marks the occasion with the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/new-profile-ping.html">&quot;new-profile&quot; ping</a>
which sends the Telemetry Environment. It is sent either 30 minutes after Firefox
starts running for the first time in this profile (reason: &quot;startup&quot;) or at the
end of the profile's first session (reason: &quot;shutdown&quot;), whichever comes first.
&quot;new-profile&quot; pings are sent immediately when triggered. Those with reason
&quot;startup&quot; are sent by Firefox. Those with reason &quot;shutdown&quot; are sent by
Pingsender.</p>
<p>It was introduced in Firefox 55.</p>
<h3><a class="header" href="#crash-ping-1" id="crash-ping-1">&quot;crash&quot; ping</a></h3>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/crash-ping.html">&quot;crash&quot; ping</a> provides diagnostic information whenever a
Firefox process exits abnormally. Unlike the &quot;main&quot; ping with reason
&quot;aborted-session&quot;, this ping does not contain Histograms or Scalars. It
contains a Telemetry Environment, <a href="https://searchfox.org/mozilla-central/source/toolkit/crashreporter/CrashAnnotations.yaml">Crash Annotations</a>, and
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/crash-ping.html#stack-traces">Stack Traces</a>.</p>
<p>It was introduced in Firefox 40.</p>
<h3><a class="header" href="#deletion-request-ping-1" id="deletion-request-ping-1">&quot;deletion request&quot; ping</a></h3>
<p>In the event a user opts out of Telemetry, we send one final
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/data/deletion-request-ping.html">&quot;deletion-request&quot; ping</a> to let us know. It contains
only the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/common-ping.html">common ping data</a> and an empty payload.</p>
<p>It was introduced in Firefox 72, replacing the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/obsolete/optout-ping.html">&quot;optout&quot; ping</a>
(which was in turn introduced in Firefox 63).</p>
<h3><a class="header" href="#pingsender-2" id="pingsender-2">Pingsender</a></h3>
<p><a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/internals/pingsender.html">Pingsender</a> is a small application shipped with Firefox which
attempts to send pings even if Firefox is not running. If Firefox has crashed or has already shut
down we would otherwise have to wait for the next Firefox session to begin to
send pings.</p>
<p>Pingsender was introduced in Firefox 54 to send &quot;crash&quot; pings. It was expanded
to send &quot;main&quot; pings of reason &quot;shutdown&quot; in Firefox 55 (excepting the first
session). It sends the &quot;first-shutdown&quot; ping since its introduction in Firefox 57.</p>
<h3><a class="header" href="#analysis-1" id="analysis-1">Analysis</a></h3>
<p>The large majority of analyses can be completed using only the
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html">main ping</a>.
This ping includes histograms, scalars, and other performance and diagnostic data.</p>
<p>Few analyses actually rely directly on any raw ping data.
Instead, we provide <strong>derived datasets</strong> which are processed versions of these data,
made to be:</p>
<ul>
<li>Easier and faster to query</li>
<li>Organized to make the data easier to analyze</li>
<li>Cleaned of erroneous or misleading data</li>
</ul>
<p>Before analyzing raw ping data,
<strong>check to make sure there isn't already a derived dataset</strong> made for your purpose.
If you do need to work with raw ping data, be aware that the volume of data can be high.
Try to limit the size of your data by controlling the date range, and start off using a sample.</p>
<h4><a class="header" href="#accessing-the-data-13" id="accessing-the-data-13">Accessing the Data</a></h4>
<p>Ping data lives in BigQuery and is accessible in <a href="https://sql.telemetry.mozilla.org/">re:dash</a>;
see the <a href="datasets/../cookbooks/bigquery.html">BigQuery intro</a> article.</p>
<h4><a class="header" href="#further-reading-6" id="further-reading-6">Further Reading</a></h4>
<p>You can find <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/index.html">the complete ping documentation</a>.
To augment our data collection, see <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Performance/Adding_a_new_Telemetry_probe">Collecting New Data</a> and the
<a href="https://wiki.mozilla.org/Firefox/Data_Collection">Data Collection Policy</a>.</p>
<h1><a class="header" href="#data-reference" id="data-reference">Data Reference</a></h1>
<p>You can find the reference documentation for all Firefox Telemetry ping types
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/concepts/pings.html">here</a>.</p>
<p>The <a href="datasets/../concepts/glean/glean.html">Glean</a> article describes ping types sent by that SDK.</p>
<h1><a class="header" href="#ping-metadata" id="ping-metadata">Ping Metadata</a></h1>
<p>The data pipeline appends metadata to arriving pings containing
information about the ingestion environment including timestamps,
Geo-IP data about the client,
and fields extracted from the ping or client headers that are useful for downstream processing.</p>
<p>These fields are available in BigQuery ping tables inside the <code>metadata</code> struct, described in detail
in <a href="datasets/../cookbooks/new_ping.html">the &quot;Ingestion Metadata&quot; section of this article</a>.</p>
<p>Since the metadata are not present in the ping as it is sent by the client,
these fields are documented here, instead of in the source tree docs.</p>
<p>As of September 28, 2018, members of the <code>meta</code> key on main pings include:</p>
<!-- table generated via `scripts/new_ping_metadata_table.py > src/cookbooks/new_ping_metadata_table.md` -->
<table><thead><tr><th>field</th><th>description</th></tr></thead><tbody>
<tr><td><code>additional_properties</code></td><td>A JSON string containing any payload properties not present in the schema</td></tr>
<tr><td><code>document_id</code></td><td>The document ID specified in the URI when the client sent this message</td></tr>
<tr><td><code>normalized_app_name</code></td><td>Set to &quot;Other&quot; if this message contained an unrecognized app name</td></tr>
<tr><td><code>normalized_channel</code></td><td>Set to &quot;Other&quot; if this message contained an unrecognized channel name</td></tr>
<tr><td><code>normalized_country_code</code></td><td>An ISO 3166-1 alpha-2 country code</td></tr>
<tr><td><code>normalized_os</code></td><td>Set to &quot;Other&quot; if this message contained an unrecognized OS name</td></tr>
<tr><td><code>normalized_os_version</code></td><td>N/A</td></tr>
<tr><td><code>sample_id</code></td><td>Hashed version of client_id (if present) useful for partitioning; ranges from 0 to 99</td></tr>
<tr><td><code>submission_timestamp</code></td><td>Time when the ingestion edge server accepted this message</td></tr>
<tr><td><code>metadata.user_agent.browser</code></td><td>N/A</td></tr>
<tr><td><code>metadata.user_agent.os</code></td><td>N/A</td></tr>
<tr><td><code>metadata.user_agent.version</code></td><td>N/A</td></tr>
<tr><td><code>metadata.uri.app_build_id</code></td><td>N/A</td></tr>
<tr><td><code>metadata.uri.app_name</code></td><td>N/A</td></tr>
<tr><td><code>metadata.uri.app_update_channel</code></td><td>N/A</td></tr>
<tr><td><code>metadata.uri.app_version</code></td><td>N/A</td></tr>
<tr><td><code>metadata.header.date</code></td><td>Date HTTP header</td></tr>
<tr><td><code>metadata.header.dnt</code></td><td>DNT (Do Not Track) HTTP header</td></tr>
<tr><td><code>metadata.header.x_debug_id</code></td><td>X-Debug-Id HTTP header</td></tr>
<tr><td><code>metadata.header.x_pingsender_version</code></td><td>X-PingSender-Version HTTP header</td></tr>
<tr><td><code>metadata.geo.city</code></td><td>N/A</td></tr>
<tr><td><code>metadata.geo.country</code></td><td>An ISO 3166-1 alpha-2 country code</td></tr>
<tr><td><code>metadata.geo.db_version</code></td><td>The specific geo database version used for this lookup</td></tr>
<tr><td><code>metadata.geo.subdivision1</code></td><td>First major country subdivision, typically a state, province, or county</td></tr>
<tr><td><code>metadata.geo.subdivision2</code></td><td>Second major country subdivision; not applicable for most countries</td></tr>
</tbody></table>
<h1><a class="header" href="#derived-datasets" id="derived-datasets">Derived Datasets</a></h1>
<p>See <a href="datasets/../concepts/choosing_a_dataset.html">Choosing a Dataset</a>
for a discussion on the differences between pings and derived datasets.</p>
<h1><a class="header" href="#intro" id="intro">Intro</a></h1>
<p>The <code>active_profiles</code> dataset gives client-level estimates of whether a profile
is still an active user of the browser at a given point in time, as well as probabilistic forecasts
of the client's future activity. These quantities are estimated by a model that attempts to infer
and decouple a client's latent propensity to leave Firefox and become inactive, as well as their
latent propensity to use the browser while still active. These estimates are currently
generated for release desktop browser profiles only, across all operating systems and
geographies.</p>
<h1><a class="header" href="#model" id="model">Model</a></h1>
<p>The model generates predictions for each client by looking at just the recency and frequency of a
client's daily usage within the previous 90 day window. Usage is defined by the daily level binary
indicator of whether they show up in <code>clients_daily</code> on a given day.</p>
<p>The table contains columns related to these quantities:</p>
<ul>
<li><code>submission_date</code>: Day marking the end of the 90 day window. Earliest <code>submission_date</code> that
the table covers is <code>'2019-05-13'</code>.</li>
<li><code>min_day</code>: First day in the window that the client was seen. This could be anywhere between
the first day in the window and the last day in the window.</li>
<li><code>max_day</code>: Last day in the window the client was seen. The highest value this can be is
<code>submission_date</code>.</li>
<li><code>recency</code>: Age of client in days.</li>
<li><code>frequency</code>: Number of days in the window that a client has returned to use the browser
after <code>min_day</code>.</li>
<li><code>num_opportunities</code>: Given a first appearance at <code>min_day</code>, what is the highest number of
days a client could have returned. That is, what is the highest possible value for <code>frequency</code>.</li>
</ul>
<p>Since the model is only using these 2 coarse-grained statistics, these columns should make it
relatively straightforward to interpret why the model made the predictions that it did for a given
profile.</p>
<h2><a class="header" href="#latent-quantities" id="latent-quantities">Latent quantities</a></h2>
<p>The model estimates the expected value for 2 related latent probability variables for a user. The
values in <code>prob_daily_leave</code> give our expectation of the probability that they will become inactive
on a given day, and <code>prob_daily_usage</code> represents the probability that a user will return on a given
day, <em>given that they are still active</em>.</p>
<p>These quantities could be useful for disentangling usage <em>rate</em> from the likelihood that a user is
still using the browser. We could, for example, identify intense users who are at risk of
churning, or users who at first glance appear to have churned, but are actually just infrequent
users.</p>
<p><code>prob_active</code> is the expected value of the probability that a user is still active on
<code>submission_date</code>, given their most recent 90 days' of activity. 'Inactive' in this sense
means that the profile will not use the browser again, whether because they have uninstalled
the browser or for some other reason.</p>
<h2><a class="header" href="#predictions" id="predictions">Predictions</a></h2>
<p>There are several columns of the form <code>e_total_days_in_next_7_days</code>, which give the expected
number of times that a user will show up in the next 7 days (or 14, 21, 28 days). These
predictions take into account both the likelihood that a user will become inactive in the
future, as well as their daily propensity to use the browser, given that they are still active.
The values in <code>e_total_days_in_next_7_days</code> will be between 0 and 7.</p>
<p>An estimate for the probability that a client will contribute to MAU is available in the
column <code>prob_mau</code>. This is simply the probability that the user will return at any point in
the following 28 days, thereby contributing to MAU. Since it is a probability, the values will
range between 0 and 1, just like <code>prob_daily_leave</code> and <code>prob_daily_usage</code>.</p>
<h2><a class="header" href="#attributes" id="attributes">Attributes</a></h2>
<p>There are several columns that contain attributes of the client, like <code>os</code>, <code>locale</code>,
<code>normalized_channel</code>, <code>normalized_os_version</code>, and <code>country</code>. <code>sample_id</code> is also included,
which can be useful for quicker queries, as the table is clustered by this column in BigQuery.</p>
<h2><a class="header" href="#remarks-on-the-model" id="remarks-on-the-model">Remarks on the model</a></h2>
<p>A way to think about the model that infers these quantities is to imagine a simple process
where each client is given 2 weighted coins when they become users, and that they flip each
day. Since they're weighted, the probability of heads won't be 50%, but rather some probability
between 0 and 100%, specific to each client's coin. One coin, called <em>L</em>, comes up heads with
probability <code>prob_daily_leave</code>, and if it ever comes up heads, the client will never use the
browser again. The daily usage coin, <em>U</em>, has heads <code>prob_daily_usage</code>% of the time. <em>While
they are still active</em>, clients flip this coin to decide whether they will use the browser
on that day, and show up in <code>clients_daily</code>.</p>
<p>The combination of these two coin flipping processes results in a history of activity that we
can see in <code>clients_daily</code>. While the model is simple, it has very good predictive power that
can tell, <em>in aggregate</em>, how many users will still be active at some point in the future.
A downside of the model's simplicity, however, is that its predictions are not highly tailored
to an individual client. The very simplified features do not take into account things like
seasonality, or finer grained attributes of their usage (like active hours, addons, etc.).
Further, the predictions in this table only account for existing users that have been seen in
the 90 days of history, and so longer term forecasts of user activity would need to somehow model
new users separately.</p>
<h1><a class="header" href="#caveats-and-future-work" id="caveats-and-future-work">Caveats and future work</a></h1>
<p>Due to the lightweight feature space of the model, the predictions perform better at the
population level rather than the individual client level, and there will be a lot of client-level
variation in behavior. That is, when grouping clients by different dimensions, say all of the
<code>en-IN</code> users on Darwin, the <em>average</em> MAU prediction should be quite close, but a lot of users'
behavior can deviate significantly from the predictions.</p>
<p>The model will also be better at medium- to longer- term forecasts. In particular, the model
will not be well suited to give predictions for new users who have appeared only once in the data
set very recently. These constitute a disproportionately large share of users, but do not
have enough history for this model to make good use of.
These single day profiles are currently the subject of
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1507073">an investigation</a>
that will hopefully yield good heuristics for users that only show up for a single day.</p>
<h1><a class="header" href="#sample-query" id="sample-query">Sample query</a></h1>
<p><a href="https://console.cloud.google.com/bigquery?sq=630180991450:648f8e0a2faa4d86847fe8d27daf1938">Here</a> is
a sample query that will give averages for predicted MAU, probability that users are still
active, and other quantities across different operating systems:</p>
<pre><code>SELECT
  os,
  cast(sum(prob_mau) AS int64) AS predicted_mau,
  count(*) AS n,
  round(avg(prob_active) * 100, 1) AS prob_active,
  round(avg(prob_daily_leave) * 100, 1) AS prob_daily_leave,
  round(avg(prob_daily_usage) * 100, 1) AS prob_daily_usage,
  round(avg(e_total_days_in_next_28_days), 1) AS e_total_days_in_next_28_days
FROM
  `telemetry.active_profiles`
WHERE
  submission_date = '2019-08-01'
  AND sample_id = 1
GROUP BY
  1
HAVING
  count(*) &gt; 100
ORDER BY
  avg(prob_daily_usage) DESC
</code></pre>
<h2><a class="header" href="#scheduling" id="scheduling">Scheduling</a></h2>
<p>The code behind the model can be found in the <a href="https://github.com/wcbeard/bgbb_lib/"><code>bgbb_lib</code> repo</a>,
or on <a href="https://pypi.org/project/bgbb/">PyPI</a>. The airflow job is defined in the
<a href="https://github.com/wcbeard/bgbb_airflow"><code>bgbb_airflow</code> repo</a>.</p>
<p>The model to fit the parameters is run weekly, and the table is updated daily.</p>
<h1><a class="header" href="#addons-datasets" id="addons-datasets">Addons Datasets</a></h1>
<ul>
<li><a href="datasets/batch_view/addons/reference.html#introduction">Introduction</a></li>
<li><a href="datasets/batch_view/addons/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/batch_view/addons/reference.html#example-queries">Example Queries</a></li>
<li><a href="datasets/batch_view/addons/reference.html#sampling">Sampling</a></li>
<li><a href="datasets/batch_view/addons/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/batch_view/addons/reference.html#schema">Schema</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#introduction-3" id="introduction-3">Introduction</a></h1>
<p>This is a work in progress.
The work is being tracked
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1364172">here</a>.</p>
<h1><a class="header" href="#data-reference-1" id="data-reference-1">Data Reference</a></h1>
<h2><a class="header" href="#example-queries" id="example-queries">Example Queries</a></h2>
<h2><a class="header" href="#sampling" id="sampling">Sampling</a></h2>
<p>It contains one or more records for every
<a href="datasets/batch_view/addons/../main_summary/reference.html">Main Summary</a>
record that contains a non-null value for <code>client_id</code>.
Each Addons record contains info for a single addon,
or if the main ping did not contain any active addons,
there will be a row with nulls for all the addon fields
(to identify <code>client_id</code>s/records without any addons).</p>
<p>Like the Main Summary dataset, No attempt is made to de-duplicate submissions by <code>documentId</code>, so any analysis that could be affected by duplicate records should take care to remove duplicates using the <code>documentId</code> field.</p>
<h2><a class="header" href="#scheduling-1" id="scheduling-1">Scheduling</a></h2>
<p>This dataset is updated daily via the
<a href="https://github.com/mozilla/telemetry-airflow">telemetry-airflow</a> infrastructure.
The job DAG runs every day after the Main Summary data has been generated.
The DAG is <a href="https://github.com/mozilla/telemetry-airflow/blob/master/dags/main_summary.py#L36">here</a>.</p>
<h2><a class="header" href="#schema" id="schema">Schema</a></h2>
<p>As of 2017-03-16, the current version of the <code>addons</code> dataset is <code>v2</code>,
and has a schema as follows:</p>
<pre><code>root
 |-- document_id: string (nullable = true)
 |-- client_id: string (nullable = true)
 |-- subsession_start_date: string (nullable = true)
 |-- normalized_channel: string (nullable = true)
 |-- addon_id: string (nullable = true)
 |-- blocklisted: boolean (nullable = true)
 |-- name: string (nullable = true)
 |-- user_disabled: boolean (nullable = true)
 |-- app_disabled: boolean (nullable = true)
 |-- version: string (nullable = true)
 |-- scope: integer (nullable = true)
 |-- type: string (nullable = true)
 |-- foreign_install: boolean (nullable = true)
 |-- has_binary_components: boolean (nullable = true)
 |-- install_day: integer (nullable = true)
 |-- update_day: integer (nullable = true)
 |-- signed_state: integer (nullable = true)
 |-- is_system: boolean (nullable = true)
 |-- submission_date_s3: string (nullable = true)
 |-- sample_id: string (nullable = true)
</code></pre>
<p>For more detail on where these fields come from in the
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/environment.html#addons">raw data</a>,
please look
<a href="https://github.com/mozilla/telemetry-batch-view/blob/master/GRAVEYARD.md#main-summary-clients-daily-and-addons">in the <code>AddonsView</code> code</a>.</p>
<p>The fields are all simple scalar values.</p>
<h1><a class="header" href="#addons_daily-derived-dataset" id="addons_daily-derived-dataset"><code>addons_daily</code> Derived Dataset</a></h1>
<h2><a class="header" href="#introduction-4" id="introduction-4">Introduction:</a></h2>
<p>The <code>addons_daily</code> dataset serves as the central hub for all Firefox extension related questions.
This includes questions regarding browser performance, user engagement, click through rates, etc.
Each row in the table represents a unique add-on, and each column is a unique metric.</p>
<h3><a class="header" href="#contents-9" id="contents-9">Contents</a></h3>
<p>Prior to construction of this dataset, extension related data lived in several different sources.
<code>Addons_daily</code> has combined metrics aggregated from several sources,
including raw pings, telemetry data, and google analytics data.
Note that the data is a 1% sample of Release Firefox, so metrics like <code>DAU</code>, <code>WAU</code>, etc are approximate.</p>
<h3><a class="header" href="#accessing-the-data-14" id="accessing-the-data-14">Accessing the Data</a></h3>
<p>The data is stored as a parquet table in S3 <code>s3://telemetry-parquet/addons_daily/v1/</code></p>
<p><em><strong>The <code>addons_daily</code> table is accessible through re:dash using the Athena data source.
It is also available via the Presto data source,
though Athena should be preferred for performance and stability reasons.</strong></em></p>
<h2><a class="header" href="#data-reference-2" id="data-reference-2">Data Reference</a></h2>
<h3><a class="header" href="#example-queries-1" id="example-queries-1">Example Queries</a></h3>
<h4><a class="header" href="#query-1" id="query-1">Query 1</a></h4>
<p>Select average daily, weekly, monthly active users,
as well as the proportion of total daily active users per  for all non system <code>add-ons</code>.</p>
<pre><code class="language-sql">SELECT addon_id,
       arbitrary(name) as name,
       avg(dau) as &quot;Average DAU&quot;,
       avg(wau) as &quot;Average WAU&quot;,
       avg(mau) as &quot;Average MAU&quot;,
       avg(dau_prop) as &quot;Average % of Total DAU&quot;
FROM addons_daily
WHERE
  is_system = false
  and addon_id not like '%mozilla%'
GROUP BY 1
ORDER BY 3 DESC
</code></pre>
<p>This query can be seen and ran in STMO <a href="https://sql.telemetry.mozilla.org/queries/63294/source">here</a>.</p>
<h4><a class="header" href="#query-2" id="query-2">Query 2</a></h4>
<p>Select average daily active users for the <code>uBlock add-on</code> for all dates.</p>
<pre><code class="language-sql">SELECT DATE_PARSE(submission_date_s3, '%Y%m%d') as &quot;Date&quot;,
       dau as &quot;DAU&quot;
FROM addons_daily
WHERE
    addon_id = 'uBlock0@raymondhill.net'
</code></pre>
<p>This query can be seen and ran in STMO <a href="https://sql.telemetry.mozilla.org/queries/63293/source#162153">here</a></p>
<h3><a class="header" href="#scheduling-2" id="scheduling-2">Scheduling</a></h3>
<p>This dataset is updated daily via the telemetry-airflow infrastructure.
The job runs as part of the <code>main_summary</code> DAG.</p>
<h3><a class="header" href="#schema-1" id="schema-1">Schema</a></h3>
<p>The data is partitioned by <code>submission_date_s3</code> which is formatted as <code>%Y%m%d</code>, like <code>20180130</code>.
As of 2019-06-05, the current version of the <code>addons_daily</code> dataset is <code>v1</code>, and has a schema as follows:</p>
<pre><code>root
|-- addon_id: string (nullable = true)
 |-- name: string (nullable = true)
 |-- os_pct: map (nullable = true)
 |    |-- key: string
 |    |-- value: double (valueContainsNull = false)
 |-- country_pct: map (nullable = true)
 |    |-- key: string
 |    |-- value: double (valueContainsNull = false)
 |-- avg_time_total: double (nullable = true)
 |-- active_hours: double (nullable = true)
 |-- disabled: long (nullable = true)
 |-- avg_tabs: double (nullable = true)
 |-- avg_bookmarks: double (nullable = true)
 |-- avg_toolbox_opened_count: double (nullable = true)
 |-- avg_uri: double (nullable = true)
 |-- pct_w_tracking_prot_enabled: double (nullable = true)
 |-- mau: long (nullable = true)
 |-- wau: long (nullable = true)
 |-- dau: long (nullable = true)
 |-- dau_prop: double (nullable = true)
 |-- search_with_ads: map (nullable = true)
 |    |-- key: string
 |    |-- value: long (valueContainsNull = true)
 |-- ad_click: map (nullable = true)
 |    |-- key: string
 |    |-- value: long (valueContainsNull = true)
 |-- organic_searches: map (nullable = true)
 |    |-- key: string
 |    |-- value: long (valueContainsNull = true)
 |-- sap_searches: map (nullable = true)
 |    |-- key: string
 |    |-- value: long (valueContainsNull = true)
 |-- tagged_sap_searches: map (nullable = true)
 |    |-- key: string
 |    |-- value: long (valueContainsNull = true)
 |-- installs: map (nullable = true)
 |    |-- key: string
 |    |-- value: long (valueContainsNull = true)
 |-- download_times: map (nullable = true)
 |    |-- key: string
 |    |-- value: double (valueContainsNull = false)
 |-- uninstalls: map (nullable = true)
 |    |-- key: string
 |    |-- value: long (valueContainsNull = true)
 |-- is_system: boolean (nullable = true)
 |-- avg_webext_storage_local_get_ms_: double (nullable = true)
 |-- avg_webext_storage_local_set_ms_: double (nullable = true)
 |-- avg_webext_extension_startup_ms_: double (nullable = true)
 |-- top_10_coinstalls: map (nullable = true)
 |    |-- key: string
 |    |-- value: string (valueContainsNull = true)
 |-- avg_webext_background_page_load_ms_: double (nullable = true)
 |-- avg_webext_browseraction_popup_open_ms_: double (nullable = true)
 |-- avg_webext_pageaction_popup_open_ms_: double (nullable = true)
 |-- avg_webext_content_script_injection_ms_: double (nullable = true)
</code></pre>
<h2><a class="header" href="#code-reference" id="code-reference">Code Reference</a></h2>
<p>All code can be found <a href="https://github.com/mozilla/addons_daily">here</a>.
Refer to this repository for information on how to run or augment the dataset.</p>
<h1><a class="header" href="#clients-daily" id="clients-daily">Clients Daily</a></h1>
<ul>
<li><a href="datasets/batch_view/clients_daily/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/batch_view/clients_daily/reference.html#contents">Contents</a></li>
<li><a href="datasets/batch_view/clients_daily/reference.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="datasets/batch_view/clients_daily/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/batch_view/clients_daily/reference.html#example-queries">Example Queries</a>
<ul>
<li><a href="datasets/batch_view/clients_daily/reference.html#compute-churn-for-a-one-day-cohort">Compute Churn for a one-day cohort:</a></li>
<li><a href="datasets/batch_view/clients_daily/reference.html#distribution-of-pings-per-client-per-day">Distribution of pings per client per day:</a></li>
</ul>
</li>
<li><a href="datasets/batch_view/clients_daily/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/batch_view/clients_daily/reference.html#schema">Schema</a></li>
</ul>
</li>
<li><a href="datasets/batch_view/clients_daily/reference.html#code-reference">Code Reference</a></li>
</ul>
<h1><a class="header" href="#introduction-5" id="introduction-5">Introduction</a></h1>
<p>The <code>clients_daily</code> table is intended as the first stop for asking questions
about how people use Firefox. It should be easy to answer simple questions.
Each row in the table is a (<code>client_id</code>, <code>submission_date</code>) and contains a
number of aggregates about that day's activity.</p>
<h4><a class="header" href="#contents-10" id="contents-10">Contents</a></h4>
<p>Many questions about Firefox take the form &quot;What did clients with
characteristics X, Y, and Z do during the period S to E?&quot; The
<code>clients_daily</code> table is aimed at answer those questions.</p>
<h4><a class="header" href="#accessing-the-data-15" id="accessing-the-data-15">Accessing the Data</a></h4>
<p>The <code>clients_daily</code> table is accessible through re:dash using the
<code>Telemetry (BigQuery)</code> data source.</p>
<p>Here's an <a href="https://sql.telemetry.mozilla.org/queries/23746#61771">example query</a>.</p>
<h1><a class="header" href="#data-reference-3" id="data-reference-3">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-2" id="example-queries-2">Example Queries</a></h2>
<h4><a class="header" href="#compute-churn-for-a-one-day-cohort" id="compute-churn-for-a-one-day-cohort">Compute Churn for a one-day cohort:</a></h4>
<pre><code class="language-sql">SELECT
  submission_date,
  approx_count_distinct(client_id) AS cohort_dau
FROM
  telemetry.clients_daily
WHERE
  submission_date &gt; '2017-08-31'
  AND submission_date &lt; '2017-10-01'
  AND profile_creation_date LIKE '2017-09-01%'
GROUP BY 1
ORDER BY 1
</code></pre>
<h4><a class="header" href="#distribution-of-pings-per-client-per-day" id="distribution-of-pings-per-client-per-day">Distribution of pings per client per day:</a></h4>
<pre><code class="language-sql">SELECT
  normalized_channel,
  CASE
    WHEN pings_aggregated_by_this_row &gt; 50 THEN 50
    ELSE pings_aggregated_by_this_row
  END AS pings_per_day,
  approx_count_distinct(client_id) AS client_count
FROM telemetry.clients_daily
WHERE
  submission_date = '2017-09-01'
  AND normalized_channel &lt;&gt; 'Other'
GROUP BY
  normalized_channel,
  pings_per_day
ORDER BY
  pings_per_day,
  normalized_channel
</code></pre>
<h2><a class="header" href="#scheduling-3" id="scheduling-3">Scheduling</a></h2>
<p>This dataset is updated daily via the
<a href="https://github.com/mozilla/telemetry-airflow">telemetry-airflow</a> infrastructure.
The job runs as part of the <a href="https://github.com/mozilla/telemetry-airflow/blob/master/dags/main_summary.py"><code>main_summary</code> DAG</a>.</p>
<h2><a class="header" href="#schema-2" id="schema-2">Schema</a></h2>
<p>The data is partitioned by <code>submission_date</code>.</p>
<p>As of 2019-11-28, the current version of the <code>clients_daily</code> dataset is <code>v6</code>.</p>
<h1><a class="header" href="#code-reference-1" id="code-reference-1">Code Reference</a></h1>
<p>This dataset is generated by
<a href="https://github.com/mozilla/bigquery-etl/blob/25b702d0824b96ec1342d653296adfbe1302027d/sql/telemetry_derived/clients_daily_v6/query.sql"><code>bigquery-etl</code></a>.
Refer to this repository for information on how to run or augment the dataset.</p>
<h1><a class="header" href="#clients-last-seen-reference" id="clients-last-seen-reference">Clients Last Seen Reference</a></h1>
<ul>
<li><a href="datasets/bigquery/clients_last_seen/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/bigquery/clients_last_seen/reference.html#content">Content</a></li>
<li><a href="datasets/bigquery/clients_last_seen/reference.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="datasets/bigquery/clients_last_seen/reference.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="datasets/bigquery/clients_last_seen/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/bigquery/clients_last_seen/reference.html#example-queries">Example Queries</a>
<ul>
<li><a href="datasets/bigquery/clients_last_seen/reference.html#compute-dau-for-non-windows-clients-for-the-last-week">Compute DAU for non-windows clients for the last week</a></li>
<li><a href="datasets/bigquery/clients_last_seen/reference.html#compute-wau-by-channel-for-the-last-week">Compute WAU by Channel for the last week</a></li>
</ul>
</li>
<li><a href="datasets/bigquery/clients_last_seen/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/bigquery/clients_last_seen/reference.html#schema">Schema</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#introduction-6" id="introduction-6">Introduction</a></h1>
<p>The <code>clients_last_seen</code> dataset is useful for efficiently determining exact
user counts such as <a href="datasets/bigquery/clients_last_seen/../../../cookbooks/dau.html">DAU and MAU</a>.</p>
<p>It does <em>not</em> use approximates, unlike the HyperLogLog algorithm used in the
<a href="datasets/bigquery/clients_last_seen//datasets/obsolete/client_count/reference.html"><code>client_count_daily</code> dataset</a>,
and it includes the most recent values in a 28 day window for all columns in
the <a href="datasets/bigquery/clients_last_seen//datasets/batch_view/clients_daily/reference.html"><code>clients_daily</code> dataset</a>.</p>
<p>This dataset should be used instead of <code>client_count_daily</code>.</p>
<h4><a class="header" href="#content-3" id="content-3">Content</a></h4>
<p>For each <code>submission_date</code> this dataset contains one row per <code>client_id</code>
that appeared in <code>clients_daily</code> in a 28 day window including
<code>submission_date</code> and preceding days.</p>
<p>The <code>days_since_seen</code> column indicates the difference between <code>submission_date</code>
and the most recent <code>submission_date</code> in <code>clients_daily</code> where the <code>client_id</code>
appeared. A client observed on the given <code>submission_date</code> will have <code>days_since_seen = 0</code>.</p>
<p>Other <code>days_since_</code> columns use the most recent date in <code>clients_daily</code> where
a certain condition was met. If the condition was not met for a <code>client_id</code> in
a 28 day window <code>NULL</code> is used. For example <code>days_since_visited_5_uri</code> uses the
condition <code>scalar_parent_browser_engagement_total_uri_count_sum &gt;= 5</code>. These
columns can be used for user counts where a condition must be met on any day
in a window instead of using the most recent values for each <code>client_id</code>.</p>
<p>The rest of the columns use the most recent value in <code>clients_daily</code> where
the <code>client_id</code> appeared.</p>
<h4><a class="header" href="#background-and-caveats-7" id="background-and-caveats-7">Background and Caveats</a></h4>
<p>User counts generated using <code>days_since_seen</code> only reflect the most recent
values from <code>clients_daily</code> for each <code>client_id</code> in a 28 day window. This means
<a href="datasets/bigquery/clients_last_seen/../../../cookbooks/active_dau.html">Active MAU</a>
as defined cannot be efficiently calculated using <code>days_since_seen</code> because if
a given <code>client_id</code> appeared every day in February and only on February 1st had
<code>scalar_parent_browser_engagement_total_uri_count_sum &gt;= 5</code> then it would only
be counted on the 1st, and not the 2nd-28th. Active MAU can be efficiently and
correctly calculated using <code>days_since_visited_5_uri</code>.</p>
<p>MAU can be calculated over a <code>GROUP BY submission_date[, ...]</code> clause using
<code>COUNT(*)</code>, because there is exactly one row in the dataset for each
<code>client_id</code> in the 28 day MAU window for each <code>submission_date</code>.</p>
<p>User counts generated using <code>days_since_seen</code> can use <code>SUM</code> to reduce groups,
because a given <code>client_id</code> will only be in one group per <code>submission_date</code>. So
if MAU were calculated by <code>country</code> and <code>channel</code>, then the sum of the MAU for
each <code>country</code> would be the same as if MAU were calculated only by <code>channel</code>.</p>
<h4><a class="header" href="#accessing-the-data-16" id="accessing-the-data-16">Accessing the Data</a></h4>
<p>The data is available in Re:dash and BigQuery. Take a look at this full running
<a href="https://sql.telemetry.mozilla.org/queries/62029/source#159510">example query in Re:dash</a>.</p>
<h1><a class="header" href="#data-reference-4" id="data-reference-4">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-3" id="example-queries-3">Example Queries</a></h2>
<h4><a class="header" href="#compute-dau-for-non-windows-clients-for-the-last-week" id="compute-dau-for-non-windows-clients-for-the-last-week">Compute DAU for non-windows clients for the last week</a></h4>
<pre><code class="language-sql">SELECT
    submission_date,
    os,
    COUNT(*) AS count
FROM
    clients_last_seen
WHERE
    submission_date &gt;= DATE_SUB(CURRENT_DATE, INTERVAL 1 WEEK)
    AND days_since_seen = 0
GROUP BY
    submission_date,
    os
HAVING
    count &gt; 10 -- remove outliers
    AND lower(os) NOT LIKE '%windows%'
ORDER BY
    os,
    submission_date DESC
</code></pre>
<h4><a class="header" href="#compute-wau-by-channel-for-the-last-week" id="compute-wau-by-channel-for-the-last-week">Compute WAU by Channel for the last week</a></h4>
<pre><code class="language-sql">SELECT
    submission_date,
    normalized_channel,
    COUNT(*) AS count
FROM
    clients_last_seen
WHERE
    submission_date &gt;= DATE_SUB(CURRENT_DATE, INTERVAL 1 WEEK)
    AND days_since_seen &lt; 7
GROUP BY
    submission_date,
    normalized_channel
HAVING
    count &gt; 10 -- remove outliers
ORDER BY
    normalized_channel,
    submission_date DESC
</code></pre>
<h2><a class="header" href="#scheduling-4" id="scheduling-4">Scheduling</a></h2>
<p>This dataset is updated daily via the
<a href="https://github.com/mozilla/telemetry-airflow">telemetry-airflow</a>
infrastructure. The job runs as part of the
<a href="https://github.com/mozilla/telemetry-airflow/blob/89a6dc3/dags/main_summary.py#L365"><code>main_summary</code> DAG</a>.</p>
<h2><a class="header" href="#schema-3" id="schema-3">Schema</a></h2>
<p>The data is partitioned by <code>submission_date</code>.</p>
<p>As of 2019-03-25, the current version of the <code>clients_last_seen</code> dataset is
<code>v1</code>, and the schema is visible in the BigQuery console
<a href="https://console.cloud.google.com/bigquery?p=moz-fx-data-derived-datasets&amp;d=telemetry&amp;t=clients_last_seen_v1&amp;page=table">here</a>.</p>
<h1><a class="header" href="#introduction-7" id="introduction-7">Introduction</a></h1>
<p>This is a work in progress.
The work is being tracked
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1364170">here</a>.</p>
<h1><a class="header" href="#data-reference-5" id="data-reference-5">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-4" id="example-queries-4">Example Queries</a></h2>
<p>This is a work in progress.
The work is being tracked
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1364170">here</a>.</p>
<h2><a class="header" href="#sampling-1" id="sampling-1">Sampling</a></h2>
<p>The events dataset contains one row for each event in a main ping.
This dataset is derived from <a href="datasets/batch_view/events/../main_summary/reference.html"><code>main_summary</code></a>
so any of <code>main_summary</code>'s filters affect this dataset as well.</p>
<p>Data is currently available from 2017-01-05 on.</p>
<h2><a class="header" href="#scheduling-5" id="scheduling-5">Scheduling</a></h2>
<p>The events dataset is updated daily, shortly after
<a href="datasets/batch_view/events/../main_summary/reference.html"><code>main_summary</code></a> is updated.
The job is scheduled on <a href="https://github.com/mozilla/telemetry-airflow">Airflow</a>.
The DAG is <a href="https://github.com/mozilla/telemetry-airflow/blob/master/dags/main_summary.py#L63">here</a>.</p>
<h2><a class="header" href="#firefox-events" id="firefox-events">Firefox events</a></h2>
<p>Firefox has an API to record events, which are then submitted through the main ping.
The format and mechanism of event collection in Firefox is documented <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/events.html">here</a>.</p>
<p>The full events data pipeline is <a href="datasets/batch_view/events/../../../concepts/pipeline/event_pipeline.html">documented here</a>.</p>
<h2><a class="header" href="#schema-4" id="schema-4">Schema</a></h2>
<p>As of 2017-01-26, the current version of the <code>events</code> dataset is <code>v1</code>, and has a schema as follows:</p>
<pre><code>root
 |-- document_id: string (nullable = true)
 |-- client_id: string (nullable = true)
 |-- normalized_channel: string (nullable = true)
 |-- country: string (nullable = true)
 |-- locale: string (nullable = true)
 |-- app_name: string (nullable = true)
 |-- app_version: string (nullable = true)
 |-- os: string (nullable = true)
 |-- os_version: string (nullable = true)
 |-- subsession_start_date: string (nullable = true)
 |-- subsession_length: long (nullable = true)
 |-- sync_configured: boolean (nullable = true)
 |-- sync_count_desktop: integer (nullable = true)
 |-- sync_count_mobile: integer (nullable = true)
 |-- timestamp: long (nullable = true)
 |-- sample_id: string (nullable = true)
 |-- event_timestamp: long (nullable = false)
 |-- event_category: string (nullable = false)
 |-- event_method: string (nullable = false)
 |-- event_object: string (nullable = false)
 |-- event_string_value: string (nullable = true)
 |-- event_map_values: map (nullable = true)
 |    |-- key: string
 |    |-- value: string
 |-- submission_date_s3: string (nullable = true)
 |-- doc_type: string (nullable = true)
</code></pre>
<h1><a class="header" href="#exact-mau-data" id="exact-mau-data">Exact MAU Data</a></h1>
<h2><a class="header" href="#introduction-8" id="introduction-8">Introduction</a></h2>
<p>This article introduces the usage of and methodology behind the &quot;exact MAU&quot;
tables in BigQuery:</p>
<ul>
<li><code>firefox_desktop_exact_mau28_by_dimensions_v1</code>,</li>
<li><code>firefox_nondesktop_exact_mau28_by_dimensions_v1</code>, and</li>
<li><code>firefox_accounts_exact_mau28_by_dimensions_v1</code>.</li>
</ul>
<p>The calculation of MAU (monthly active users) has historically been fraught
with troubling details around exact definitions and computational limitations,
leading to disagreements between analyses.
These tables contain pre-computed MAU, WAU, and DAU aggregates for
various usage criteria and dimensions, allowing efficient calculation of
aggregates across arbitrary slices of those dimensions.
The tables follow a consistent methodology which is intended as a standard
across Mozilla for MAU analysis going forward.</p>
<h2><a class="header" href="#table-of-contents-3" id="table-of-contents-3">Table of Contents</a></h2>
<ul>
<li><a href="datasets/bigquery/exact_mau/reference.html#conceptual-model">Conceptual Model</a>
<ul>
<li><a href="datasets/bigquery/exact_mau/reference.html#metric">Metric</a></li>
<li><a href="datasets/bigquery/exact_mau/reference.html#usage-criteria">Usage Criteria</a></li>
<li><a href="datasets/bigquery/exact_mau/reference.html#slice">Slice</a></li>
</ul>
</li>
<li><a href="datasets/bigquery/exact_mau/reference.html#using-the-tables">Using the Tables</a></li>
<li><a href="datasets/bigquery/exact_mau/reference.html#additional-details">Additional Details</a>
<ul>
<li><a href="datasets/bigquery/exact_mau/reference.html#inclusive-tier-1-calculation-for-fxa">Inclusive Tier 1 Calculation for FxA</a></li>
<li><a href="datasets/bigquery/exact_mau/reference.html#confidence-intervals">Confidence Intervals</a></li>
</ul>
</li>
<li><a href="datasets/bigquery/exact_mau/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/bigquery/exact_mau/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/bigquery/exact_mau/reference.html#schema">Schema</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#conceptual-model" id="conceptual-model">Conceptual Model</a></h1>
<h2><a class="header" href="#metric" id="metric">Metric</a></h2>
<p>A metric is anything want to (and can) measure.  In order for a metric to be 
calculated, a <em>usage criterion</em> and a <em>slice</em> must be specified. The metric 
will produce a single value per day, summarizing data:</p>
<ul>
<li>for one day or more days (i.e. the metric value for a particular day may depend on data from other days as well)</li>
<li>for all users (whatever notion of user makes sense for the data, generally profiles) in a particular sub-population</li>
<li>where the sub-population will include users that meet the specified usage criteria and are in the specified slice.</li>
</ul>
<p>A simple <em>usage criterion</em> is &quot;All Desktop Activity&quot;, which includes all Firefox Desktop users that we have any data (telemetry ping) for on the day in question.  The simplest slice is &quot;All&quot; which places no restrictions on the sub-population.</p>
<p>For example, the metric &quot;Daily Active Users (DAU)&quot; with usage criteria &quot;All Desktop Activity&quot; and slice &quot;All&quot; involves summarizing data on all users of Firefox Desktop over a single day.</p>
<h2><a class="header" href="#usage-criteria" id="usage-criteria">Usage Criteria</a></h2>
<p>Active user counts must always be calculated in reference to some specific
<em>usage criterion</em>, a binary condition we use to determine whether a given
user should be considered &quot;active&quot; in a given product or feature.
It may be something simple like &quot;All Desktop Activity&quot; (as above) or,
similarly, &quot;All Mobile Activity&quot;.  It may also be something more specific like
&quot;Desktop Visited 5 URI&quot; corresponding to calculation of
<a href="datasets/bigquery/exact_mau/../../../cookbooks/active_dau.html">aDAU</a>.</p>
<p>Distinct usage criteria correspond to distinct <code>*_mau</code> columns in the Exact MAU tables.</p>
<h2><a class="header" href="#slice" id="slice">Slice</a></h2>
<p>A slice defines the sub-population on which we can calculate a metric and
is specified by setting restrictions in different dimensions.
Examples of dimensions include: &quot;Country&quot;, &quot;Attribution Source&quot;,
and &quot;Firefox Version&quot;.
Thus an example slice may be &quot;Country = US; Firefox Version = 60|61&quot;, which
restricts to profiles that report usage in the US on Firefox versions 60 or 61.
There is implicitly no restriction on any other dimensions.
Thus, the empty slice - &quot;All&quot; - is also a valid slice and simply places no 
restrictions on any dimension.
Note there are some complexities here:</p>
<ul>
<li>Firstly, a dimension may be scalar and need to be suitably bucketed (instead of every possible profile age being a unique slice element, maybe we prefer to group users between 12 and 16 months old into a single slice element); likewise we may need to use normalized versions of string fields</li>
<li>Secondly, we require that dimensions be non-overlapping, especially for metrics calculated over multiple days of user activity.  In a given day, a profile may be active in multiple countries, but we aggregate that to a single value by taking the most frequent value seen in that day, breaking ties by taking the value that occurs last. In a given month, the assigned country may change from day to day; we use the value from the most recent active day up to the day we're calculating usage for.</li>
</ul>
<p>A slice is expressed as a set of conditions in <code>WHERE</code> or <code>GROUP BY</code> clauses
when querying Exact MAU tables.</p>
<h1><a class="header" href="#using-the-tables" id="using-the-tables">Using the Tables</a></h1>
<p>The various Exact MAU datasets are computed daily from the <code>*_last_seen</code>
tables (see <a href="datasets/bigquery/exact_mau//datasets/bigquery/clients_last_seen/reference.html"><code>clients_last_seen</code></a>)
and contain pre-computed DAU, WAU, and MAU counts per usage criterion
per each unique combination of dimensions values.
Because of our restriction that dimension values be non-overlapping, we
can recover MAU for a particular slice of the data by summing over all rows
matching the slice definition.</p>
<p>The simple case of retrieving MAU for usage criterion
&quot;All Desktop Activity&quot; and slice &quot;All&quot; looks like:</p>
<pre><code class="language-sql">SELECT
    submission_date,
    SUM(mau) AS mau
FROM
    `moz-fx-data-derived-datasets.telemetry.firefox_desktop_exact_mau28_by_dimensions_v1`
GROUP BY
    submission_date
ORDER BY
    submission_date
</code></pre>
<p>Now, let's refine our slice to &quot;Country = US; Campaign = <code>whatsnew</code>&quot;
via a <code>WHERE</code> clause:</p>
<pre><code class="language-sql">SELECT
    submission_date,
    SUM(mau) AS mau
FROM
    `moz-fx-data-derived-datasets.telemetry.firefox_desktop_exact_mau28_by_dimensions_v1`
WHERE
    country = 'US'
    AND campaign = 'whatsnew'
GROUP BY
    submission_date
ORDER BY
    submission_date
</code></pre>
<p>Perhaps we want to compare MAU as above to  <a href="datasets/bigquery/exact_mau/../../../cookbooks/active_dau.html">aDAU</a>
over the same slice. The column <code>visited_5_uri_dau</code> gives DAU as calculated
with the &quot;Desktop Visited 5 URI&quot; usage criterion, corresponding to aDAU:</p>
<pre><code>SELECT
    submission_date,
    SUM(mau) AS mau,
    SUM(visited_5_uri_dau) AS adau
FROM
    `moz-fx-data-derived-datasets.telemetry.firefox_desktop_exact_mau28_by_dimensions_v1`
WHERE
    country = 'US'
    AND campaign = 'whatsnew'
GROUP BY
    submission_date
ORDER BY
    submission_date
</code></pre>
<p>Additional usage criteria may be added in the future as new columns named
<code>*_*mau</code>, etc. where the prefix describes the usage criterion.</p>
<p>For convenience and clarity, we make the exact data presented in the
<a href="https://dbc-caf9527b-e073.cloud.databricks.com/#job/1160/run/latestSuccess/dashboard/42765b23-7b69-4d59-b08b-ea9cf45b63df">2019 Key Performance Indicator Dashboard</a>
available as views that do not require any aggregation:</p>
<ul>
<li><code>firefox_desktop_exact_mau28_v1</code>,</li>
<li><code>firefox_nondesktop_exact_mau28_v1</code>, and</li>
<li><code>firefox_accounts_exact_mau28_v1</code>.</li>
</ul>
<p>An example query for desktop:</p>
<pre><code>SELECT
    submission_date,
    mau,
    tier1_mau
FROM
    `moz-fx-data-derived-datasets.telemetry.firefox_desktop_exact_mau28_v1`
</code></pre>
<p>These views contain no dimensions and abstract away the detail that FxA
data uses the &quot;Last Seen in Tier 1 Country&quot; usage criterion while desktop
and non-desktop data use the &quot;Country&quot; dimension to determine tier 1 membership.</p>
<h1><a class="header" href="#additional-details" id="additional-details">Additional Details</a></h1>
<h2><a class="header" href="#inclusive-tier-1-calculation-for-fxa" id="inclusive-tier-1-calculation-for-fxa">Inclusive Tier 1 Calculation for FxA</a></h2>
<p>The 2019 Key Performance Indicator definition for Relationships relies on a MAU calculation restricted
to a specific set of &quot;Tier 1&quot; countries. 
In the Exact MAU datasets, country is a dimension that would normally be specified
in a slice definition.
Indeed, for desktop and non-desktop clients, the definition of &quot;Tier 1 MAU&quot; looks like:</p>
<pre><code>SELECT
    submission_date,
    SUM(mau) AS mau
FROM
    `moz-fx-data-derived-datasets.telemetry.firefox_desktop_exact_mau28_by_dimensions_v1`
WHERE
    country IN ('US', 'UK', 'DE', 'FR', 'CA')
GROUP BY
    submission_date
ORDER BY
    submission_date
</code></pre>
<p>Remember that our non-overlapping dimensions methodology means that the filter
in the query above considers only the country value from the most recent daily
aggregation, so a user that appeared in one of the specified countries early
in the month but then changed location to a non-tier 1 country would not count
toward MAU.</p>
<p>Due to the methodology used when forecasting goal values for the year, however, we need to
follow a more inclusive definition for &quot;Tier 1 FxA MAU&quot; where a user counts if they register
even a single FxA event originating from a tier 1 country in the 28 day MAU window.
That calculation requires a separate &quot;FxA Seen in Tier 1 Country&quot; criterion
and is represented in the exact MAU table as <code>seen_in_tier1_country_mau</code>:</p>
<pre><code>SELECT
    submission_date,
    SUM(seen_in_tier1_country_mau) AS tier1_mau
FROM
    `moz-fx-data-derived-datasets.telemetry.firefox_accounts_exact_mau28_by_dimensions_v1`
GROUP BY
    submission_date
ORDER BY
    submission_date
</code></pre>
<h2><a class="header" href="#confidence-intervals" id="confidence-intervals">Confidence Intervals</a></h2>
<p>The Exact MAU tables enable tracking of MAU for potentially very small
subpopulations of users where statistical variation can often overwhelm
real trends in the data. 
In order to support statistical inference (confidence intervals and hypothesis tests), 
these tables include a &quot;pseudo-dimension&quot; we call <code>id_bucket</code>. We assign
each client (or user, in the case of FxA data) to one of 20 buckets based on a
hash of their <code>client_id</code> (or <code>user_id</code>), with the effect that each user is
randomly assigned to one and only one bucket. If we sum MAU numbers for each
bucket individually, we can use resampling techniques to determine the magnitude
of variation and assign a confidence interval to our sums.</p>
<p>As an example of calculating confidence intervals, see the
<a href="https://sql.telemetry.mozilla.org/queries/61957/source">Desktop MAU KPI query in STMO</a>
which uses a jackknife resampling technique implemented as a BigQuery UDF.</p>
<h1><a class="header" href="#data-reference-6" id="data-reference-6">Data Reference</a></h1>
<h2><a class="header" href="#scheduling-6" id="scheduling-6">Scheduling</a></h2>
<p>These tables are updated daily via the
<a href="https://github.com/mozilla-services/spark-parquet-to-bigquery">parquet to BigQuery</a>
infrastructure in the following DAGs:</p>
<ul>
<li><a href="https://github.com/mozilla-services/spark-parquet-to-bigquery/blob/master/dags/reprocess_clients_daily_v6.py"><code>reprocess_clients_daily_v6</code> DAG</a>,</li>
<li><a href="https://github.com/mozilla-services/spark-parquet-to-bigquery/blob/master/dags/incremental_telemetry_core_parquet_v3.py"><code>incremental_telemetry_core_parquet_v3</code> DAG</a>, and</li>
<li><a href="https://github.com/mozilla-services/spark-parquet-to-bigquery/blob/master/dags/incremental_fxa_events_v1.py"><code>incremental_fxa_events_v1</code> DAG</a>.</li>
</ul>
<h2><a class="header" href="#schema-5" id="schema-5">Schema</a></h2>
<p>The data is partitioned by <code>submission_date</code>.</p>
<p>As of 2019-03-29, the current version for all Exact MAU tables is <code>v1</code>,
and the schemas are visible via the <code>telemetry</code> dataset in <a href="https://console.cloud.google.com/bigquery?project=moz-fx-data-derived-datasets&amp;folder&amp;organizationId=442341870013&amp;p=moz-fx-data-derived-datasets&amp;d=telemetry&amp;page=dataset">the BigQuery console</a>.</p>
<h1><a class="header" href="#first-shutdown-summary" id="first-shutdown-summary">First Shutdown Summary</a></h1>
<ul>
<li><a href="datasets/batch_view/first_shutdown_summary/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/batch_view/first_shutdown_summary/reference.html#contents">Contents</a></li>
<li><a href="datasets/batch_view/first_shutdown_summary/reference.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="datasets/batch_view/first_shutdown_summary/reference.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#introduction-9" id="introduction-9">Introduction</a></h1>
<p>The <code>first_shutdown_summary</code> table is a summary of the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/first-shutdown-ping.html"><code>first-shutdown</code>
ping</a>.</p>
<h4><a class="header" href="#contents-11" id="contents-11">Contents</a></h4>
<p>The first shutdown ping contains first session usage data. The
dataset has rows similar to the
<a href="datasets/batch_view/first_shutdown_summary//datasets/batch_view/new_profile/reference.html"><code>telemetry_new_profile_parquet</code></a>,
but in the shape of
<a href="datasets/batch_view/first_shutdown_summary//datasets/batch_view/main_summary/reference.html"><code>main_summary</code></a>.</p>
<h4><a class="header" href="#background-and-caveats-8" id="background-and-caveats-8">Background and Caveats</a></h4>
<p>Ping latency was reduced through the
shutdown ping-sender mechanism in Firefox 55. To maintain consistent historical
behavior, the first main ping is not sent until the second start up. In Firefox 57, a
separate first-shutdown ping was created to evaluate first-shutdown behavior while maintaining backwards compatibility.</p>
<p>In many cases, the first-shutdown ping is a duplicate of the main ping. The first-shutdown summary can be used in conjunction with the main summary by taking the union and deduplicating on the <code>document_id</code>.</p>
<h4><a class="header" href="#accessing-the-data-17" id="accessing-the-data-17">Accessing the Data</a></h4>
<p>The data can be accessed as <code>first_shutdown_summary</code>.</p>
<p>The data is backfilled to 2017-09-22, the date of its first nightly appearance. This data should be available to all releases on and after Firefox 57.</p>
<h1><a class="header" href="#main-summary" id="main-summary">Main Summary</a></h1>
<ul>
<li><a href="datasets/batch_view/main_summary/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/batch_view/main_summary/reference.html#contents">Contents</a></li>
<li><a href="datasets/batch_view/main_summary/reference.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="datasets/batch_view/main_summary/reference.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="datasets/batch_view/main_summary/reference.html#adding-new-fields">Adding New Fields</a>
<ul>
<li><a href="datasets/batch_view/main_summary/reference.html#user-preferences">User Preferences</a></li>
<li><a href="datasets/batch_view/main_summary/reference.html#other-fields">Other Fields</a></li>
</ul>
</li>
<li><a href="datasets/batch_view/main_summary/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/batch_view/main_summary/reference.html#example-queries">Example Queries</a></li>
<li><a href="datasets/batch_view/main_summary/reference.html#sampling">Sampling</a></li>
<li><a href="datasets/batch_view/main_summary/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/batch_view/main_summary/reference.html#schema">Schema</a></li>
<li><a href="datasets/batch_view/main_summary/reference.html#time-formats">Time formats</a></li>
</ul>
</li>
<li><a href="datasets/batch_view/main_summary/reference.html#code-reference">Code Reference</a></li>
</ul>
<h1><a class="header" href="#introduction-10" id="introduction-10">Introduction</a></h1>
<h4><a class="header" href="#contents-12" id="contents-12">Contents</a></h4>
<p>The <code>main_summary</code> table contains one row for each ping.
Each column represents one field from the main ping payload,
though only a subset of all main ping fields are included.
This dataset <strong>does not include most histograms</strong>.</p>
<h4><a class="header" href="#background-and-caveats-9" id="background-and-caveats-9">Background and Caveats</a></h4>
<p>This table is massive, and due to its size, it can be difficult to work with.</p>
<p>Instead, we recommend using the <code>clients_daily</code> or <code>clients_last_seen</code> dataset
where possible.</p>
<p>If you do need to query this table, make use of the <code>sample_id</code> field and
limit to a short submission date range.</p>
<h4><a class="header" href="#accessing-the-data-18" id="accessing-the-data-18">Accessing the Data</a></h4>
<p>The <code>main_summary</code> table is accessible through re:dash.
Here's an <a href="https://sql.telemetry.mozilla.org/queries/4201/source">example query</a>.</p>
<h1><a class="header" href="#adding-new-fields" id="adding-new-fields">Adding New Fields</a></h1>
<p>We support a few basic types that can be easily added to <code>main_summary</code>.</p>
<p>Non-addon scalars are automatically added to <code>main_summary</code>.</p>
<h2><a class="header" href="#user-preferences" id="user-preferences">User Preferences</a></h2>
<p>These are added in the <a href="https://github.com/mozilla/bigquery-etl/blob/25b702d0824b96ec1342d653296adfbe1302027d/sql/telemetry_derived/main_summary_v4/part1.sql#L476-L501">Main Summary ETL code</a>.
They must be available in the <a href="http://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/environment.html">ping environment</a> to be included here.</p>
<p>Once added, they will show as top-level fields, with the string <code>user_pref</code> prepended.
For example, <code>dom.ipc.processCount</code> becomes <code>user_pref_dom_ipc_processcount</code>.</p>
<h2><a class="header" href="#other-fields" id="other-fields">Other Fields</a></h2>
<p>We can include other types of fields as well, for example if there needs to be
a specific transformation done.</p>
<p>In general, it is preferable to simply access the data directly in the <code>main</code> ping table instead.</p>
<h1><a class="header" href="#data-reference-7" id="data-reference-7">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-5" id="example-queries-5">Example Queries</a></h2>
<p>Compare the search volume for different search source values:</p>
<pre><code class="language-sql">WITH search_data AS (
  SELECT
    s.source AS search_source,
    s.count AS search_count
  FROM
    telemetry.main_summary
    CROSS JOIN UNNEST(search_counts) AS s
  WHERE
    submission_date_s3 = '2019-11-11'
    AND sample_id = 42
    AND search_counts IS NOT NULL
)

SELECT
  search_source,
  sum(search_count) as total_searches
FROM search_data
GROUP BY search_source
ORDER BY sum(search_count) DESC
</code></pre>
<h2><a class="header" href="#sampling-2" id="sampling-2">Sampling</a></h2>
<p>The <code>main_summary</code> dataset contains one record for each <code>main</code> ping
as long as the record contains a non-null value for
<code>documentId</code>, <code>submissionDate</code>, and <code>Timestamp</code>.
We do not ever expect nulls for these fields.</p>
<h2><a class="header" href="#scheduling-7" id="scheduling-7">Scheduling</a></h2>
<p>This dataset is updated daily via the <a href="https://github.com/mozilla/telemetry-airflow">telemetry-airflow</a> infrastructure.
The job DAG runs every day shortly after midnight UTC.
You can find the job definition
<a href="https://github.com/mozilla/telemetry-airflow/blob/master/dags/main_summary.py">here</a></p>
<h2><a class="header" href="#schema-6" id="schema-6">Schema</a></h2>
<p>As of 2019-11-28, the current version of the <code>main_summary</code> dataset is <code>v4</code>.</p>
<p>For more detail on where these fields come from in the
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/main-ping.html">raw data</a>,
please look <a href="https://github.com/mozilla/bigquery-etl/tree/25b702d0824b96ec1342d653296adfbe1302027d/sql/telemetry_derived/main_summary_v4">in the <code>main_summary</code> ETL code</a>.</p>
<p>Most of the fields are simple scalar values, with a few notable exceptions:</p>
<ul>
<li>The <code>search_count</code> field is an array of structs, each item in the array representing
a 3-tuple of (<code>engine</code>, <code>source</code>, <code>count</code>). The <code>engine</code> field represents the name of
the search engine against which the searches were done. The <code>source</code> field represents
the part of the Firefox UI that was used to perform the search. It contains values
such as <code>abouthome</code>, <code>urlbar</code>, and <code>searchbar</code>. The <code>count</code> field contains the number
of searches performed against this engine+source combination during that subsession.
Any of the fields in the struct may be null (for example if the search key did not
match the expected pattern, or if the count was non-numeric).</li>
<li>The <code>loop_activity_counter</code> field is a simple struct containing inner fields for each
expected value of the <code>LOOP_ACTIVITY_COUNTER</code> Enumerated Histogram. Each inner field
is a count for that histogram bucket.</li>
<li>The <code>popup_notification_stats</code> field is a map of <code>String</code> keys to struct values,
each field in the struct being a count for the expected values of the
<code>POPUP_NOTIFICATION_STATS</code> Keyed Enumerated Histogram.</li>
<li>The <code>places_bookmarks_count</code> and <code>places_pages_count</code> fields contain the <strong>mean</strong>
value of the corresponding Histogram, which can be interpreted as the average number
of bookmarks or pages in a given subsession.</li>
<li>The <code>active_addons</code> field contains an array of structs, one for each entry in
the <code>environment.addons.activeAddons</code> section of the payload. More detail in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1290181">Bug 1290181</a>.</li>
<li>The <code>disabled_addons_ids</code> field contains an array of strings, one for each entry in
the <code>payload.addonDetails</code> which is not already reported in the <code>environment.addons.activeAddons</code>
section of the payload. More detail in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1390814">Bug 1390814</a>.
Please note that while using this field is generally OK, this was introduced to support
the <a href="https://github.com/mozilla/taar/pulls">TAAR</a> project and you should not count on it
in the future. The field can stay in the <code>main_summary</code>, but we might need to slightly change
the ping structure to something better than <code>payload.addonDetails</code>.</li>
<li>The <code>theme</code> field contains a single struct in the same shape as the items in the
<code>active_addons</code> array. It contains information about the currently active browser
theme.</li>
<li>The <code>user_prefs</code> field contains a struct with values for preferences of interest.</li>
<li>The <code>events</code> field contains an array of event structs.</li>
<li>Dynamically-included histogram fields are present as key-&gt;value maps,
or key-&gt;(key-&gt;value) nested maps for keyed histograms.</li>
</ul>
<h2><a class="header" href="#time-formats" id="time-formats">Time formats</a></h2>
<p>Columns in <code>main_summary</code> may use one of a handful of time formats with different precisions:</p>
<table><thead><tr><th>Column Name</th><th>Origin</th><th>Description</th><th>Example</th><th>Spark</th><th>Presto</th></tr></thead><tbody>
<tr><td><code>timestamp</code></td><td>stamped at ingestion</td><td>nanoseconds since epoch</td><td><code>1504689165972861952</code></td><td><code>from_unixtime(timestamp/1e9)</code></td><td><code>from_unixtime(timestamp/1e9)</code></td></tr>
<tr><td><code>submission_date_s3</code></td><td>derived from timestamp</td><td><code>YYYYMMDD</code> date string of timestamp in UTC</td><td><code>20170906</code></td><td><code>from_unixtime(unix_timestamp(submission_date, 'yyyyMMdd'))</code></td><td><code>date_parse(submission_date, '%Y%m%d')</code></td></tr>
<tr><td><code>client_submission_date</code></td><td>derived from HTTP header: <code>Fields[Date]</code></td><td>HTTP date header string sent with the ping</td><td><code>Tue, 27 Sep 2016 16:28:23 GMT</code></td><td><code>unix_timestamp(client_submission_date, 'EEE, dd M yyyy HH:mm:ss zzz')</code></td><td><code>date_parse(substr(client_submission_date, 1, 25), '%a, %d %b %Y %H:%i:%s')</code></td></tr>
<tr><td><code>creation_date</code></td><td><code>creationDate</code></td><td>time of ping creation ISO8601 at UTC+0</td><td><code>2017-09-06T08:21:36.002Z</code></td><td><code>to_timestamp(creation_date, &quot;yyyy-MM-dd'T'HH:mm:ss.SSSXXX&quot;)</code></td><td><code>from_iso8601_timestamp(creation_date) AT TIME ZONE 'GMT'</code></td></tr>
<tr><td><code>timezone_offset</code></td><td><code>info.timezoneOffset</code></td><td>timezone offset in minutes</td><td><code>120</code></td><td></td><td></td></tr>
<tr><td><code>subsession_start_date</code></td><td><code>info.subsessionStartDate</code></td><td>hourly precision, ISO8601 date in local time</td><td><code>2017-09-06T00:00:00.0+02:00</code></td><td></td><td><code>from_iso8601_timestamp(subsession_start_date) AT TIME ZONE 'GMT'</code></td></tr>
<tr><td><code>subsession_length</code></td><td><code>info.subsessionLength</code></td><td>subsession length in seconds</td><td><code>599</code></td><td></td><td><code>date_add('second', subsession_length, subsession_start_date)</code></td></tr>
<tr><td><code>profile_creation_date</code></td><td><code>environment.profile.creationDate</code></td><td>days since epoch</td><td><code>15,755</code></td><td></td><td><code>from_unixtime(profile_creation_date * 86400)</code></td></tr>
</tbody></table>
<h1><a class="header" href="#code-reference-2" id="code-reference-2">Code Reference</a></h1>
<p>This dataset is generated by <a href="https://github.com/mozilla/bigquery-etl/tree/25b702d0824b96ec1342d653296adfbe1302027d/sql/telemetry_derived/main_summary_v4">bigquery-etl</a>.
Refer to this repository for information on how to run or augment the dataset.</p>
<h1><a class="header" href="#new-profile" id="new-profile">New Profile</a></h1>
<ul>
<li><a href="datasets/batch_view/new_profile/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/batch_view/new_profile/reference.html#contents">Contents</a></li>
<li><a href="datasets/batch_view/new_profile/reference.html#accessing-the-data">Accessing the Data</a></li>
<li><a href="datasets/batch_view/new_profile/reference.html#further-reading">Further Reading</a></li>
</ul>
</li>
<li><a href="datasets/batch_view/new_profile/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/batch_view/new_profile/reference.html#schema">Schema</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#introduction-11" id="introduction-11">Introduction</a></h1>
<p>The <code>telemetry_new_profile_parquet</code> table is the most direct representation of a new-profile ping.</p>
<h4><a class="header" href="#contents-13" id="contents-13">Contents</a></h4>
<p>The table contains one row for each ping. Each column represents one field from the new-profile ping payload, though only a subset of all fields are included.</p>
<h4><a class="header" href="#accessing-the-data-19" id="accessing-the-data-19">Accessing the Data</a></h4>
<p>The data is stored as a parquet table in S3 at the following address.</p>
<pre><code>s3://net-mozaws-prod-us-west-2-pipeline-data/telemetry-new-profile-parquet/v2/
</code></pre>
<p>The <code>telemetry_new_profile_parquet</code> is accessible through re:dash.
Here's an <a href="https://sql.telemetry.mozilla.org/queries/5888#table">example query</a>.</p>
<h4><a class="header" href="#further-reading-7" id="further-reading-7">Further Reading</a></h4>
<p>This dataset is generated automatically using direct to parquet. The configuration responsible for generating this dataset was introduced in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1360256">bug 1360256</a>.</p>
<h1><a class="header" href="#data-reference-8" id="data-reference-8">Data Reference</a></h1>
<h2><a class="header" href="#schema-7" id="schema-7">Schema</a></h2>
<p>As of 2018-06-26, the current version of the <code>telemetry_new_profile_parquet</code> dataset is <code>v2</code>, and has a schema as follows:</p>
<pre><code>root
 |-- id: string (nullable = true)
 |-- client_id: string (nullable = true)
 |-- metadata: struct (nullable = true)
 |    |-- timestamp: long (nullable = true)
 |    |-- date: string (nullable = true)
 |    |-- normalized_channel: string (nullable = true)
 |    |-- geo_country: string (nullable = true)
 |    |-- geo_city: string (nullable = true)
 |    |-- geo_subdivision1: string (nullable = true)
 |    |-- geo_subdivision2: string (nullable = true)
 |    |-- creation_timestamp: long (nullable = true)
 |    |-- x_ping_sender_version: string (nullable = true)
 |-- environment: struct (nullable = true)
 |    |-- build: struct (nullable = true)
 |    |    |-- application_name: string (nullable = true)
 |    |    |-- architecture: string (nullable = true)
 |    |    |-- version: string (nullable = true)
 |    |    |-- build_id: string (nullable = true)
 |    |    |-- vendor: string (nullable = true)
 |    |    |-- hotfix_version: string (nullable = true)
 |    |-- partner: struct (nullable = true)
 |    |    |-- distribution_id: string (nullable = true)
 |    |    |-- distribution_version: string (nullable = true)
 |    |    |-- partner_id: string (nullable = true)
 |    |    |-- distributor: string (nullable = true)
 |    |    |-- distributor_channel: string (nullable = true)
 |    |    |-- partner_names: array (nullable = true)
 |    |    |    |-- element: string (containsNull = true)
 |    |-- settings: struct (nullable = true)
 |    |    |-- is_default_browser: boolean (nullable = true)
 |    |    |-- default_search_engine: string (nullable = true)
 |    |    |-- default_search_engine_data: struct (nullable = true)
 |    |    |    |-- name: string (nullable = true)
 |    |    |    |-- load_path: string (nullable = true)
 |    |    |    |-- origin: string (nullable = true)
 |    |    |    |-- submission_url: string (nullable = true)
 |    |    |-- telemetry_enabled: boolean (nullable = true)
 |    |    |-- locale: string (nullable = true)
 |    |    |-- attribution: struct (nullable = true)
 |    |    |    |-- source: string (nullable = true)
 |    |    |    |-- medium: string (nullable = true)
 |    |    |    |-- campaign: string (nullable = true)
 |    |    |    |-- content: string (nullable = true)
 |    |    |-- update: struct (nullable = true)
 |    |    |    |-- channel: string (nullable = true)
 |    |    |    |-- enabled: boolean (nullable = true)
 |    |    |    |-- auto_download: boolean (nullable = true)
 |    |-- system: struct (nullable = true)
 |    |    |-- os: struct (nullable = true)
 |    |    |    |-- name: string (nullable = true)
 |    |    |    |-- version: string (nullable = true)
 |    |    |    |-- locale: string (nullable = true)
 |    |-- profile: struct (nullable = true)
 |    |    |-- creation_date: long (nullable = true)
 |-- payload: struct (nullable = true)
 |    |-- reason: string (nullable = true)
 |-- submission: string (nullable = true)
</code></pre>
<p>For more detail on the raw ping these fields come from, see the
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/new-profile-ping.html">raw data</a>.</p>
<h1><a class="header" href="#socorro-crash-reports" id="socorro-crash-reports">Socorro Crash Reports</a></h1>
<ul>
<li><a href="datasets/other/socorro_crash/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/other/socorro_crash/reference.html#contents">Contents</a>
<ul>
<li><a href="datasets/other/socorro_crash/reference.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="datasets/other/socorro_crash/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/other/socorro_crash/reference.html#example">Example</a></li>
<li><a href="datasets/other/socorro_crash/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/other/socorro_crash/reference.html#schema">Schema</a></li>
<li><a href="datasets/other/socorro_crash/reference.html#code-reference">Code Reference</a></li>
</ul>
</li>
</ul>
<h2><a class="header" href="#introduction-12" id="introduction-12">Introduction</a></h2>
<p>Public crash statistics for Firefox are available through the Data Platform in a <code>socorro_crash</code> dataset.
The crash data in <a href="https://wiki.mozilla.org/Socorro">Socorro</a> is sanitized and made available to ATMO and STMO.
A nightly import job converts batches of JSON documents into a columnar format using the associated JSON Schema. </p>
<h3><a class="header" href="#contents-14" id="contents-14">Contents</a></h3>
<h4><a class="header" href="#accessing-the-data-20" id="accessing-the-data-20">Accessing the Data</a></h4>
<p>The dataset is available in parquet at <code>s3://telemetry-parquet/socorro_crash/v2</code>.
It is also indexed with Athena and Presto with the table name <code>socorro_crash</code>.</p>
<h2><a class="header" href="#data-reference-9" id="data-reference-9">Data Reference</a></h2>
<h3><a class="header" href="#example" id="example">Example</a></h3>
<p>The dataset can be queried using SQL.
For example, we can aggregate the number of crashes and total up-time by date and reason.</p>
<pre><code class="language-sql">SELECT crash_date,
       reason,
       count(*) as n_crashes,
       avg(uptime) as avg_uptime,
       stddev(uptime) as stddev_uptime,
       approx_percentile(uptime, ARRAY [0.25, 0.5, 0.75]) as qntl_uptime
FROM socorro_crash
WHERE crash_date='20180520'
GROUP BY 1,
         2
</code></pre>
<p><a href="https://sql.telemetry.mozilla.org/queries/53884/source">STMO Source</a></p>
<h3><a class="header" href="#scheduling-8" id="scheduling-8">Scheduling</a></h3>
<p>The job is schedule on a nightly basis on airflow.
The dag is available under <a href="https://github.com/mozilla/telemetry-airflow/blob/930790116d8d5c924cd61a07311fc8a34340f3d6/dags/socorro_import.py"><code>mozilla/telemetry-airflow:/dags/socorro_import.py</code></a>.</p>
<h3><a class="header" href="#schema-8" id="schema-8">Schema</a></h3>
<p>The source schema is available on the <a href="https://raw.githubusercontent.com/mozilla/socorro/master/socorro/schemas/crash_report.json"><code>mozilla/socorro</code> GitHub repository</a>.
This schema is transformed into a Spark-SQL structure and serialized to parquet after transforming column names from <code>camelCase</code> to <code>snake_case</code>.</p>
<h3><a class="header" href="#code-reference-3" id="code-reference-3">Code Reference</a></h3>
<p>The code is <a href="https://github.com/mozilla-services/data-pipeline/blob/master/reports/socorro_import/ImportCrashData.ipynb">a notebook in the <code>mozilla-services/data-pipeline</code> repository</a>.</p>
<h1><a class="header" href="#ssl-ratios" id="ssl-ratios">SSL Ratios</a></h1>
<ul>
<li><a href="datasets/other/ssl/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/other/ssl/reference.html#content">Content</a></li>
<li><a href="datasets/other/ssl/reference.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="datasets/other/ssl/reference.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="datasets/other/ssl/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/other/ssl/reference.html#combining-rows">Combining Rows</a></li>
<li><a href="datasets/other/ssl/reference.html#schema">Schema</a></li>
<li><a href="datasets/other/ssl/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/other/ssl/reference.html#code-reference">Code Reference</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#introduction-13" id="introduction-13">Introduction</a></h1>
<p>The public SSL dataset publishes the percentage of page loads Firefox users have performed
that were conducted over SSL. This dataset is used to produce graphs like
<a href="https://letsencrypt.org/stats/">Let's Encrypt's</a> to determine SSL adoption on the Web
over time.</p>
<h4><a class="header" href="#content-4" id="content-4">Content</a></h4>
<p>The public SSL dataset is a table where each row is a distinct set of dimensions, with their
associated SSL statistics. The dimensions are <code>submission_date</code>, <code>os</code>, and <code>country</code>. The
statistics are <code>reporting_ratio</code>, <code>normalized_pageloads</code>, and <code>ratio</code>.</p>
<h4><a class="header" href="#background-and-caveats-10" id="background-and-caveats-10">Background and Caveats</a></h4>
<ul>
<li>We're using normalized values in <code>normalized_pageloads</code> to obscure absolute page load counts.</li>
<li>This is across the entirety of release, not per-version, because we're looking at Web health,
not Firefox user health.</li>
<li>Any dimension tuple (any given combination of <code>submission_date</code>, <code>os</code>, and <code>country</code>) with 
fewer than 5000 page loads is omitted from the dataset.</li>
<li>This is hopefully just a temporary dataset to stopgap release aggregates going away
until we can come up with a better way to publicly publish datasets.</li>
</ul>
<h4><a class="header" href="#accessing-the-data-21" id="accessing-the-data-21">Accessing the Data</a></h4>
<p>For details on accessing the data, please look at
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1414839">bug 1414839</a>.</p>
<h1><a class="header" href="#data-reference-10" id="data-reference-10">Data Reference</a></h1>
<h2><a class="header" href="#combining-rows" id="combining-rows">Combining Rows</a></h2>
<p>This is a dataset of ratios. You can't combine ratios if they have different bases. For example,
if 50% of 10 loads (5 loads) were SSL and 5% of 20 loads (1 load) were SSL, you cannot calculate
that 20% (6 loads) of the total loads (30 loads) were SSL unless you know that the 50% was for
10 and the 5% was for 20.</p>
<p>If you're reluctant, for product reasons, to share the numbers 10 and 20, this gets tricky.</p>
<p>So what we've done is normalize the whole batch of 30 down to 1. That means we tell you that
50% of one-third of the loads (0.333...) was SSL and 5% of the other two-thirds of the loads
(0.666...) was SSL. Then you can figure out the overall 20% figure by this calculation:</p>
<p><code>0.5 * 0.333 + 0.05 * 0.666 = 0.2</code></p>
<p>For this dataset the same rule applies. To combine rows' ratios (to, for example, see what the
SSL ratio was across all <code>os</code> and <code>country</code> for a given <code>submission_date</code>), you must first
multiply them by the rows' <code>normalized_pageviews</code> values.</p>
<p>Or, in JavaScript:</p>
<pre><code class="language-js">let rows = query_result.data.rows;
let ratioForDateInQuestion = rows
  .filter(row =&gt; row.submission_date == dateInQuestion)
  .reduce((row, acc) =&gt; acc + row.normalized_pageloads * row.ratio, 0);
</code></pre>
<h2><a class="header" href="#schema-9" id="schema-9">Schema</a></h2>
<p>The data is output in re:dash API format:</p>
<pre><code>&quot;query_result&quot;: {
  &quot;retrieved_at&quot;: &lt;timestamp&gt;,
  &quot;query_hash&quot;: &lt;hash&gt;,
  &quot;query&quot;: &lt;SQL&gt;,
  &quot;runtime&quot;: &lt;number of seconds&gt;,
  &quot;id&quot;: &lt;an id&gt;,
  &quot;data_source_id&quot;: 26, // Athena
  &quot;data_scanned&quot;: &lt;some really large number, as a string&gt;,
  &quot;data&quot;: {
    &quot;data_scanned&quot;: &lt;some really large number, as a number&gt;,
    &quot;columns&quot;: [
      {&quot;friendly_name&quot;: &quot;submission_date&quot;, &quot;type&quot;: &quot;datetime&quot;, &quot;name&quot;: &quot;submission_date&quot;},
      {&quot;friendly_name&quot;: &quot;os&quot;, &quot;type&quot;: &quot;string&quot;, &quot;name&quot;: &quot;os&quot;},
      {&quot;friendly_name&quot;: &quot;country&quot;, &quot;type&quot;: &quot;string&quot;, &quot;name&quot;: &quot;country&quot;},
      {&quot;friendly_name&quot;: &quot;reporting_ratio&quot;, &quot;type&quot;: &quot;float&quot;, &quot;name&quot;: &quot;reporting_ratio&quot;},
      {&quot;friendly_name&quot;: &quot;normalized_pageloads&quot;, &quot;type&quot;: &quot;float&quot;, &quot;name&quot;: &quot;normalized_pageloads&quot;},
      {&quot;friendly_name&quot;: &quot;ratio&quot;, &quot;type&quot;: &quot;float&quot;, &quot;name&quot;: &quot;ratio&quot;}
    ],
    &quot;rows&quot;: [
      {
        &quot;submission_date&quot;: &quot;2017-10-24T00:00:00&quot;, // date string, day resolution
        &quot;os&quot;: &quot;Windows_NT&quot;, // operating system family of the clients reporting the pageloads. One of &quot;Windows_NT&quot;, &quot;Linux&quot;, or &quot;Darwin&quot;.
        &quot;country&quot;: &quot;CZ&quot;, // ISO 639 two-character country code, or &quot;??&quot; if we have no idea. Determined by performing a geo-IP lookup of the clients that submitted the pings.
        &quot;reporting_ratio&quot;: 0.006825266611977031, // the ratio of pings that reported any pageloads at all. A number between 0 and 1. See [bug 1413258](https://bugzilla.mozilla.org/show_bug.cgi?id=1413258).
        &quot;normalized_pageloads&quot;: 0.00001759145263985348, // the proportion of total pageloads in the dataset that are represented by this row. Provided to allow combining rows. A number between 0 and 1.
        &quot;ratio&quot;: 0.6916961976822144 // the ratio of the pageloads that were performed over SSL. A number between 0 and 1.
      }, ...
    ]
  }
}
</code></pre>
<h2><a class="header" href="#scheduling-9" id="scheduling-9">Scheduling</a></h2>
<p>The dataset updates every 24 hours.</p>
<h2><a class="header" href="#code-reference-4" id="code-reference-4">Code Reference</a></h2>
<p>You can find the query that generates the SSL dataset
<a href="https://sql.telemetry.mozilla.org/queries/49323/source#table">here</a>.</p>
<h1><a class="header" href="#telemetry-aggregates-reference" id="telemetry-aggregates-reference">Telemetry Aggregates Reference</a></h1>
<ul>
<li><a href="datasets/batch_view/telemetry_aggregates/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/batch_view/telemetry_aggregates/reference.html#rows-and-columns">Rows and Columns</a></li>
<li><a href="datasets/batch_view/telemetry_aggregates/reference.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="datasets/batch_view/telemetry_aggregates/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/batch_view/telemetry_aggregates/reference.html#example-queries">Example Queries</a></li>
<li><a href="datasets/batch_view/telemetry_aggregates/reference.html#sampling">Sampling</a>
<ul>
<li><a href="datasets/batch_view/telemetry_aggregates/reference.html#invalid-pings">Invalid Pings</a></li>
</ul>
</li>
<li><a href="datasets/batch_view/telemetry_aggregates/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/batch_view/telemetry_aggregates/reference.html#schema">Schema</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#introduction-14" id="introduction-14">Introduction</a></h1>
<p>The <code>telemetry_aggregates</code> dataset is a daily aggregation of the pings,
aggregating the histograms across a set of dimensions.</p>
<h4><a class="header" href="#rows-and-columns" id="rows-and-columns">Rows and Columns</a></h4>
<p>There's one column for each of the dimensions and the histogram and each row
is a distinct set of dimensions, along with their associated histograms.</p>
<h4><a class="header" href="#accessing-the-data-22" id="accessing-the-data-22">Accessing the Data</a></h4>
<p>This dataset is accessible via re:dash by selecting from <code>telemetry_aggregates</code>.</p>
<p>The data is stored as a parquet table in S3 at the following address.</p>
<pre><code>s3://telemetry-parquet/aggregates_poc/v1/
</code></pre>
<h1><a class="header" href="#data-reference-11" id="data-reference-11">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-6" id="example-queries-6">Example Queries</a></h2>
<p>Here's an example query that shows the number of pings received per
<code>submission_date</code> for the dimensions provided.</p>
<pre><code class="language-sql">SELECT
    submission_date,
    SUM(count) AS pings
FROM
    telemetry_aggregates
WHERE
    channel = 'nightly'
    AND metric = 'GC_MS'
    AND aggregate_type = 'build_id'
    AND period = '201901'
GROUP BY
    submission_date
ORDER BY
    submission_date
;
</code></pre>
<h2><a class="header" href="#sampling-3" id="sampling-3">Sampling</a></h2>
<h3><a class="header" href="#invalid-pings" id="invalid-pings">Invalid Pings</a></h3>
<p>We ignore invalid pings in our processing. Invalid pings are defined as those that:</p>
<ul>
<li>The submission dates are invalid or missing.</li>
<li>The build ID is malformed.</li>
<li>The <code>docType</code> field is missing or unknown.</li>
<li>The build ID is older than a defined cutoff days.
(See the <code>BUILD_ID_CUTOFFS</code> variable in the
<a href="https://github.com/mozilla/python_mozaggregator/">code</a> for the max days per channel)</li>
</ul>
<h2><a class="header" href="#scheduling-10" id="scheduling-10">Scheduling</a></h2>
<p>The <code>telemetry_aggregates</code> job is run daily, at midnight UTC.
The job is scheduled on <a href="https://github.com/mozilla/telemetry-airflow">Airflow</a>.
The DAG is <a href="https://github.com/mozilla/telemetry-airflow/blob/831fe84a36347f440ede4f5a90e0bf83d4fa1e1e/dags/mozaggregator_parquet.py">here</a></p>
<h2><a class="header" href="#schema-10" id="schema-10">Schema</a></h2>
<p>The <code>telemetry_aggregates</code> table has a set of dimensions and set of
aggregates for those dimensions.</p>
<p>The partitioned dimensions are the following columns. Filtering by one of
these fields to limit the resulting number of rows can run significantly
faster:</p>
<ul>
<li><code>metric</code> is the name of the metric, like <code>&quot;GC_MS&quot;</code>.</li>
<li><code>aggregate_type</code> is the type of aggregation, either <code>&quot;build_id&quot;</code> or
<code>&quot;submission_date&quot;</code>, representing how this aggregation was grouped.</li>
<li><code>period</code> is a string representing the month in <code>YYYYMM</code> format that a ping
was submitted, like <code>'201901'</code>.</li>
</ul>
<p>The rest of the dimensions are:</p>
<ul>
<li><code>submission_date</code> is the date pings were submitted for a particular aggregate.</li>
<li><code>channel</code> is the channel, like <code>release</code> or <code>beta</code>.</li>
<li><code>version</code> is the program version, like <code>46.0a1</code>.</li>
<li><code>build_id</code> is the <code>YYYYMMDDhhmmss</code> timestamp the program was built, like
<code>20190123192837</code>.</li>
<li><code>application</code> is the program name, like <code>Firefox</code> or <code>Fennec</code>.</li>
<li><code>architecture</code> is the architecture that the program was built for (not
necessarily the one it is running on).</li>
<li><code>os</code> is the name of the OS the program is running on, like <code>Darwin</code> or <code>Windows_NT</code>.</li>
<li><code>os_version</code> is the version of the OS the program is running on.</li>
<li><code>key</code> is the key of a keyed metric. This will be empty if the underlying
metric is not a keyed metric.</li>
<li><code>process_type</code> is the process the histogram was recorded in, like <code>content</code>
or <code>parent</code>.</li>
</ul>
<p>The aggregates are:</p>
<ul>
<li><code>count</code> is the aggregate sum of the number of pings per dimensions.</li>
<li><code>sum</code> is the aggregate sum of the histogram values per dimensions.</li>
<li><code>histogram</code> is the aggregated histogram per dimensions.</li>
</ul>
<h1><a class="header" href="#update" id="update">Update</a></h1>
<ul>
<li><a href="datasets/batch_view/update/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/batch_view/update/reference.html#contents">Contents</a></li>
<li><a href="datasets/batch_view/update/reference.html#accessing-the-data">Accessing the Data</a></li>
<li><a href="datasets/batch_view/update/reference.html#further-reading">Further Reading</a></li>
</ul>
</li>
<li><a href="datasets/batch_view/update/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/batch_view/update/reference.html#schema">Schema</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#introduction-15" id="introduction-15">Introduction</a></h1>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/update-ping.html">update ping</a>
is sent from Firefox Desktop when a browser update is ready to be applied and after it was correctly applied.
It contains the build information and the update blob information, in addition to some information about the
user environment.
The <code>telemetry_update_parquet</code> table is the most direct representation of an update ping.</p>
<h4><a class="header" href="#contents-15" id="contents-15">Contents</a></h4>
<p>The table contains one row for each ping. Each column represents one field from the update ping payload, though only a subset of all fields are included.</p>
<h4><a class="header" href="#accessing-the-data-23" id="accessing-the-data-23">Accessing the Data</a></h4>
<p>The data is stored as a parquet table in S3 at the following address.</p>
<pre><code>s3://net-mozaws-prod-us-west-2-pipeline-data/telemetry-update-parquet/v1/
</code></pre>
<p>The <code>telemetry_update_parquet</code> is accessible through re:dash.
Here's an <a href="https://sql.telemetry.mozilla.org/queries/31267#table">example query</a>.</p>
<h4><a class="header" href="#further-reading-8" id="further-reading-8">Further Reading</a></h4>
<p>This dataset is generated automatically using direct to parquet. The configuration responsible for generating this dataset was introduced in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1384861">bug 1384861</a>.</p>
<h1><a class="header" href="#data-reference-12" id="data-reference-12">Data Reference</a></h1>
<h2><a class="header" href="#schema-11" id="schema-11">Schema</a></h2>
<p>As of 2017-09-07, the current version of the <code>telemetry_update_parquet</code> dataset is <code>v1</code>, and has a schema as follows:</p>
<pre><code>root
 |-- id: string (nullable = true)
 |-- client_id: string (nullable = true)
 |-- metadata: struct (nullable = true)
 |    |-- timestamp: long (nullable = true)
 |    |-- date: string (nullable = true)
 |    |-- normalized_channel: string (nullable = true)
 |    |-- geo_country: string (nullable = true)
 |    |-- geo_city: string (nullable = true)
 |    |-- creation_timestamp: long (nullable = true)
 |    |-- x_ping_sender_version: string (nullable = true)
 |-- application: struct (nullable = true)
 |    |-- displayVersion: string (nullable = true)
 |-- environment: struct (nullable = true)
 |    |-- build: struct (nullable = true)
 |    |    |-- application_name: string (nullable = true)
 |    |    |-- architecture: string (nullable = true)
 |    |    |-- version: string (nullable = true)
 |    |    |-- build_id: string (nullable = true)
 |    |    |-- vendor: string (nullable = true)
 |    |    |-- hotfix_version: string (nullable = true)
 |    |-- partner: struct (nullable = true)
 |    |    |-- distribution_id: string (nullable = true)
 |    |    |-- distribution_version: string (nullable = true)
 |    |    |-- partner_id: string (nullable = true)
 |    |    |-- distributor: string (nullable = true)
 |    |    |-- distributor_channel: string (nullable = true)
 |    |    |-- partner_names: array (nullable = true)
 |    |    |    |-- element: string (containsNull = true)
 |    |-- settings: struct (nullable = true)
 |    |    |-- telemetry_enabled: boolean (nullable = true)
 |    |    |-- locale: string (nullable = true)
 |    |    |-- update: struct (nullable = true)
 |    |    |    |-- channel: string (nullable = true)
 |    |    |    |-- enabled: boolean (nullable = true)
 |    |    |    |-- auto_download: boolean (nullable = true)
 |    |-- system: struct (nullable = true)
 |    |    |-- os: struct (nullable = true)
 |    |    |    |-- name: string (nullable = true)
 |    |    |    |-- version: string (nullable = true)
 |    |    |    |-- locale: string (nullable = true)
 |    |-- profile: struct (nullable = true)
 |    |    |-- creation_date: long (nullable = true)
 |-- payload: struct (nullable = true)
 |    |-- reason: string (nullable = true)
 |    |-- target_channel: string (nullable = true)
 |    |-- target_version: string (nullable = true)
 |    |-- target_build_id: string (nullable = true)
 |    |-- target_display_version: string (nullable = true)
 |    |-- previous_channel: string (nullable = true)
 |    |-- previous_version: string (nullable = true)
 |    |-- previous_build_id: string (nullable = true)
 |-- submission_date_s3: string (nullable = true)
</code></pre>
<p>For more detail on the raw ping these fields come from, see the
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/update-ping.html">raw data</a>.</p>
<h1><a class="header" href="#work-in-progress" id="work-in-progress">Work in Progress</a></h1>
<p>This article is a work in progress.
The work is being tracked in
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1341812">this bug</a>.</p>
<h1><a class="header" href="#guide-to-our-experimental-tools" id="guide-to-our-experimental-tools">Guide to our Experimental Tools</a></h1>
<h2><a class="header" href="#shield" id="shield">Shield</a></h2>
<ul>
<li>Shield is an addon-based experimentation platform with fine-tuned enrollment criteria. The system add-on landed in FF 53.</li>
<li>For the moment, it sends back data in its own <code>shield</code> type ping, so there's lots of flexibility in data you can collect.</li>
<li>Uses the Normandy server to serve out study recipes (?)</li>
<li>Annotates the main ping in the environment/experiments block</li>
<li>The shield system is itself a system add-on, so rolling out changes to the entire system does not require riding release trains</li>
<li>Strategy and Insights (strategyandinsights@mozilla.com) team are product owners and shepherd the study development and release process along</li>
<li>Opt-out experiments should be available soon?</li>
<li>Further reading:
<ul>
<li>https://wiki.mozilla.org/Firefox/SHIELD</li>
<li>https://wiki.mozilla.org/Firefox/Shield/Shield_Studies</li>
<li><a href="tools/BROKEN:https://mozilla.github.io/shield-studies-docs/study-process/">https://mozilla.github.io/shield-studies-docs/study-process/</a></li>
<li>When should you use SHIELD over other options?</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#preference-flipping-experiments" id="preference-flipping-experiments">Preference Flipping experiments</a></h2>
<p>Uses Normandy, requires NO additional addon as long as a preference rides the release train</p>
<h2><a class="header" href="#heartbeat" id="heartbeat">Heartbeat</a></h2>
<p>Survey mechanism, also run via Normandy</p>
<h2><a class="header" href="#telemetry-experiments" id="telemetry-experiments">Telemetry Experiments</a></h2>
<p>Pre-release only
<a href="tools/BROKEN:https://gecko.readthedocs.io/en/latest/browser/experiments/experiments/index.html">https://gecko.readthedocs.io/en/latest/browser/experiments/experiments/index.html</a></p>
<h2><a class="header" href="#funnelcake" id="funnelcake">Funnelcake</a></h2>
<p>Custom builds of Firefox that are served to some percentage of the direct download population</p>
<h1><a class="header" href="#accessing-heartbeat-data" id="accessing-heartbeat-data">Accessing Heartbeat data</a></h1>
<p><a href="https://docs.telemetry.mozilla.org/tools/experiments.html#heartbeat">Heartbeat</a> survey studies return telemetry on user engagement with the survey prompt.
The heartbeat pings do not contain the survey responses themselves,
which are stored by SurveyGizmo.</p>
<p>The telemetry is received using the <code>heartbeat</code> document type,
which is <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/heartbeat-ping.html">described in the Firefox source tree docs</a>.</p>
<p>These pings are aggregated into the <code>telemetry_heartbeat_parquet</code> table,
and may also be accessed using the Dataset API.</p>
<h2><a class="header" href="#linking-heartbeat-responses-to-telemetry" id="linking-heartbeat-responses-to-telemetry">Linking Heartbeat responses to telemetry</a></h2>
<p>Heartbeat responses may be linked to Firefox telemetry
if there is a <code>&quot;includeTelemetryUUID&quot;: true</code> key in the <code>arguments</code> object
of the <a href="https://mozilla.github.io/normandy/user/actions/show-heartbeat.html"><code>show-heartbeat</code> recipe</a>.</p>
<p>Heartbeat never reports telemetry <code>client_id</code>s to SurveyGizmo, but,
when <code>includeTelemetryUUID</code> is true,
the Normandy <code>user_id</code> is reported to SurveyGizmo
as the <code>userid</code> URL variable.
Simultaneously, a <code>heartbeat</code> ping is sent to Mozilla,
containing both the telemetry <code>client_id</code> and the Normandy <code>userid</code> that was reported to SurveyGizmo.</p>
<p>The <code>userid</code> is reported by appending it to the <code>surveyId</code> field of the ping, like:</p>
<pre><code>hb-example-slug::e87bcae5-bb63-4829-822a-85ba41ee5d53
</code></pre>
<p>These can be extracted from the ping table for analysis using expressions like:</p>
<pre><code>SPLIT(payload.survey_id,'::')[OFFSET(1)] AS surveygizmo_userid
</code></pre>
<h2><a class="header" href="#data-reference-13" id="data-reference-13">Data reference</a></h2>
<p>Heartbeat data is available in the <code>telemetry.heartbeat</code> table in BigQuery.</p>
<p>Its structure matches the <a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/blob/8b0641ebb8aad570b79e811ae10fd81c718af48f/schemas/telemetry/heartbeat/heartbeat.4.schema.json">heartbeat ping schema</a>.</p>
<h1><a class="header" href="#analyzing-data-from-shield-studies" id="analyzing-data-from-shield-studies">Analyzing data from SHIELD studies</a></h1>
<p>This article introduces the datasets that are useful for analyzing SHIELD studies.
After reading this article,
you should understand how to answer questions about
study enrollment,
identify telemetry from clients enrolled in an experiment,
and locate telemetry from add-on studies.</p>
<h2><a class="header" href="#table-of-contents-4" id="table-of-contents-4">Table of contents</a></h2>
<ul>
<li><a href="datasets/shield.html#dashboards">Dashboards</a></li>
<li><a href="datasets/shield.html#experiment-slugs">Experiment slugs</a></li>
<li><a href="datasets/shield.html#tables">Tables</a>
<ul>
<li><a href="datasets/shield.html#experiments"><code>experiments</code></a></li>
<li><a href="datasets/shield.html#-column"> column</a></li>
<li><a href="datasets/shield.html#experiments"><code>experiments</code></a></li>
<li><a href="datasets/shield.html#events"><code>events</code></a></li>
<li><a href="datasets/shield.html#telemetryshield_study_addon"><code>telemetry.shield_study_addon</code></a></li>
<li><a href="datasets/shield.html#telemetryshield_study"><code>telemetry.shield_study</code></a></li>
</ul>
</li>
</ul>
<h2><a class="header" href="#dashboards-1" id="dashboards-1">Dashboards</a></h2>
<p>The <a href="https://strategy-and-insights.mozilla.com/shield-studies/index.html">Shield Studies Viewer</a> and <a href="https://experimenter.services.mozilla.com/">Experimenter</a> dashboards
are other places to find lists of live experiments.</p>
<h2><a class="header" href="#experiment-slugs" id="experiment-slugs">Experiment slugs</a></h2>
<p>Each experiment is associated with a slug,
which is the label used to identify the experiment to Normandy clients.
The slug is also used to identify the experiment in most telemetry.
The slug for pref-flip experiments is defined in the recipe by a field named <code>slug</code>;
the slug for add-on experiments is defined in the recipe by a field named <code>name</code>.</p>
<p>You can determine the slug for a particular experiment by consulting
<a href="https://metrics.mozilla.com/%7Esguha/report/normandy_recipes.html">this summary table</a>
or the list of active recipes at
https://normandy.cdn.mozilla.net/api/v1/recipe/signed/.</p>
<h2><a class="header" href="#tables" id="tables">Tables</a></h2>
<p>These tables are accessible from BigQuery and Databricks.</p>
<h3><a class="header" href="#experiments-column" id="experiments-column"><code>experiments</code> column</a></h3>
<p><a href="datasets/batch_view/main_summary/reference.html"><code>main_summary</code></a>,
<a href="datasets/batch_view/clients_daily/reference.html"><code>clients_daily</code></a>,
and some other tables
include a <code>experiments</code> column
which is a mapping from experiment slug to branch.</p>
<p>You can collect rows from enrolled clients using query syntax like:</p>
<pre><code class="language-sql">SELECT
  ... some fields ...,
  udf.get_key(experiments, 'some-experiment-slug-12345') AS branch
FROM
  telemetry.clients_daily
WHERE
  udf.get_key(experiments, 'some-experiment-slug-12345') IS NOT NULL
</code></pre>
<h3><a class="header" href="#experiments" id="experiments"><code>experiments</code></a></h3>
<p>The <code>experiments</code> table is a subset of rows from <code>main_summary</code>
reflecting pings from clients that are currently enrolled in an experiment.
The <code>experiments</code> table has additional string-type
<code>experiment_id</code> and <code>experiment_branch</code> columns,
and is partitioned by <code>experiment_id</code>, which makes it efficient to query.</p>
<p>Experiments deployed to large fractions of the release channel
may have the <code>isHighVolume</code> flag set in the Normandy recipe;
those experiments will not be aggregated into the <code>experiments</code> table.</p>
<p>Please note that the <code>experiments</code> table cannot be used
for calculating retention for periods extending beyond
the end of the experiment.
Once a client is unenrolled from an experiment,
subsequent pings will not be captured by the <code>experiments</code> table.</p>
<h3><a class="header" href="#events" id="events"><code>events</code></a></h3>
<p>The <a href="datasets/batch_view/events/reference.html"><code>events</code> table</a> includes
Normandy enrollment and unenrollment events
for both pref-flip and add-on studies.</p>
<p>Normandy events have event category <code>normandy</code>.
The event value will contain the experiment slug.</p>
<p>The event schema is described
<a href="https://hg.mozilla.org/mozilla-central/file/tip/toolkit/components/normandy/lib/TelemetryEvents.jsm">in the Firefox source tree</a>.</p>
<p>The <code>events</code> table is updated daily.</p>
<h3><a class="header" href="#telemetryshield_study_addon" id="telemetryshield_study_addon"><code>telemetry.shield_study_addon</code></a></h3>
<p>The <code>telemetry.shield_study_addon</code> table contains SHIELD telemetry from add-on experiments,
i.e. key-value pairs sent with the
<code>browser.study.sendTelemetry()</code> method from the
<a href="https://github.com/mozilla/shield-studies-addon-utils/">SHIELD study add-on utilities</a>
library.</p>
<p>The <code>study_name</code> attribute of the <code>payload</code> column will contain the identifier
registered with the SHIELD add-on utilities.
This is set by the add-on; sometimes it takes the value of
<code>applications.gecko.id</code> from the add-on's <code>manifest.json</code>.
This is often not the same as the Normandy slug.</p>
<p>The schema for shield-study-addon pings is described in the
<a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/tree/master/schemas/telemetry/shield-study-addon"><code>mozilla-pipeline-schemas</code> repository</a>.</p>
<p>The key-value pairs are present in <code>data</code> attribute of the <code>payload</code> column.</p>
<p>The <code>telemetry.shield_study_addon</code> table contains only full days of data.
If you need access to data with lower latency, you can use the &quot;live&quot; table
<code>telemetry_live.shield_study_addon_v4</code> which should have latency significantly
less than 1 hour.</p>
<h3><a class="header" href="#telemetryshield_study" id="telemetryshield_study"><code>telemetry.shield_study</code></a></h3>
<p>The <code>telemetry.shield_study</code> dataset includes
enrollment and unenrollment events for add-on experiments only,
sent by the <a href="https://github.com/mozilla/shield-studies-addon-utils/">SHIELD study add-on utilities</a>.</p>
<p>The <code>study_name</code> attribute of the <code>payload</code> column will contain the identifier
registered with the SHIELD add-on utilities.
This is set by the add-on; sometimes it takes the value of
<code>applications.gecko.id</code> from the add-on's <code>manifest.json</code>.
This is often not the same as the Normandy slug.</p>
<p>Normandy also emits its own enrollment and unenrollment events for these studies,
which are available in the <code>events</code> table.</p>
<p>The <code>telemetry.shield_study</code> table contains only full days of data.
If you need access to data with lower latency, you can use the &quot;live&quot; table
<code>telemetry_live.shield_study_v4</code> which should have latency significantly
less than 1 hour.</p>
<h1><a class="header" href="#search-data" id="search-data">Search Data</a></h1>
<h2><a class="header" href="#introduction-16" id="introduction-16">Introduction</a></h2>
<p>This article introduces the datasets we maintain for search analyses:
<code>search_aggregates</code> and <code>search_clients_daily</code>. After reading this article,
you should understand the search datasets well enough to produce moderately
complex analyses.</p>
<h2><a class="header" href="#table-of-contents-5" id="table-of-contents-5">Table of Contents</a></h2>
<ul>
<li><a href="datasets/search.html#permissions">Permissions</a></li>
<li><a href="datasets/search.html#terminology">Terminology</a>
<ul>
<li><a href="datasets/search.html#direct-vs-follow-on-search">Direct vs Follow-on Search</a></li>
<li><a href="datasets/search.html#tagged-vs-untagged-searches">Tagged vs Untagged Searches</a></li>
</ul>
</li>
<li><a href="datasets/search.html#standard-search-aggregates">Standard Search Aggregates</a>
<ul>
<li><a href="datasets/search.html#outlier-filtering">Outlier Filtering</a></li>
</ul>
</li>
<li><a href="datasets/search.html#in-content-telemetry-issues">In Content Telemetry Issues</a>
<ul>
<li><a href="datasets/search.html#relies-on-whitelists">Relies on whitelists</a></li>
<li><a href="datasets/search.html#limited-historical-data">Limited historical data</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#permissions" id="permissions">Permissions</a></h1>
<p>Access to both <code>search_aggregates</code> and <code>search_clients_daily</code>
is heavily restricted in re:dash.
We also maintain a restricted group for search on Github and Bugzilla.
If you reach a 404 on Github or don't have access to a re:dash query or bug
this is likely your issue.
To get access permissions, file a bug using the <a href="https://bugzilla.mozilla.org/enter_bug.cgi?assigned_to=rharter%40mozilla.com&amp;bug_file_loc=http%3A%2F%2F&amp;bug_ignored=0&amp;bug_severity=normal&amp;bug_status=NEW&amp;cf_fx_iteration=---&amp;cf_fx_points=---&amp;comment=Please%20add%20the%20following%20user%20to%20the%20Search%20group%3A%0D%0A%0D%0AMozilla%20email%20address%3A%0D%0AGithub%20handle%3A&amp;component=Datasets%3A%20Search&amp;contenttypemethod=autodetect&amp;contenttypeselection=text%2Fplain&amp;defined_groups=1&amp;flag_type-4=X&amp;flag_type-607=X&amp;flag_type-800=X&amp;flag_type-803=X&amp;flag_type-916=X&amp;form_name=enter_bug&amp;maketemplate=Remember%20values%20as%20bookmarkable%20template&amp;op_sys=Linux&amp;priority=--&amp;product=Data%20Platform%20and%20Tools&amp;rep_platform=x86_64&amp;short_desc=Add%20user%20to%20search%20user%20groups&amp;target_milestone=---&amp;version=unspecified">search permissions template</a></p>
<p>Once you have proper permissions,
you'll have access to a new source in re:dash called <code>Telemetry Search (BigQuery)</code>.
<strong>You will not be able to access any of the search datasets
via the standard <code>Telemetry (BigQuery)</code> data source</strong>, even with proper permissions.</p>
<h1><a class="header" href="#terminology-1" id="terminology-1">Terminology</a></h1>
<h2><a class="header" href="#direct-vs-follow-on-search" id="direct-vs-follow-on-search">Direct vs Follow-on Search</a></h2>
<p>Searches can be split into three major classes: <em>sap</em>, <em>follow-on</em>, and <em>organic</em>.</p>
<p>SAP searches result from a direct interaction with a <code>search access point</code> (SAP),
which is part of the Firefox UI.
These searches are often called SAP searches.
There are currently 7 SAPs:</p>
<ul>
<li><code>urlbar</code> - entering a search query in the Awesomebar</li>
<li><code>searchbar</code> - the main search bar; not present by default for new profiles on Firefox 57+</li>
<li><code>newtab</code> - the search bar on the <code>about:newtab</code> page</li>
<li><code>abouthome</code> - the search bar on the <code>about:home</code> page</li>
<li><code>contextmenu</code> - selecting text and clicking &quot;Search&quot; from the context menu</li>
<li><code>system</code> - starting Firefox from the command line with an option that immediately makes a search</li>
<li><code>webextension</code> - initiated from a web extension (<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1492233">added</a> as of Firefox 63)</li>
<li><code>alias</code> - initiated from a search keyword (like @google) (<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1499193">added</a> as of Firefox 64)</li>
</ul>
<p>Users will often interact with the Search Engine Results Page (SERP)
to create &quot;downstream&quot; queries.
These queries are called <code>follow-on queries</code>.
These are sometimes also referred to as <strong>in-content queries</strong>
since they are initiated from the content of the page itself
and not from the Firefox UI.</p>
<p>For example, follow-on queries can be caused by:</p>
<ul>
<li>Revising a query (<code>restaurants</code> becomes <code>restaurants near me</code>)</li>
<li>Clicking on the &quot;next&quot; button</li>
<li>Accepting spelling suggestions</li>
</ul>
<p>Finally, we track the number of <em>organic</em> searches. These would be searches initiated directly
from a search engine provider, not through a search access point.</p>
<h2><a class="header" href="#tagged-vs-untagged-searches" id="tagged-vs-untagged-searches">Tagged vs Untagged Searches</a></h2>
<p>Our partners (search engines) attribute queries to Mozilla using <strong>partner codes</strong>.
When a user issues a query through one of our SAPs,
we include our partner code in the URL of the resulting search.</p>
<p><strong>Tagged queries</strong> are queries that <strong>include one of our partner codes</strong>.</p>
<p><strong>Untagged queries</strong> are queries that <strong>do not include one of our partner codes</strong>.
If a query is untagged,
it's usually because we do not have a partner deal for that search engine and region
(or it is an organic search that did not start from an SAP).</p>
<p>If an SAP query is tagged, any follow-on query should also be tagged.</p>
<h1><a class="header" href="#standard-search-aggregates" id="standard-search-aggregates">Standard Search Aggregates</a></h1>
<p>We report five types of searches in our search datasets:
<code>sap</code>, <code>tagged-sap</code>, <code>tagged-follow-on</code>, <code>organic</code>, and <code>unknown</code>.
These aggregates show up as columns in the
<code>search_aggregates</code> and <code>search_clients_daily</code> datasets.
Our search datasets are all derived from <code>main_summary</code>.
The aggregate columns are derived from the <code>SEARCH_COUNTS</code> histogram.</p>
<p>The <strong><code>sap</code> column counts all SAP (or direct) searches</strong>.
<code>sap</code> search counts are collected via
<a href="https://firefox-source-docs.mozilla.org/browser/browser/BrowserUsageTelemetry.html#search-telemetry">probes</a>
within the Firefox UI
These counts are <strong>very reliable, but do not count follow-on queries</strong>.</p>
<p>In 2017-06 we deployed the <a href="https://github.com/mozilla/followonsearch"><code>followonsearch</code> addon</a>, which adds probes for <code>tagged-sap</code> and <code>tagged-follow-on</code> searches.
These columns <strong>attempt to count all tagged searches</strong>
by looking for Mozilla partner codes in the URL of requests to partner search engines.
These search counts are critical to understanding revenue
since they exclude untagged searches and include follow-on searches.
However, these search counts have <strong>important caveats affecting their reliability</strong>.
See <a href="datasets/search.html#in-content-telemetry-issues">In Content Telemetry Issues</a> for more information.</p>
<p>In 2018, we
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1475571">incorporated</a> this code
into the product (as of version 61) and also started tracking so-called
&quot;organic&quot; searches that weren't initiated through a search access point (sap).
This data has the same caveats as those for follow on searches, above.</p>
<p>We also started tracking &quot;unknown&quot; searches, which generally correspond
to clients submitting random/unknown search data to our servers as part
of their telemetry payload. This category can generally safely be ignored, unless its value
is extremely high (which indicates a bug in either Firefox or the aggregation code
which creates our datasets).</p>
<p>In <code>main_summary</code>, all of these searches are stored in <code>search_counts.count</code>,
<strong>which makes it easy to over count searches</strong>.
However, in general, please avoid using <code>main_summary</code> for search analyses --
it's slow and you will need to duplicate much of the work done to make
analyses of our search datasets tractable.</p>
<h2><a class="header" href="#outlier-filtering" id="outlier-filtering">Outlier Filtering</a></h2>
<p>We remove search count observations representing more than
10,000 searches for a single search engine in a single ping.</p>
<h1><a class="header" href="#in-content-telemetry-issues" id="in-content-telemetry-issues">In Content Telemetry Issues</a></h1>
<p>The search code module inside Firefox (formerly implemented
as an addon until version 60) implements the probe used to measure <code>tagged-sap</code> and
<code>tagged-follow-on</code> searches and also tracks organic searches. This probe is critical
to understanding our revenue. It's the only tool that gives us a view of follow-on searches
and differentiates between tagged and untagged queries.
However, it comes with some notable caveats.</p>
<h2><a class="header" href="#relies-on-whitelists" id="relies-on-whitelists">Relies on whitelists</a></h2>
<p>Firefox's search module attempts to count all tagged searches
by looking for Mozilla partner codes in the URL of requests to partner search engines.
To do this, it relies on a whitelist of partner codes and URL formats.
The list of partner codes is incomplete and only covers a few top partners.
These codes also occasionally change so there will be gaps in the data.</p>
<p>Additionally, changes to search engine URL formats can cause problems with our data collection.
See
<a href="https://sql.telemetry.mozilla.org/queries/47631/source#128887">this query</a>
for a notable example.</p>
<h2><a class="header" href="#limited-historical-data" id="limited-historical-data">Limited historical data</a></h2>
<p>The <a href="https://github.com/mozilla/followonsearch"><code>followonsearch</code> addon</a> was first deployed in 2017-06.
There is no <code>tagged-*</code> search data available before this.</p>
<h1><a class="header" href="#search-aggregates" id="search-aggregates">Search Aggregates</a></h1>
<ul>
<li><a href="datasets/mozetl/search_aggregates/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/mozetl/search_aggregates/reference.html#contents">Contents</a></li>
<li><a href="datasets/mozetl/search_aggregates/reference.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="datasets/mozetl/search_aggregates/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/mozetl/search_aggregates/reference.html#example-queries">Example Queries</a></li>
<li><a href="datasets/mozetl/search_aggregates/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/mozetl/search_aggregates/reference.html#schema">Schema</a></li>
</ul>
</li>
<li><a href="datasets/mozetl/search_aggregates/reference.html#code-reference">Code Reference</a></li>
</ul>
<h1><a class="header" href="#introduction-17" id="introduction-17">Introduction</a></h1>
<p><code>search_aggregates</code> is designed to power high level search dashboards.
It's quick and easy to query, but the data are coarse.
In particular, this dataset allows you to segment
by a limited number of client characteristics which are relevant to search markets.
However, it is not possible to normalize by client count.
If you need fine-grained data, consider using <code>search_clients_daily</code>
which breaks down search counts by client</p>
<h4><a class="header" href="#contents-16" id="contents-16">Contents</a></h4>
<p>Each row of <code>search_aggregates</code> contains
the standard search count aggregations
for each unique combination of the following columns.
Unless otherwise noted, these columns are taken directly from <code>main_summary</code>.</p>
<ul>
<li><code>submission_date</code> - <code>yyyymmdd</code></li>
<li><code>engine</code> - e.g. <code>google</code>, <code>bing</code>, <code>yahoo</code></li>
<li><code>source</code> - The UI component used to issue a search - e.g. <code>urlbar</code>, <code>abouthome</code></li>
<li><code>country</code></li>
<li><code>locale</code></li>
<li><code>addon_version</code> - The installed version of the [<code>followonsearch</code> addon] (before version 61)</li>
<li><code>app_version</code></li>
<li><code>distribution_id</code> - <code>NULL</code> means the standard Firefox build</li>
<li><code>search_cohort</code> - <code>NULL</code> except for small segments relating to search experimentation</li>
</ul>
<p>There are five aggregation columns:
<code>sap</code>, <code>tagged-sap</code>, and <code>tagged-follow-on</code>, <code>organic</code> and <code>unknown</code>.
Each of these columns represent different types of searches.
For more details, see the <a href="datasets/mozetl/search_aggregates/../../search.html">search data documentation</a>
Note that, if there were no such searches in a row's segment
(i.e. the count would be 0),
the column value is <code>null</code>.</p>
<!--
#### Background and Caveats
-->
<h4><a class="header" href="#accessing-the-data-24" id="accessing-the-data-24">Accessing the Data</a></h4>
<p>Access to <code>search_aggregates</code> is heavily restricted.
You will not be able to access this table without additional permissions.
For more details see the <a href="datasets/mozetl/search_aggregates/../../search.html">search data documentation</a>.</p>
<!--
#### Further Reading
-->
<h1><a class="header" href="#data-reference-14" id="data-reference-14">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-7" id="example-queries-7">Example Queries</a></h2>
<p><a href="https://sql.telemetry.mozilla.org/queries/51140/source">This query</a>
calculates daily US searches.
If you have trouble viewing this query,
it's likely you don't have the proper permissions.
For more details see the <a href="datasets/mozetl/search_aggregates/../../search.html">search data documentation</a>.</p>
<h2><a class="header" href="#scheduling-11" id="scheduling-11">Scheduling</a></h2>
<p>This job is
<a href="https://github.com/mozilla/telemetry-airflow/blob/master/dags/main_summary.py#L135">scheduled on airflow</a>
to run daily.</p>
<h2><a class="header" href="#schema-12" id="schema-12">Schema</a></h2>
<p>As of 2018-11-28,
the current version of <code>search_aggregates</code> is <code>v4</code>,
and has a schema as follows.
The dataset is backfilled through 2016-06-06</p>
<pre><code>root
 |-- country: string (nullable = true)
 |-- engine: string (nullable = true)
 |-- source: string (nullable = true)
 |-- submission_date: string (nullable = true)
 |-- app_version: string (nullable = true)
 |-- distribution_id: string (nullable = true)
 |-- locale: string (nullable = true)
 |-- search_cohort: string (nullable = true)
 |-- addon_version: string (nullable = true)
 |-- tagged-sap: long (nullable = true)
 |-- tagged-follow-on: long (nullable = true)
 |-- sap: long (nullable = true)
 |-- organic: long (nullable = true)
 |-- unknown: long (nullable = true)
</code></pre>
<h1><a class="header" href="#code-reference-5" id="code-reference-5">Code Reference</a></h1>
<p>The <code>search_aggregates</code> job is
<a href="https://github.com/mozilla/python_mozetl/blob/master/mozetl/search/aggregates.py">defined in <code>python_mozetl</code></a></p>
<h1><a class="header" href="#search-clients-daily" id="search-clients-daily">Search Clients Daily</a></h1>
<ul>
<li><a href="datasets/mozetl/search_clients_daily/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/mozetl/search_clients_daily/reference.html#contents">Contents</a></li>
<li><a href="datasets/mozetl/search_clients_daily/reference.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="datasets/mozetl/search_clients_daily/reference.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="datasets/mozetl/search_clients_daily/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/mozetl/search_clients_daily/reference.html#example-queries">Example Queries</a></li>
<li><a href="datasets/mozetl/search_clients_daily/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/mozetl/search_clients_daily/reference.html#schema">Schema</a></li>
</ul>
</li>
<li><a href="datasets/mozetl/search_clients_daily/reference.html#code-reference">Code Reference</a></li>
</ul>
<h1><a class="header" href="#introduction-18" id="introduction-18">Introduction</a></h1>
<p><code>search_clients_daily</code> is designed to enable client-level search analyses.
Querying this dataset can be slow;
consider using <code>search_aggregates</code> for coarse analyses.</p>
<h4><a class="header" href="#contents-17" id="contents-17">Contents</a></h4>
<p><code>search_clients_daily</code> has one row for each unique combination of:
(<code>client_id</code>, <code>submission_date</code>, <code>engine</code>, <code>source</code>).</p>
<p>In addition to the standard search count aggregations,
this dataset includes some descriptive data for each client.
For example, we include <code>country</code> and <code>channel</code> for each row of data.
In the event that a client sends multiple pings on a given <code>submission_date</code>
we choose an arbitrary value from the pings for that (<code>client_id</code>, <code>submission_date</code>),
unless otherwise noted.</p>
<p>There are five standard search count aggregation columns:
<code>sap</code>, <code>tagged-sap</code>, and <code>tagged-follow-on</code>, <code>organic</code> and <code>unknown</code>.
Note that, if there were no such searches in a row's segment
(i.e. the count would be 0),
the column value is <code>null</code>.
Each of these columns represent different types of searches.
For more details, see the <a href="datasets/mozetl/search_clients_daily/../../search.html">search data documentation</a></p>
<h4><a class="header" href="#background-and-caveats-11" id="background-and-caveats-11">Background and Caveats</a></h4>
<p><code>search_clients_daily</code> does not include
(<code>client_id</code> <code>submission_date</code>) pairs
if we did not receive a ping for that <code>submission_date</code>.</p>
<p>We impute a <code>NULL</code> <code>engine</code> and <code>source</code> for pings with no search counts.
This ensures users who never search are included in this dataset.</p>
<p>This dataset is large.
Consider using an <a href="datasets/mozetl/search_clients_daily/../../../tools/spark.html">Databricks</a> for heavy analyses.
If these datasets do not suffice, consider using Spark on <a href="https://dbc-caf9527b-e073.cloud.databricks.com">Databricks</a>.
If you're querying this dataset from re:dash,
heavily limit the data you read using <code>submission_date_s3</code> or <code>sample_id</code>.</p>
<h4><a class="header" href="#accessing-the-data-25" id="accessing-the-data-25">Accessing the Data</a></h4>
<p>Access to <code>search_clients_daily</code> is heavily restricted.
You will not be able to access this table without additional permissions.
For more details see the <a href="datasets/mozetl/search_clients_daily/../../search.html">search data documentation</a>.</p>
<!--
#### Further Reading
-->
<h1><a class="header" href="#data-reference-15" id="data-reference-15">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-8" id="example-queries-8">Example Queries</a></h2>
<p><a href="https://sql.telemetry.mozilla.org/queries/51141/source">This query</a>
calculates searches per <code>normalized_channel</code> for US clients on an arbitrary day.
If you have trouble viewing this query,
it's likely you don't have the proper permissions.
For more details see the <a href="datasets/mozetl/search_clients_daily/../../search.html">search data documentation</a>.</p>
<h2><a class="header" href="#scheduling-12" id="scheduling-12">Scheduling</a></h2>
<p>This dataset is scheduled on Airflow
(<a href="https://github.com/mozilla/telemetry-airflow/blob/master/dags/main_summary.py#L164">source</a>).</p>
<h2><a class="header" href="#schema-13" id="schema-13">Schema</a></h2>
<p>As of 2018-11-28, the current version of <code>search_clients_daily</code> is <code>v4</code>,
and has a schema as follows.
It's backfilled through 2016-06-07</p>
<pre><code>root
 |-- client_id: string (nullable = true)
 |-- submission_date: string (nullable = true)
 |-- engine: string (nullable = true)
 |-- source: string (nullable = true)
 |-- country: string (nullable = true)
 |-- app_version: string (nullable = true)
 |-- distribution_id: string (nullable = true)
 |-- locale: string (nullable = true)
 |-- search_cohort: string (nullable = true)
 |-- addon_version: string (nullable = true)
 |-- os: string (nullable = true)
 |-- channel: string (nullable = true)
 |-- profile_creation_date: long (nullable = true)
 |-- default_search_engine: string (nullable = true)
 |-- default_search_engine_data_load_path: string (nullable = true)
 |-- default_search_engine_data_submission_url: string (nullable = true)
 |-- sample_id: string (nullable = true)
 |-- sessions_started_on_this_day: long (nullable = true)
 |-- profile_age_in_days: integer (nullable = true)
 |-- subsession_hours_sum: double (nullable = true)
 |-- active_addons_count_mean: double (nullable = true)
 |-- max_concurrent_tab_count_max: integer (nullable = true)
 |-- tab_open_event_count_sum: long (nullable = true)
 |-- active_hours_sum: double (nullable = true)
 |-- tagged-sap: long (nullable = true)
 |-- tagged-follow-on: long (nullable = true)
 |-- sap: long (nullable = true)
 |-- tagged_sap: long (nullable = true)
 |-- tagged_follow_on: long (nullable = true)
 |-- organic: long (nullable = true)
 |-- unknown: long (nullable = true)
 |-- submission_date_s3: string (nullable = true)
</code></pre>
<h1><a class="header" href="#code-reference-6" id="code-reference-6">Code Reference</a></h1>
<p>The <code>search_clients_daily</code> job is
<a href="https://github.com/mozilla/python_mozetl/blob/master/mozetl/search/aggregates.py">defined in <code>python_mozetl</code></a></p>
<h1><a class="header" href="#other-datasets-1" id="other-datasets-1">Other Datasets</a></h1>
<p>These datasets are for projects outside of the Firefox telemetry domain.</p>
<h1><a class="header" href="#hgpush" id="hgpush">hgpush</a></h1>
<p>This dataset records facts about individual commits to the Firefox source tree 
in the <a href="https://hg.mozilla.org/mozilla-central/"><code>mozilla-central</code></a> source
code repository.</p>
<h1><a class="header" href="#data-reference-16" id="data-reference-16">Data Reference</a></h1>
<p>The dataset is accessible via <a href="https://sql.telemetry.mozilla.org"><code>STMO</code></a>.
Use the <code>eng_workflow_hgpush_parquet_v1</code> table with the <code>Athena</code> data source.
(The <code>Presto</code> data source is also available, but much slower.)</p>
<h2><a class="header" href="#field-types-and-descriptions" id="field-types-and-descriptions">Field Types and Descriptions</a></h2>
<p>See the <a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/blob/dev/schemas/eng-workflow/hgpush/hgpush.1.schema.json"><code>hgpush</code> ping schema</a>
for a description of available fields.</p>
<p>Be careful to:</p>
<ul>
<li>Use the latest schema version.  e.g. <code>v1</code>.  Browse the <a href="https://github.com/mozilla-services/mozilla-pipeline-schemas/tree/dev/schemas/eng-workflow/hgpush"><code>hgpush</code> schema directory</a> in the GitHub repo to be sure.</li>
<li>Change dataset field names from <code>camelCaseNames</code> to <code>under_score_names</code> in STMO. e.g. <code>reviewSystemUsed</code> in the ping schema becomes <code>review_system_used</code> in STMO.</li>
</ul>
<h2><a class="header" href="#example-queries-9" id="example-queries-9">Example Queries</a></h2>
<p>Select the number of commits with an 'unknown' review system in the last 7 days:</p>
<pre><code class="language-sql">select
    count(1)
from
    eng_workflow_hgpush_parquet_v1
where
    review_system_used = 'unknown'
    and date_diff('day', from_unixtime(push_date), now()) &lt; 7
</code></pre>
<h1><a class="header" href="#code-reference-7" id="code-reference-7">Code Reference</a></h1>
<p>The dataset is populated via the <a href="https://github.com/mozilla-conduit/commit-telemetry-service">Commit Telemetry Service</a>.</p>
<h1><a class="header" href="#what-is-the-stub-installer-ping" id="what-is-the-stub-installer-ping">What is the Stub Installer ping?</a></h1>
<p>When the stub installer completes with almost any result, it generates a ping containing some data about the system and about how the installation went. This ping isn't part of Firefox unified telemetry, it's a bespoke system; we can't use the telemetry client code when it isn't installed yet.</p>
<p>No ping is sent if the installer exits early because initial system requirements checks fail.</p>
<h2><a class="header" href="#how-its-processed" id="how-its-processed">How its processed</a></h2>
<p>They are formed and sent from NSIS code (!) in the stub installer, in the <a href="https://searchfox.org/mozilla-central/source/browser/installer/windows/nsis/stub.nsi">SendPing subroutine</a>. </p>
<p>They are processed into Redshift by <a href="https://github.com/whd/dsmo_load"><code>dsmo_load</code></a>.</p>
<h2><a class="header" href="#how-to-access-the-data" id="how-to-access-the-data">How to access the data</a></h2>
<p>The Redshift tables are accessible from the <code>DSMO-RS</code> data source in <a href="https://sql.telemetry.mozilla.org/">STMO</a>. </p>
<p>The canonical documentation is in <a href="https://searchfox.org/mozilla-central/source/browser/installer/windows/docs/StubPing.rst">this tree</a>.</p>
<p>There are three tables produced every day (you can see them in Redshift as <code>{tablename}_YYYYMMDD</code>:</p>
<ul>
<li><code>download_stats_YYYYMMDD</code> (<a href="https://github.com/whd/dsmo_load/blob/master/hindsight/hs_run/output/dsmo_redshift.lua">source</a>)</li>
<li><code>download_stats_funnelcake_YYYYMMDD</code> (<a href="https://github.com/whd/dsmo_load/blob/master/hindsight/hs_run/output/dsmo_funnelcake_redshift.lua">source</a>)</li>
<li><code>download_stats_errors_YYYYMMDD</code> (<a href="https://github.com/whd/dsmo_load/blob/master/hindsight/hs_run/output/dsmo_errors_redshift.lua">source</a>)</li>
</ul>
<p>The funnelcake tables aggregate funnelcake builds, which have additional metadata for tracking distribution experiments. <a href="https://wiki.mozilla.org/Funnelcake">More on Funnelcake</a>.</p>
<p><code>download_stats</code> (without the date appended) and <code>download_stats_year</code> are views that union all (or a year's worth) of the per-day tables together, which makes e.g. <code>SELECT * LIMIT 10</code> operations on them quite slow.</p>
<p>Note about <code>os_version</code>: Previous versions of Windows have used a very small set of build numbers through their entire life cycle. However, Windows 10 gets a new build number with every major update (about every 6 months), and many more builds have been released on its insider channels. So, to prevent a huge amount of noise, queries using this field should generally filter out the build number and only use the major and minor version numbers to differentiate Windows versions, unless the build number is specifically needed.</p>
<h1><a class="header" href="#what-is-activity-stream" id="what-is-activity-stream">What is Activity Stream?</a></h1>
<p>Activity Stream is the Firefox module which manages the in product content pages for Firefox: </p>
<ul>
<li><code>about:home</code></li>
<li><code>about:newtab</code></li>
<li><code>about:welcome</code>
<ul>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1448918">starting with Firefox 62</a></li>
</ul>
</li>
</ul>
<p>The Activity Stream team has implemented data collection in and around these pages. This data has some overlap with the standard Firefox Telemetry system, however it is a custom system, designed and maintained by that team. </p>
<p>For specific questions about this data, reach out to the <code>#fx-messaging-system</code> Slack channel directly. </p>
<h2><a class="header" href="#activity-stream-pings" id="activity-stream-pings">Activity Stream Pings</a></h2>
<p>This data is measured in various custom pings that are sent via <a href="https://github.com/mozilla/ping-centre">PingCentre</a> (different from <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/internals/pingsender.html">Pingsender</a>). </p>
<ul>
<li><a href="https://github.com/mozilla/activity-stream/blob/master/docs/v2-system-addon/data_events.md">Activity Stream Pings: <code>data_events.md</code></a></li>
<li><a href="https://github.com/mozilla/activity-stream/blob/master/docs/v2-system-addon/data_dictionary.md">Activity Stream Pings: <code>data_dictionary.md</code></a></li>
<li><a href="https://firefox-source-docs.mozilla.org/browser/components/newtab/docs/v2-system-addon/data_dictionary.html">Activity Stream Pings: Firefox Source Tree Documentation</a></li>
</ul>
<h2><a class="header" href="#accessing-activity-stream-data" id="accessing-activity-stream-data">Accessing Activity Stream Data</a></h2>
<p>The various Activity Stream pings are stored in tables stored in the <code>Tiles</code> Redshift database, maintained by the Activity Stream team. </p>
<p>This database can be accessed via <a href="https://sql.telemetry.mozilla.org/">re:dash</a>, or in Databricks via a <a href="https://dbc-caf9527b-e073.cloud.databricks.com/#notebook/155100/command/155102">workaround provided by the Data Operations team</a>, tracked in this <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1272388#c16">bug</a>. </p>
<h2><a class="header" href="#gotchas-and-caveats" id="gotchas-and-caveats">Gotchas and Caveats</a></h2>
<p>Since this data collection isn't collected or maintained through our standard Telemetry API, there are a number of &quot;gotchas&quot; to keep in mind when working on this data. </p>
<ul>
<li>
<p><strong>Ping send conditions</strong>: Activity Stream pings have different send conditions, both from Telemetry pings as well as from each other. <a href="https://github.com/mozilla/activity-stream/blob/master/docs/v2-system-addon/data_events.md#health-ping">AS Health Pings</a>, for example, get sent by all profiles with Telemetry enabled, upon startup of each Firefox session. In contrast, <a href="https://github.com/mozilla/activity-stream/blob/master/docs/v2-system-addon/data_events.md#session-end-pings">AS Session Pings</a> only get sent by profiles that entered an Activity Stream session, at the end of that session, regardless of how long that session is. Compare this to <code>main</code> pings, which get sent by all Telemetry enabled profiles upon subsession end (browser shutdown, environment change, or local midnight cutoff). </p>
<p>Due to these inconsistencies, using data from different sources can be tricky. For example, if we wanted to know how much of DAU (from <code>main</code> pings) had a custom <code>about:home</code> page (available in AS Health Pings), joining on <code>client_id</code> and a date field would only provide information on profiles that started the session on that same day (active profiles on multi-day sessions would be excluded). </p>
</li>
<li>
<p><strong>Population covered</strong>: In addition to the usual considerations when looking at a measurement (in what version of Firefox did this measurement start getting collected? In what channels is it enabled in? etc.), when working with this data, there are additional Activity Stream specific conditions to consider when deciding &quot;who is eligible to send this ping?&quot;</p>
<p>For example, Pocket recommendations are only enabled in the US, CA, and DE countries, for profiles that are on en-US, en-CA, and DE locales. Furthermore, users can set their <code>about:home</code> and <code>about:newtab</code> page to non-Activity Stream pages. This information can be important when deciding denominators for certain metrics. </p>
</li>
<li>
<p><strong>Different ping types in the same table</strong>: The tables in the <code>Tiles</code> database can contain multiple types of pings. For example, the <code>assa_events_daily</code> table contains both <a href="https://github.com/mozilla/activity-stream/blob/master/docs/v2-system-addon/data_events.md#page-takeover-ping">AS Page Takeover pings</a> as well as <a href="https://github.com/mozilla/activity-stream/blob/master/docs/v2-system-addon/data_events.md#user-event-pings">AS User Event pings</a>. </p>
</li>
<li>
<p><strong>Inconsistent fields</strong>: In some tables, the same field can have different meanings for different records. </p>
<p>For example, in the <code>assa_router_events_daily</code> table, the <code>impression_id</code> field corresponds to the standard Telemetry <code>client_id</code> field for <a href="https://github.com/mozilla/activity-stream/blob/master/docs/v2-system-addon/data_events.md#snippets-impression">Snippets impressions</a>, <a href="https://github.com/mozilla/activity-stream/blob/master/docs/v2-system-addon/data_events.md#cfr-impression-for-all-the-prerelease-channels-and-shield-experiment">CFR impressions for pre-release and shield experiments</a>, and <a href="https://github.com/mozilla/activity-stream/blob/master/docs/v2-system-addon/data_events.md#onboarding-impression">onboarding impressions</a>. However, for <a href="https://github.com/mozilla/activity-stream/blob/master/docs/v2-system-addon/data_events.md#cfr-impression-for-the-release-channel">CFR impressions for release</a>, this field is a separate, impression identifier. </p>
</li>
<li>
<p><strong>Passing Experiment Tags</strong>: If a profile is enrolled in a Normandy experiment, the experiment slug for that profile is only passed to the Activity Stream data if it contains the string &quot;activity-stream&quot;. </p>
<p>In other words, Activity Stream will not tag data as belonging to an experiment if it is missing &quot;activity-stream&quot; in the slug, even if it is indeed enrolled in an experiment. </p>
</li>
<li>
<p><strong>Data field formats</strong>: The format for some of the data that is shared with standard Telemetry can differ. </p>
<p>For example, experiment slugs in standard Telemetry is formatted as an array of maps (one for each experiment the profile is enrolled in) </p>
<p><code>[{'experiment1_name':'branch_name'}, {'experiment2_name':'branch_name'}]</code></p>
<p>However, in the Activity Stream telemetry, experiment slugs are reported in a string, using <code>;</code> as a separater between experiments and <code>:</code> as a separator between experiment name and branch name. </p>
<p><code>'experiment1_name:branch_name;experiment2_name:branch_name'</code></p>
</li>
<li>
<p><strong>Null handling</strong>: Some fields in the Activity Stream data encode nulls with a <code>'N/A'</code> string or a <code>-1</code> value. </p>
</li>
<li>
<p><strong>Changes in ping behaviors</strong>: These pings continue to undergo development and the behavior as well as possible values for a given ping seem to change over time. For example, older versions of the event pings for clicking on a Topsite do not seem to report <code>card_types</code> and <code>icon_types</code>, while newer versions do. Caution is advised. </p>
</li>
<li>
<p><strong>Pocket data</strong>: Data related to Pocket interaction and usage in the <code>about:home</code> and <code>about:newtab</code> pages get sent to Pocket via this data collection and pipeline. However, due to privacy reasons, that data is sanitized and <code>client_id</code> is randomized. So while it is possible to ask, &quot;how many Topsites and Highlights did a given profile click on in a given day?&quot;, we cannot answer that question for Pocket tiles. </p>
</li>
</ul>
<h2><a class="header" href="#examples" id="examples">Examples</a></h2>
<h4><a class="header" href="#sessions-per-client_id" id="sessions-per-client_id">Sessions per <code>client_id</code></a></h4>
<p>Note: only includes <code>client_ids</code> that completed an Activity Stream session that day. </p>
<pre><code>SELECT
	client_id, 
	date, 
	count(DISTINCT session_id) as num_sessions
FROM
	assa_sessions_daily_by_client_id
WHERE
	date = '20190601' 
GROUP BY 
	1
</code></pre>
<h4><a class="header" href="#topsite-clicks-and-highlights-clicks" id="topsite-clicks-and-highlights-clicks">Topsite clicks and Highlights clicks</a></h4>
<pre><code>SELECT
	client_id, 
	date, 
	session_id,
	page, 
	source, 
	action_position, 
	shield_id
FROM
	assa_events_daily
WHERE
	source in ('TOP_SITES', 'HIGHLIGHTS')
	AND event = 'CLICK'
	AND date = '20190601' 
</code></pre>
<h4><a class="header" href="#snippet-impressions-blocks-clicks-and-dismissals" id="snippet-impressions-blocks-clicks-and-dismissals">Snippet impressions, blocks, clicks, and dismissals</a></h4>
<p>Note: Which snippet message a record corresponds to can be identified by the <code>message_id</code> (check with Marketing for snippet recipes published). </p>
<pre><code>SELECT 
    impression_id AS client_id, 
    date, 
    source,
    event,
    message_id, 
    value,
    shield_id
FROM 
	assa_router_events_daily
WHERE 
	source = 'snippets_user_event'
  	AND date = '20190601'
</code></pre>
<h1><a class="header" href="#obsolete-datasets-1" id="obsolete-datasets-1">Obsolete Datasets</a></h1>
<p>These datasets are no longer updated or maintained. Please reach out to the Data Platform team
if you think your needs are best met by an obsolete dataset.</p>
<h1><a class="header" href="#churn-1" id="churn-1">Churn</a></h1>
<p><em><strong>As of 2019-08-21, this dataset has been deprecated and is no longer
maintained. See <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1561048">Bug
1561048</a> for historical
sources. See the <a href="datasets/obsolete/churn/../../../cookbooks/retention.html">retention cookbook</a> for
current best practices.</strong></em></p>
<ul>
<li><a href="datasets/obsolete/churn/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/obsolete/churn/reference.html#content">Content</a></li>
<li><a href="datasets/obsolete/churn/reference.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="datasets/obsolete/churn/reference.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/churn/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/obsolete/churn/reference.html#example-queries">Example Queries</a></li>
<li><a href="datasets/obsolete/churn/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/obsolete/churn/reference.html#schema">Schema</a></li>
<li><a href="datasets/obsolete/churn/reference.html#code-reference">Code Reference</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#introduction-19" id="introduction-19">Introduction</a></h1>
<p>The churn dataset tracks the 7-day churn rate of telemetry profiles. This
dataset is generally used for analyzing cohort churn across segments and time.</p>
<h4><a class="header" href="#content-5" id="content-5">Content</a></h4>
<p>Churn is the rate of attrition defined by <code>(clients seen in week N)/(clients seen in week 0)</code>
for groups of clients with some shared attributes. A group of clients with
shared attributes is called a <em>cohort</em>. The cohorts in this dataset are created
every week and can be tracked over time using the <code>acquisition_date</code> and the
weeks since acquisition or <code>current_week</code>.</p>
<p>The following example demonstrates the current logic for generating this
dataset. Each column represents the days since some arbitrary starting date.</p>
<table><thead><tr><th>client</th><th>00</th><th>01</th><th>02</th><th>03</th><th>04</th><th>05</th><th>06</th><th>07</th><th>08</th><th>09</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th></tr></thead><tbody>
<tr><td>A</td><td>X</td><td></td><td></td><td></td><td></td><td></td><td></td><td>X</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td>B</td><td></td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td><td>X</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td>C</td><td>X</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>X</td></tr>
</tbody></table>
<p>All three clients are part of the same cohort. Client A is retained for weeks 0
and 1 since there is activity in both periods. A client only needs to show up
once in the period to be counted as retained. Client B is acquired in week 0 and
is active frequently but does not appear in following weeks. Client B is
considered churned on week 1. However, a client that is churned can become
retained again. Client C is considered churned on week 1 but retained on week 2.</p>
<p>The following table summarizes the above daily activity into the following view
where every column represents the current week since acquisition date..</p>
<table><thead><tr><th>client</th><th>0</th><th>1</th><th>2</th></tr></thead><tbody>
<tr><td>A</td><td>X</td><td>X</td><td></td></tr>
<tr><td>B</td><td>X</td><td></td><td></td></tr>
<tr><td>C</td><td>X</td><td></td><td>X</td></tr>
</tbody></table>
<p>The clients are then grouped into cohorts by attributes. An attribute describes
a property about the cohort such as the country of origin or the binary
distribution channel. Each group also contains descriptive aggregates of
engagement. Each metric describes the activity of a cohort such as size and
overall usage at a given time instance.</p>
<h4><a class="header" href="#background-and-caveats-12" id="background-and-caveats-12">Background and Caveats</a></h4>
<p>The original concept for churn is captured in <a href="https://mana.mozilla.org/wiki/display/FIREFOX/Project%3A+Firefox+Churn+v1.0">this Mana
page</a>.
The original derived data-set was created in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1198537">bug
1198537</a>.  The first
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1389230">major revision (<code>v2</code>)</a> of
this data-set added attribution, search, and uri counts.  The second <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1389231">major
revision (<code>v3</code>)</a> included
additional clients through the <code>new-profile</code> ping and adjusted the collection
window from 10 to 5 days.</p>
<ul>
<li>Each row in this dataset describes a unique segment of users
<ul>
<li>The number of rows is exponential with the number of dimensions</li>
<li>New fields should be added sparing to account for data-set size</li>
</ul>
</li>
<li>The dataset lags by 10 days in order account for submission latency
<ul>
<li>This value was determined to be time for 99% of main pings to arrive at the
server. With the shutdown-ping sender, this has been reduced to 4 days.
However, <code>churn_v3</code> still tracks releases older than Firefox 55.</li>
</ul>
</li>
<li>The start of the period is fixed to Sundays. Once it has been aggregated, the
period cannot be shifted due to the way clients are counted.
<ul>
<li>A supplementary 1-day <code>retention</code> dataset using HyperLogLog for client
counts is available for counting over arbitrary retention periods and date
offsets. Additionally, calculating churn or retention over specific cohorts
is tractable in STMO with <code>main_summary</code> or <code>clients_daily</code> datasets.</li>
</ul>
</li>
</ul>
<h4><a class="header" href="#accessing-the-data-26" id="accessing-the-data-26">Accessing the Data</a></h4>
<p><code>churn</code> is available in Re:dash under Athena and Presto. The data is also
available in parquet for consumption by columnar data engines at
<code>s3://telemetry-parquet/churn/v3</code>.</p>
<h1><a class="header" href="#data-reference-17" id="data-reference-17">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-10" id="example-queries-10">Example Queries</a></h2>
<p>This section walks through a typical query to generate data suitable for
visualization.</p>
<table><thead><tr><th>field</th><th>type</th><th>description</th></tr></thead><tbody>
<tr><td><code>cohort_date</code></td><td>common, attribute</td><td>The start date bucket of the cohort. This is week the client was acquired.</td></tr>
<tr><td><code>elapsed_periods</code></td><td>common, attribute</td><td>The number of periods that have elapsed since the cohort date. In this dataset, the retention period is 7 days.</td></tr>
<tr><td><code>channel</code></td><td>attribute</td><td>Part of the release train model. An attribute that distinguishes cohorts.</td></tr>
<tr><td><code>geo</code></td><td>filter attribute</td><td>Country code. Used to filter out all countries other than the 'US'</td></tr>
<tr><td><code>n_profiles</code></td><td>metric</td><td>Count of users in a cohort. Use sum to aggregate.</td></tr>
</tbody></table>
<p>First the fields are extracted and aliased for consistency. <code>cohort_date</code> and
<code>elapsed_periods</code> are common to most retention queries and are useful concepts
for building on other datasets.</p>
<pre><code class="language-sql">WITH extracted AS (
    SELECT acquisition_period AS cohort_date,
           current_week AS elapsed_periods,
           n_profiles,
           channel,
           geo
    FROM churn
),
</code></pre>
<p>The extracted table is filtered down to the attributes of interest. The cohorts
of interest originate in the US and are in the release or beta channels. Note
that <code>channel</code> here is the concatenation of the normalized channel and the
funnelcake id. Only cohorts appearing after August 6, 2017 are chosen to be in
this population.</p>
<pre><code class="language-sql"> population AS (
    SELECT channel,
           cohort_date,
           elapsed_periods,
           n_profiles
    FROM extracted
    WHERE geo = 'US'
      AND channel IN ('release', 'beta')
      AND cohort_date &gt; '20170806'
      -- filter out noise from clients with incorrect dates
      AND elapsed_periods &gt;= 0
      AND elapsed_periods &lt; 12
),
</code></pre>
<p>The number of profiles is aggregated by the cohort dimensions. The cohort
acquisition date and elapsed periods since acquisition are fundamental to cohort
analysis.</p>
<pre><code class="language-sql"> cohorts AS (
     SELECT channel,
            cohort_date,
            elapsed_periods,
            sum(n_profiles) AS n_profiles
     FROM population
     GROUP BY 1, 2, 3
),
</code></pre>
<p>The table will have the following structure. The table is sorted by the first three columns for demonstration.</p>
<table><thead><tr><th><code>channel</code></th><th><code>cohort_date</code></th><th><code>elapsed_periods</code></th><th><code>n_profiles</code></th></tr></thead><tbody>
<tr><td>release</td><td>20170101</td><td>0</td><td>100</td></tr>
<tr><td>release</td><td>20170101</td><td>1</td><td>90</td></tr>
<tr><td>release</td><td>20170101</td><td>2</td><td>80</td></tr>
<tr><td>...</td><td>...</td><td>...</td><td>...</td></tr>
<tr><td>beta</td><td>20170128</td><td>10</td><td>25</td></tr>
</tbody></table>
<p>Finally, retention is calculated through the number of profiles at the time of
the <code>elapsed_period</code> relative to the initial period. This data can be imported
into a pivot table for further analysis.</p>
<pre><code class="language-sql">results AS (
    SELECT c.*,
           iv.n_profiles AS total_n_profiles,
           (0.0+c.n_profiles)*100/iv.n_profiles AS percentage_n_profiles
    FROM cohorts c
    JOIN (
        SELECT *
        FROM cohorts
        WHERE elapsed_periods = 0
    ) iv ON (
        c.cohort_date = iv.cohort_date
        AND c.channel = iv.channel
    )
)
</code></pre>
<table><thead><tr><th><code>channel</code></th><th><code>cohort_date</code></th><th><code>elapsed_periods</code></th><th><code>n_profiles</code></th><th><code>total_n_profiles</code></th><th><code>percentage_n_profiles</code></th></tr></thead><tbody>
<tr><td>release</td><td>20170101</td><td>0</td><td>100</td><td>100</td><td>1.0</td></tr>
<tr><td>release</td><td>20170101</td><td>1</td><td>90</td><td>100</td><td>0.9</td></tr>
<tr><td>release</td><td>20170101</td><td>2</td><td>80</td><td>100</td><td>0.8</td></tr>
<tr><td>...</td><td>....</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>
<tr><td>beta</td><td>20170128</td><td>10</td><td>25</td><td>50</td><td>0.5</td></tr>
</tbody></table>
<p>Obtain the results.</p>
<pre><code class="language-SQL">SELECT *
FROM results
</code></pre>
<p>You may consider visualizing using cohort graphs, line charts, or a pivot
tables. See <a href="https://sql.telemetry.mozilla.org/dashboard/firefox-telemetry-retention-dataset-example-usage">Firefox Telemetry Retention: Dataset Example Usage</a>
for more examples.</p>
<h2><a class="header" href="#scheduling-13" id="scheduling-13">Scheduling</a></h2>
<p>The aggregated churn data is updated weekly on Wednesday.</p>
<h2><a class="header" href="#schema-14" id="schema-14">Schema</a></h2>
<p>As of 2017-10-15, the current version of <code>churn</code> is <code>v3</code> and has a schema as follows:</p>
<pre><code>root
 |-- channel: string (nullable = true)
 |-- geo: string (nullable = true)
 |-- is_funnelcake: string (nullable = true)
 |-- acquisition_period: string (nullable = true)
 |-- start_version: string (nullable = true)
 |-- sync_usage: string (nullable = true)
 |-- current_version: string (nullable = true)
 |-- current_week: long (nullable = true)
 |-- source: string (nullable = true)
 |-- medium: string (nullable = true)
 |-- campaign: string (nullable = true)
 |-- content: string (nullable = true)
 |-- distribution_id: string (nullable = true)
 |-- default_search_engine: string (nullable = true)
 |-- locale: string (nullable = true)
 |-- is_active: string (nullable = true)
 |-- n_profiles: long (nullable = true)
 |-- usage_hours: double (nullable = true)
 |-- sum_squared_usage_hours: double (nullable = true)
 |-- total_uri_count: long (nullable = true)
 |-- unique_domains_count_per_profile: double (nullable = true)
</code></pre>
<h2><a class="header" href="#code-reference-8" id="code-reference-8">Code Reference</a></h2>
<p>The script for generating <code>churn</code> currently lives in
<a href="https://github.com/mozilla/python_mozetl/tree/9217335652cad46940a51c7c2784cc5c6d3a00f4"><code>mozilla/python_mozetl</code></a>. The job can
be found in
<a href="https://github.com/mozilla/python_mozetl/blob/9217335652cad46940a51c7c2784cc5c6d3a00f4/mozetl/engagement/churn/job.py#L1-L27"><code>mozetl/engagement/churn</code></a>.</p>
<p><em><strong>As of 2019-10-23, this dataset has been deprecated and is no longer
maintained. See <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1585539">Bug 1585539</a>.</strong></em></p>
<h1><a class="header" href="#client-count-daily-reference" id="client-count-daily-reference">Client Count Daily Reference</a></h1>
<p><em><strong>As of 2019-04-10, this dataset has been deprecated and is no longer maintained. Please use <a href="datasets/obsolete/client_count_daily//datasets/bigquery/clients_last_seen/reference.html"><code>clients_last_seen</code></a> instead. See <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1543518">Bug 1543518</a> for more information.</strong></em></p>
<ul>
<li><a href="datasets/obsolete/client_count_daily/reference.html#replacement">Replacement</a></li>
<li><a href="datasets/obsolete/client_count_daily/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/obsolete/client_count_daily/reference.html#content">Content</a></li>
<li><a href="datasets/obsolete/client_count_daily/reference.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="datasets/obsolete/client_count_daily/reference.html#accessing-the-data">Accessing the Data</a></li>
<li><a href="datasets/obsolete/client_count_daily/reference.html#further-reading">Further Reading</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/client_count_daily/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/obsolete/client_count_daily/reference.html#example-queries">Example Queries</a>
<ul>
<li><a href="datasets/obsolete/client_count_daily/reference.html#compute-dau-for-non-windows-clients-for-the-last-week">Compute DAU for non-windows clients for the last week</a></li>
<li><a href="datasets/obsolete/client_count_daily/reference.html#compute-wau-by-channel-for-the-last-week">Compute WAU by Channel for the last week</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/client_count_daily/reference.html#caveats">Caveats</a></li>
<li><a href="datasets/obsolete/client_count_daily/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/obsolete/client_count_daily/reference.html#schema">Schema</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#replacement" id="replacement">Replacement</a></h1>
<p>We've moved to calculating exact user counts based on
<a href="datasets/obsolete/client_count_daily//datasets/bigquery/clients_last_seen/reference.html"><code>clients_last_seen</code></a>, see
<a href="datasets/obsolete/client_count_daily/../../../cookbooks/dau.html">DAU</a> and
<a href="datasets/obsolete/client_count_daily/../../../cookbooks/active_dau.html">Active DAU</a> for examples.</p>
<h1><a class="header" href="#introduction-20" id="introduction-20">Introduction</a></h1>
<p>The <code>client_count_daily</code> dataset is useful for estimating user counts over a few
<a href="https://github.com/mozilla/telemetry-airflow/blob/adfce4a30895faa607ccf586b292b61ad68d8f75/jobs/client_count_daily_view.sh">pre-defined dimensions</a>.</p>
<p>The <code>client_count_daily</code> dataset is similar to the deprecated
<a href="datasets/obsolete/client_count_daily//datasets/batch_view/client_count/reference.html"><code>client_count</code> dataset</a>
except that is aggregated by submission date and not activity date.</p>
<h4><a class="header" href="#content-6" id="content-6">Content</a></h4>
<p>This dataset includes columns for a dozen factors and an HLL variable.
The <code>hll</code> column contains a
<a href="https://en.wikipedia.org/wiki/HyperLogLog">HyperLogLog</a>
variable, which is an approximation to the exact count.
The factor columns include <strong>submission</strong> date and the dimensions listed
<a href="https://github.com/mozilla/telemetry-airflow/blob/adfce4a30895faa607ccf586b292b61ad68d8f75/jobs/client_count_daily_view.sh">here</a>.
Each row represents one combinations of the factor columns.</p>
<h4><a class="header" href="#background-and-caveats-13" id="background-and-caveats-13">Background and Caveats</a></h4>
<p>It's important to understand that the <code>hll</code> column is <strong>not a standard count</strong>.
The <code>hll</code> variable avoids double-counting users when aggregating over multiple days.
The HyperLogLog variable is a far more efficient way to count distinct elements of a set,
but comes with some complexity.
To find the cardinality of an HLL use <code>cardinality(cast(hll AS HLL))</code>.
To find the union of two HLL's over different dates, use <code>merge(cast(hll AS HLL))</code>.
The <a href="https://sql.telemetry.mozilla.org/queries/81/source#129">Firefox ER Reporting Query</a>
is a good example to review.
Finally, Roberto has a relevant write-up
<a href="https://robertovitillo.com/2016/04/12/measuring-product-engagment-at-scale/">here</a>.</p>
<h4><a class="header" href="#accessing-the-data-27" id="accessing-the-data-27">Accessing the Data</a></h4>
<p>The data is available in Re:dash.
Take a look at this
<a href="https://sql.telemetry.mozilla.org/queries/81/source#129">example query</a>.</p>
<p>I don't recommend accessing this data from ATMO.</p>
<h4><a class="header" href="#further-reading-9" id="further-reading-9">Further Reading</a></h4>
<h1><a class="header" href="#data-reference-18" id="data-reference-18">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-11" id="example-queries-11">Example Queries</a></h2>
<h4><a class="header" href="#compute-dau-for-non-windows-clients-for-the-last-week-1" id="compute-dau-for-non-windows-clients-for-the-last-week-1">Compute DAU for non-windows clients for the last week</a></h4>
<pre><code class="language-sql">WITH sample AS (
  SELECT
    os,
    submission_date,
    cardinality(merge(cast(hll AS HLL))) AS count
  FROM client_count_daily
  WHERE submission_date &gt;= DATE_FORMAT(CURRENT_DATE - INTERVAL '7' DAY, '%Y%m%d')
  GROUP BY
    submission_date,
    os
)

SELECT
  os,
  -- formatting date as late as possible improves performance dramatically
  date_parse(submission_date, '%Y%m%d') AS submission_date,
  count
FROM sample
WHERE
  count &gt; 10 -- remove outliers
  AND lower(os) NOT LIKE '%windows%'
ORDER BY
  os,
  submission_date DESC
</code></pre>
<h4><a class="header" href="#compute-wau-by-channel-for-the-last-week-1" id="compute-wau-by-channel-for-the-last-week-1">Compute WAU by Channel for the last week</a></h4>
<pre><code class="language-sql">WITH dau AS (
  SELECT
    normalized_channel,
    submission_date,
    merge(cast(hll AS HLL)) AS hll
  FROM client_count_daily
  -- 2 days of lag, 7 days of results, and 6 days preceding for WAU
  WHERE submission_date &gt; DATE_FORMAT(CURRENT_DATE - INTERVAL '15' DAY, '%Y%m%d')
  GROUP BY
    submission_date,
    normalized_channel
),
wau AS (
  SELECT
    normalized_channel,
    submission_date,
    cardinality(merge(hll) OVER (
      PARTITION BY normalized_channel
      ORDER BY submission_date
      ROWS BETWEEN 6 PRECEDING AND 0 FOLLOWING
    )) AS count
  FROM dau
)

SELECT
  normalized_channel,
  -- formatting date as late as possible improves performance dramatically
  date_parse(submission_date, '%Y%m%d') AS submission_date,
  count
FROM wau
WHERE
  count &gt; 10 -- remove outliers
  AND submission_date &gt; DATE_FORMAT(CURRENT_DATE - INTERVAL '9' DAY, '%Y%m%d') -- only days that have a full WAU
</code></pre>
<h2><a class="header" href="#caveats-2" id="caveats-2">Caveats</a></h2>
<p>The <code>hll</code> column does not product an exact count. <code>hll</code> stands for
<a href="https://en.wikipedia.org/wiki/HyperLogLog">HyperLogLog</a>, a sophisticated
algorithm that allows for the counting of extremely high numbers of items,
sacrificing a small amount of accuracy in exchange for using much less memory
than a simple counting structure.</p>
<p>When count is calculated over a column that may change over time, such as
<code>total_uri_count_threshold</code>, then a client would be counted in every group
where they appear. Over longer windows, like MAU, this is more likely to occur.</p>
<h2><a class="header" href="#scheduling-14" id="scheduling-14">Scheduling</a></h2>
<p>This dataset is updated daily via the
<a href="https://github.com/mozilla/telemetry-airflow">telemetry-airflow</a> infrastructure.
The job runs as part of the <a href="https://github.com/mozilla/telemetry-airflow/blob/master/dags/main_summary.py"><code>main_summary</code> DAG</a>.</p>
<h2><a class="header" href="#schema-15" id="schema-15">Schema</a></h2>
<p>The data is partitioned by <code>submission_date</code> which is formatted as <code>%Y%m%d</code>,
like <code>20180130</code>.</p>
<p>As of 2018-03-15, the current version of the <code>client_count_daily</code> dataset
is <code>v2</code>, and has a schema as follows:</p>
<pre><code>root
 |-- app_name: string (nullable = true)
 |-- app_version: string (nullable = true)
 |-- country: string (nullable = true)
 |-- devtools_toolbox_opened: boolean (nullable = true)
 |-- e10s_enabled: boolean (nullable = true)
 |-- hll: binary (nullable = true)
 |-- locale: string (nullable = true)
 |-- normalized_channel: string (nullable = true)
 |-- os: string (nullable = true)
 |-- os_version: string (nullable = true)
 |-- top_distribution_id: string (nullable = true)
 |-- total_uri_count_threshold: integer (nullable = true)
</code></pre>
<h1><a class="header" href="#crash-aggregates" id="crash-aggregates">Crash Aggregates</a></h1>
<p><em><strong>As of 2018-04-02, this dataset has been deprecated and is no longer maintained. See <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1388025">Bug 1388025</a> for more information.</strong></em></p>
<ul>
<li><a href="datasets/obsolete/crash_aggregates/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/obsolete/crash_aggregates/reference.html#rows-and-columns">Rows and Columns</a></li>
<li><a href="datasets/obsolete/crash_aggregates/reference.html#accessing-the-data">Accessing the Data</a></li>
<li><a href="datasets/obsolete/crash_aggregates/reference.html#further-reading">Further Reading</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/crash_aggregates/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/obsolete/crash_aggregates/reference.html#example-queries">Example Queries</a></li>
<li><a href="datasets/obsolete/crash_aggregates/reference.html#sampling">Sampling</a>
<ul>
<li><a href="datasets/obsolete/crash_aggregates/reference.html#invalid-pings">Invalid Pings</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/crash_aggregates/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/obsolete/crash_aggregates/reference.html#schema">Schema</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#introduction-21" id="introduction-21">Introduction</a></h1>
<p>The <code>crash_aggregates</code> dataset compiles crash statistics over various dimensions for each day.</p>
<h4><a class="header" href="#rows-and-columns-1" id="rows-and-columns-1">Rows and Columns</a></h4>
<p>There's one column for each of the stratifying dimensions and the crash statistics.
Each row is a distinct set of dimensions, along with their associated crash stats.
Example stratifying dimensions include channel and country,
example statistics include usage hours and plugin crashes.</p>
<h4><a class="header" href="#accessing-the-data-28" id="accessing-the-data-28">Accessing the Data</a></h4>
<p>This dataset is accessible via re:dash.</p>
<p>The data is stored as a parquet table in S3 at the following address.</p>
<pre><code>s3://telemetry-parquet/crash_aggregates/v1/
</code></pre>
<h4><a class="header" href="#further-reading-10" id="further-reading-10">Further Reading</a></h4>
<p>The technical documentation for this dataset can be found in the
<a href="https://github.com/mozilla/telemetry-batch-view/blob/0128b08/docs/CrashAggregateView.md">telemetry-batch-view documentation</a></p>
<h1><a class="header" href="#data-reference-19" id="data-reference-19">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-12" id="example-queries-12">Example Queries</a></h2>
<p>Here's an example query that computes crash rates
for each channel (sorted by number of usage hours):</p>
<pre><code class="language-sql">SELECT dimensions['channel'] AS channel,
       sum(stats['usage_hours']) AS usage_hours,
       1000 * sum(stats['main_crashes']) / sum(stats['usage_hours']) AS main_crash_rate,
       1000 * sum(stats['content_crashes']) / sum(stats['usage_hours']) AS content_crash_rate,
       1000 * sum(stats['plugin_crashes']) / sum(stats['usage_hours']) AS plugin_crash_rate,
       1000 * sum(stats['gmplugin_crashes']) / sum(stats['usage_hours']) AS gmplugin_crash_rate,
       1000 * sum(stats['gpu_crashes']) / sum(stats['usage_hours']) AS gpu_crash_rate
FROM crash_aggregates
GROUP BY dimensions['channel']
ORDER BY -sum(stats['usage_hours'])
</code></pre>
<p>Main process crashes by build date and OS version.</p>
<pre><code class="language-sql">WITH channel_rates AS (
  SELECT dimensions['build_id'] AS build_id,
         SUM(stats['main_crashes']) AS main_crashes, -- total number of crashes
         SUM(stats['usage_hours']) / 1000 AS usage_kilohours, -- thousand hours of usage
         dimensions['os_version'] AS os_version -- os version
   FROM crash_aggregates
   WHERE dimensions['experiment_id'] is null -- not in an experiment
     AND regexp_like(dimensions['build_id'], '^\d{14}$') -- validate build IDs
     AND dimensions['build_id'] &gt; '20160201000000' -- only in the date range that we care about
   GROUP BY dimensions['build_id'], dimensions['os_version']
)
SELECT cast(parse_datetime(build_id, 'yyyyMMddHHmmss') as date) as build_id, -- program build date
       usage_kilohours, -- thousands of usage hours
       os_version, -- os version
       main_crashes / usage_kilohours AS main_crash_rate -- crash rate being defined as crashes per thousand usage hours
FROM channel_rates
WHERE usage_kilohours &gt; 100 -- only aggregates that have statistically significant usage hours
ORDER BY build_id ASC
</code></pre>
<h2><a class="header" href="#sampling-4" id="sampling-4">Sampling</a></h2>
<h3><a class="header" href="#invalid-pings-1" id="invalid-pings-1">Invalid Pings</a></h3>
<p>We ignore invalid pings in our processing. Invalid pings are defined as those that:</p>
<ul>
<li>The submission dates or activity dates are invalid or missing.</li>
<li>The build ID is malformed.</li>
<li>The <code>docType</code> field is missing or unknown.</li>
<li>The ping is a main ping without usage hours or a crash ping with usage hours.</li>
</ul>
<h2><a class="header" href="#scheduling-15" id="scheduling-15">Scheduling</a></h2>
<p>The <code>crash_aggregates</code> job is run daily, at midnight UTC.
The job is scheduled on <a href="https://github.com/mozilla/telemetry-airflow">Airflow</a>.
The DAG is <a href="https://github.com/mozilla/telemetry-airflow/blob/d50b938/dags/crash_aggregates.py">here</a></p>
<h2><a class="header" href="#schema-16" id="schema-16">Schema</a></h2>
<p>The <code>crash_aggregates</code> table has 4 commonly-used columns:</p>
<ul>
<li><code>submission_date</code> is the date pings were submitted for a particular aggregate.
<ul>
<li>For example, <code>select sum(stats['usage_hours']) from crash_aggregates where submission_date = '2016-03-15'</code> will give the total number of user hours represented by pings submitted on March 15, 2016.</li>
<li>The dataset is partitioned by this field. Queries that limit the possible values of <code>submission_date</code> can run significantly faster.</li>
</ul>
</li>
<li><code>activity_date</code> is the day when the activity being recorded took place.
<ul>
<li>For example, <code>select sum(stats['usage_hours']) from crash_aggregates where activity_date = '2016-03-15'</code> will give the total number of user hours represented by activities that took place on March 15, 2016.</li>
<li>This can be several days before the pings are actually submitted, so it will always be before or on its corresponding <code>submission_date</code>.</li>
<li>Therefore, queries that are sensitive to when measurements were taken on the client should prefer this field over <code>submission_date</code>.</li>
</ul>
</li>
<li><code>dimensions</code> is a map of all the other dimensions that we currently care about. These fields include:
<ul>
<li><code>dimensions['build_version']</code> is the program version, like <code>46.0a1</code>.</li>
<li><code>dimensions['build_id']</code> is the <code>YYYYMMDDhhmmss</code> timestamp the program was built, like <code>20160123180541</code>. This is also known as the <code>build ID</code> or <code>buildid</code>.</li>
<li><code>dimensions['channel']</code> is the channel, like <code>release</code> or <code>beta</code>.</li>
<li><code>dimensions['application']</code> is the program name, like <code>Firefox</code> or <code>Fennec</code>.</li>
<li><code>dimensions['os_name']</code> is the name of the OS the program is running on, like <code>Darwin</code> or <code>Windows_NT</code>.</li>
<li><code>dimensions['os_version']</code> is the version of the OS the program is running on.</li>
<li><code>dimensions['architecture']</code> is the architecture that the program was built for (not necessarily the one it is running on).</li>
<li><code>dimensions['country']</code> is the country code for the user (determined using geoIP), like <code>US</code> or <code>UK</code>.</li>
<li><code>dimensions['experiment_id']</code> is the identifier of the experiment being participated in, such as <code>e10s-beta46-noapz@experiments.mozilla.org</code>, or null if no experiment.</li>
<li><code>dimensions['experiment_branch']</code> is the branch of the experiment being participated in, such as <code>control</code> or <code>experiment</code>, or null if no experiment.</li>
<li><code>dimensions['e10s_enabled']</code> is whether E10s is enabled.</li>
<li><code>dimensions['gfx_compositor']</code> is the graphics backend compositor used by the program, such as <code>d3d11</code>, <code>opengl</code> and <code>simple</code>. Null values may be reported as <code>none</code> as well.</li>
<li>All of the above fields can potentially be blank, which means &quot;not present&quot;. That means that in the actual pings, the corresponding fields were null.</li>
</ul>
</li>
<li><code>stats</code> contains the aggregate values that we care about:
<ul>
<li><code>stats['usage_hours']</code> is the number of user-hours represented by the aggregate.</li>
<li><code>stats['main_crashes']</code> is the number of main process crashes represented by the aggregate (or just program crashes, in the non-E10S case).</li>
<li><code>stats['content_crashes']</code> is the number of content process crashes represented by the aggregate.</li>
<li><code>stats['plugin_crashes']</code> is the number of plugin process crashes represented by the aggregate.</li>
<li><code>stats['gmplugin_crashes']</code> is the number of Gecko media plugin (often abbreviated <code>GMPlugin</code>) process crashes represented by the aggregate.</li>
<li><code>stats['content_shutdown_crashes']</code> is the number of content process crashes that were caused by failure to shut down in a timely manner.</li>
<li><code>stats['gpu_crashes']</code> is the number of GPU process crashes represented by the aggregate.</li>
</ul>
</li>
</ul>
<p><code>TODO(harter)</code>: https://bugzilla.mozilla.org/show_bug.cgi?id=1361862</p>
<h1><a class="header" href="#crash-summary-reference" id="crash-summary-reference">Crash Summary Reference</a></h1>
<ul>
<li><a href="datasets/obsolete/crash_summary/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/obsolete/crash_summary/reference.html#contents">Contents</a></li>
<li><a href="datasets/obsolete/crash_summary/reference.html#accessing-the-data">Accessing the Data</a></li>
<li><a href="datasets/obsolete/crash_summary/reference.html#further-reading">Further Reading</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/crash_summary/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/obsolete/crash_summary/reference.html#example-queries">Example Queries</a></li>
<li><a href="datasets/obsolete/crash_summary/reference.html#sampling">Sampling</a></li>
<li><a href="datasets/obsolete/crash_summary/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/obsolete/crash_summary/reference.html#schema">Schema</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#introduction-22" id="introduction-22">Introduction</a></h1>
<p><em><strong>As of 2019-11-06, this dataset has been deprecated and is no longer maintained. Please use the <code>telemetry.crash</code> table instead, which is generated directly from live pings and is much more complete. See <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1572069">Bug 1572069</a> for more information.</strong></em></p>
<p>The <code>crash_summary</code> table is the a direct representation of a crash ping.</p>
<h4><a class="header" href="#contents-18" id="contents-18">Contents</a></h4>
<p>The <code>crash_summary</code> table contains one row for each crash ping.
Each column represents one field from the crash ping payload,
though only a subset of all crash ping fields are included.</p>
<h4><a class="header" href="#accessing-the-data-29" id="accessing-the-data-29">Accessing the Data</a></h4>
<p>The data is stored as a parquet table in S3 at the following address.</p>
<pre><code>s3://telemetry-parquet/crash_summary/v1/
</code></pre>
<p><code>crash_summary</code> is accessible through re:dash.
Here's an <a href="https://sql.telemetry.mozilla.org/queries/4793/source">example query</a>.</p>
<h4><a class="header" href="#further-reading-11" id="further-reading-11">Further Reading</a></h4>
<p>The technical documentation for <code>crash_summary</code> is located in the
<a href="https://github.com/mozilla/telemetry-batch-view/blob/master/docs/CrashSummary.md">telemetry-batch-view documentation</a>.</p>
<p>The code responsible for generating this dataset is
<a href="https://github.com/mozilla/telemetry-batch-view/blob/master/GRAVEYARD.md#crash-summary">here</a></p>
<h1><a class="header" href="#data-reference-20" id="data-reference-20">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-13" id="example-queries-13">Example Queries</a></h2>
<p>Here is an example query to get the total number of main crashes by <code>gfx_compositor</code>:</p>
<pre><code class="language-sql">select gfx_compositor, count(*)
from crash_summary
where application = 'Firefox'
and (payload.processType IS NULL OR payload.processType = 'main')
group by gfx_compositor
</code></pre>
<h2><a class="header" href="#sampling-5" id="sampling-5">Sampling</a></h2>
<p><code>CrashSummary</code> contains one record for every
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/crash-ping.html">crash ping</a>
submitted by Firefox.</p>
<h2><a class="header" href="#scheduling-16" id="scheduling-16">Scheduling</a></h2>
<p>This dataset is updated daily, shortly after midnight UTC.
The job is scheduled on
<a href="https://github.com/mozilla/telemetry-airflow">telemetry-airflow</a>.
The DAG is <a href="https://github.com/mozilla/telemetry-airflow/blob/166e0a555ee2de0d3c7f0add1011f7771f7ea23d/dags/crash_summary.py">here</a>.</p>
<h2><a class="header" href="#schema-17" id="schema-17">Schema</a></h2>
<pre><code>root
 |-- client_id: string (nullable = true)
 |-- normalized_channel: string (nullable = true)
 |-- build_version: string (nullable = true)
 |-- build_id: string (nullable = true)
 |-- channel: string (nullable = true)
 |-- crash_time: string (nullable = true)
 |-- application: string (nullable = true)
 |-- os_name: string (nullable = true)
 |-- os_version: string (nullable = true)
 |-- architecture: string (nullable = true)
 |-- country: string (nullable = true)
 |-- experiment_id: string (nullable = true)
 |-- experiment_branch: string (nullable = true)
 |-- experiments: map (nullable = true)
 |    |-- key: string
 |    |-- value: string (valueContainsNull = true)
 |-- e10s_enabled: boolean (nullable = true)
 |-- gfx_compositor: string (nullable = true)
 |-- profile_created: integer (nullable = true)
 |-- payload: struct (nullable = true)
 |    |-- crashDate: string (nullable = true)
 |    |-- processType: string (nullable = true)
 |    |-- hasCrashEnvironment: boolean (nullable = true)
 |    |-- metadata: map (nullable = true)
 |    |    |-- key: string
 |    |    |-- value: string (valueContainsNull = true)
 |    |-- version: integer (nullable = true)
 |-- submission_date: string (nullable = true)
</code></pre>
<p>For more detail on where these fields come from in the
<a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/crash-ping.html">raw data</a>,
please look at the case classes
<a href="https://github.com/mozilla/telemetry-batch-view/blob/master/GRAVEYARD.md#crash-summary">in the <code>CrashSummaryView</code> code</a>.</p>
<h1><a class="header" href="#error-aggregates-reference" id="error-aggregates-reference">Error Aggregates Reference</a></h1>
<p><em><strong>As of 2019-11-21, this dataset has been deprecated and is no longer maintained. See <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1594112">Bug 1594112</a> for more information.</strong></em></p>
<ul>
<li><a href="datasets/obsolete/error_aggregates/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/obsolete/error_aggregates/reference.html#contents">Contents</a></li>
<li><a href="datasets/obsolete/error_aggregates/reference.html#accessing-the-data">Accessing the data</a></li>
<li><a href="datasets/obsolete/error_aggregates/reference.html#further-reading">Further Reading</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/error_aggregates/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/obsolete/error_aggregates/reference.html#example-queries">Example Queries</a></li>
<li><a href="datasets/obsolete/error_aggregates/reference.html#sampling">Sampling</a>
<ul>
<li><a href="datasets/obsolete/error_aggregates/reference.html#data-sources">Data sources</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/error_aggregates/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/obsolete/error_aggregates/reference.html#schema">Schema</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#introduction-23" id="introduction-23">Introduction</a></h1>
<p>The <code>error_aggregates_v2</code> table represents counts of errors counted from main and crash
pings, aggregated every 5 minutes. It is the dataset backing the main <a href="https://data-missioncontrol.dev.mozaws.net/">mission
control</a> view, but may also be queried
independently.</p>
<h4><a class="header" href="#contents-19" id="contents-19">Contents</a></h4>
<p>The <code>error_aggregates_v2</code> table contains counts of various error measures (for
example: crashes, &quot;the slow script dialog showing&quot;), aggregated across each
unique set of dimensions (for example: channel, operating system) every 5
minutes. You can get an aggregated count for any particular set of dimensions
by summing using SQL.</p>
<h5><a class="header" href="#experiment-unpacking-1" id="experiment-unpacking-1">Experiment unpacking</a></h5>
<p>It's important to note that when this dataset is written, pings from clients participating in an experiment 
are aggregated on the <code>experiment_id</code> and <code>experiment_branch</code> dimensions corresponding to what experiment and branch 
they are participating in. However, they are also aggregated with the rest of the population where the values of 
these dimensions are null.
Therefore care must be taken when writing aggregating queries over the whole population - in these cases one needs to
filter for <code>experiment_id is null</code> and <code>experiment_branch is null</code> in order to not double-count pings from experiments.</p>
<h4><a class="header" href="#accessing-the-data-30" id="accessing-the-data-30">Accessing the data</a></h4>
<p>You can access the data via re:dash. Choose <code>Athena</code> and then select the
<code>telemetry.error_aggregates_v2</code> table.</p>
<h4><a class="header" href="#further-reading-12" id="further-reading-12">Further Reading</a></h4>
<p>The code responsible for generating this dataset is <a href="https://github.com/mozilla/telemetry-streaming/blob/master/src/main/scala/com/mozilla/telemetry/streaming/ErrorAggregator.scala">here</a>.</p>
<h1><a class="header" href="#data-reference-21" id="data-reference-21">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-14" id="example-queries-14">Example Queries</a></h2>
<p>Getting a large number of different crash measures across many platforms and channels
(<a href="https://sql.telemetry.mozilla.org/queries/4769/source">view on Re:dash</a>):</p>
<pre><code class="language-sql">SELECT window_start,
       build_id,
       channel,
       os_name,
       version,
       sum(usage_hours) AS usage_hours,
       sum(main_crashes) AS main,
       sum(content_crashes) AS content,
       sum(gpu_crashes) AS gpu,
       sum(plugin_crashes) AS plugin,
       sum(gmplugin_crashes) AS gmplugin
FROM error_aggregates_v2
  WHERE application = 'Firefox'
  AND (os_name = 'Darwin' or os_name = 'Linux' or os_name = 'Windows_NT')
  AND (channel = 'beta' or channel = 'release' or channel = 'nightly' or channel = 'esr')
  AND build_id &gt; '201801'
  AND window_start &gt; current_timestamp - (1 * interval '24' hour)
  AND experiment_id IS NULL
  AND experiment_branch IS NULL
GROUP BY window_start, channel, build_id, version, os_name
</code></pre>
<p>Get the number of <code>main_crashes</code> on Windows over a small interval
(<a href="https://sql.telemetry.mozilla.org/queries/51677">view on Re:dash</a>):</p>
<pre><code class="language-sql">SELECT window_start as time, sum(main_crashes) AS main_crashes
FROM error_aggregates_v2
  WHERE application = 'Firefox'
  AND os_name = 'Windows_NT'
  AND channel = 'release'
  AND version = '58.0.2'
  AND window_start &gt; timestamp '2018-02-21'
  AND window_end &lt; timestamp '2018-02-22'
  AND experiment_id IS NULL
  AND experiment_branch IS NULL
GROUP BY window_start
</code></pre>
<h2><a class="header" href="#sampling-6" id="sampling-6">Sampling</a></h2>
<h3><a class="header" href="#data-sources-1" id="data-sources-1">Data sources</a></h3>
<p>The aggregates in this data source are derived from main, crash and core <a href="datasets/obsolete/error_aggregates/../../pings.html">pings</a>:</p>
<ul>
<li>crash pings are used to count/gather main and content crash events, all other errors from desktop clients (including all other crashes) are gathered from main pings</li>
<li>core pings are used to count usage hours, first subsession and unique client counts.</li>
</ul>
<h2><a class="header" href="#scheduling-17" id="scheduling-17">Scheduling</a></h2>
<p>The <code>error_aggregates</code> job is run continuously, using the Spark Streaming infrastructure</p>
<h2><a class="header" href="#schema-18" id="schema-18">Schema</a></h2>
<p>The <code>error_aggregates_v2</code> table has the following columns which define its dimensions:</p>
<ul>
<li><code>window_start</code>: beginning of interval when this sample was taken</li>
<li><code>window_end</code>: end of interval when this sample was taken (will always be 5 minutes more
than <code>window_start</code> for any given row)</li>
<li><code>submission_date_s3</code>: the date pings were submitted for a particular aggregate</li>
<li><code>channel</code>: the channel, like <code>release</code> or <code>beta</code></li>
<li><code>version</code>: the version e.g. <code>57.0.1</code></li>
<li><code>display_version</code>: like version, but includes beta number if applicable e.g. <code>57.0.1b4</code></li>
<li><code>build_id</code>: the <code>YYYYMMDDhhmmss</code> timestamp the program was built, like <code>20160123180541</code>. This is also known as the <code>build ID</code> or <code>buildid</code></li>
<li><code>application</code>: application name (e.g. <code>Firefox</code> or <code>Fennec</code>)</li>
<li><code>os_name</code>: name of the OS (e.g. <code>Darwin</code> or <code>Windows_NT</code>)</li>
<li><code>os_version</code>: version of the OS</li>
<li><code>architecture</code>: build architecture, e.g. <code>x86</code></li>
<li><code>country</code>: country code for the user (determined using geoIP), like <code>US</code> or <code>UK</code></li>
<li><code>experiment_id</code>: identifier of the experiment being participated in, such as <code>e10s-beta46-noapz@experiments.mozilla.org</code>, null if no experiment or for unpacked rows (see <a href="datasets/obsolete/error_aggregates/reference.html#experiment-unpacking">Experiment unpacking</a>)</li>
<li><code>experiment_branch</code>: the branch of the experiment being participated in, such as <code>control</code> or <code>experiment</code>, null if no experiment or for unpacked rows (see <a href="datasets/obsolete/error_aggregates/reference.html#experiment-unpacking">Experiment unpacking</a>)</li>
</ul>
<p>And these are the various measures we are counting:</p>
<ul>
<li><code>usage_hours</code>: number of usage hours (i.e. total number of session hours reported by the pings in this aggregate, note that this might include time where
people are not actively using the browser or their computer is asleep)</li>
<li><code>count</code>: number of pings processed in this aggregate</li>
<li><code>main_crashes</code>: number of main process crashes (or just program crashes, in the non-e10s case)</li>
<li><code>startup_crashes</code> : number of startup crashes</li>
<li><code>content_crashes</code>: number of content process crashes (<code>version =&gt; 58</code> only)</li>
<li><code>gpu_crashes</code>: number of GPU process crashes</li>
<li><code>plugin_crashes</code>: number of plugin process crashes</li>
<li><code>gmplugin_crashes</code>: number of Gecko media plugin (often abbreviated <code>GMPlugin</code>) process crashes</li>
<li><code>content_shutdown_crashes</code>: number of content process crashes that were caused by failure to shut down in a timely manner (<code>version =&gt; 58</code> only) </li>
<li><code>browser_shim_usage_blocked</code>: number of times a CPOW shim was blocked from being created by browser code</li>
<li><code>permissions_sql_corrupted</code>: number of times the permissions SQL error occurred (beta/nightly only)</li>
<li><code>defective_permissions_sql_removed</code>: number of times there was a removal of defective <code>permissions.sqlite</code> (beta/nightly only)</li>
<li><code>slow_script_notice_count</code>: number of times the slow script notice count was shown (beta/nightly only)</li>
<li><code>slow_script_page_count</code>: number of pages that trigger slow script notices (beta/nightly only)</li>
</ul>
<h1><a class="header" href="#heavy-users" id="heavy-users">Heavy Users</a></h1>
<p><em><strong>As of 2018-05-18, this dataset has been deprecated and is no longer maintained. See <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1455314">Bug 1455314</a></strong></em></p>
<ul>
<li><a href="datasets/obsolete/heavy_users/reference.html#replacement">Replacement</a></li>
<li><a href="datasets/obsolete/heavy_users/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/obsolete/heavy_users/reference.html#contents">Contents</a></li>
<li><a href="datasets/obsolete/heavy_users/reference.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="datasets/obsolete/heavy_users/reference.html#accessing-the-data">Accessing the Data</a></li>
<li><a href="datasets/obsolete/heavy_users/reference.html#further-reading">Further Reading</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/heavy_users/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/obsolete/heavy_users/reference.html#example-queries">Example Queries</a></li>
<li><a href="datasets/obsolete/heavy_users/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/obsolete/heavy_users/reference.html#schema">Schema</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/heavy_users/reference.html#code-reference">Code Reference</a></li>
</ul>
<h1><a class="header" href="#replacement-1" id="replacement-1">Replacement</a></h1>
<p>We've moved to assigning user's an active tag based on <code>total_uri_count</code>, see
the <a href="datasets/obsolete/heavy_users/../../../cookbooks/active_dau.html">Active DAU definition</a>.</p>
<p>The activity of a user based on <code>active_ticks</code> is available in <code>clients_daily</code>
in the <code>active_hours_sum</code> field, which has the <code>sum(active_ticks / 720)</code>.</p>
<p>To retrieve a client's 28-day <code>active_hours</code>, use the following query:</p>
<pre><code class="language-sql">SELECT submission_date_s3,
       client_id,
       SUM(active_hours_sum) OVER (PARTITION BY client_id
                                   ORDER BY submission_date_s3 ASC
                                   ROWS 27 PRECEDING) AS monthly_active_hours
FROM
    clients_daily
</code></pre>
<h1><a class="header" href="#introduction-24" id="introduction-24">Introduction</a></h1>
<p>The <code>heavy_users</code> table provides information about whether a given <code>client_id</code> is
considered a &quot;heavy user&quot; on each day (using submission date).</p>
<h4><a class="header" href="#contents-20" id="contents-20">Contents</a></h4>
<p>The <code>heavy_users</code> table contains one row per client-day, where day is
<code>submission_date</code>. A client has a row for a specific <code>submission_date</code> if
they were active at all in the 28 day window ending on that <code>submission_date</code>.</p>
<p>A user is a &quot;heavy user&quot; as of day N if, for the 28 day period ending
on day N, the sum of their <code>active_ticks</code> is in the 90th percentile (or
above) of all clients during that period. For more analysis on this,
and a discussion of new profiles, see
<a href="https://metrics.mozilla.com/protected/sguha/heavy/heavycutoffs5.html">this link</a>.</p>
<h4><a class="header" href="#background-and-caveats-14" id="background-and-caveats-14">Background and Caveats</a></h4>
<ol>
<li>Data starts at 20170801. There is technically data in the table before
this, but the <code>heavy_user</code> column is <code>NULL</code> for those dates because it
needed to bootstrap the first 28 day window.</li>
<li>Because it is top the 10% of clients for each 28 day period, more
than 10% of clients active on a given <code>submission_date</code> will be
considered heavy users. If you join with another data source
(<code>main_summary</code>, for example), you may see a larger proportion of heavy
users than expected.</li>
<li>Each day has a separate, but related, set of heavy users. Initial
investigations show that approximately 97.5% of heavy users as of a
certain day are still considered heavy users as of the next day.</li>
<li>There is no &quot;fixing&quot; or weighting of new profiles - days before the
profile was created are counted as zero <code>active_ticks</code>. Analyses may
need to use the included <code>profile_creation_date</code> field to take this
into account.</li>
</ol>
<h4><a class="header" href="#accessing-the-data-31" id="accessing-the-data-31">Accessing the Data</a></h4>
<p>The data is available both via <code>sql.t.m.o</code> and Spark.</p>
<p>In Spark:</p>
<pre><code class="language-python">spark.read.parquet(&quot;s3://telemetry-parquet/heavy_users/v1&quot;)
</code></pre>
<p>In SQL:</p>
<pre><code class="language-sql">SELECT * FROM heavy_users LIMIT 3
</code></pre>
<h4><a class="header" href="#further-reading-13" id="further-reading-13">Further Reading</a></h4>
<p>The code responsible for generating this dataset is
<a href="https://github.com/mozilla/telemetry-batch-view/blob/master/GRAVEYARD.md#heavy-users">here</a></p>
<h1><a class="header" href="#data-reference-22" id="data-reference-22">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-15" id="example-queries-15">Example Queries</a></h2>
<p>Example queries:</p>
<ul>
<li><a href="https://sql.telemetry.mozilla.org/queries/47041/source#127382">Join <code>heavy_users</code> with <code>main_summary</code> to get distribution of <code>max_concurrent_tab_count</code> for heavy vs. non-heavy users</a></li>
<li><a href="https://sql.telemetry.mozilla.org/queries/47044/source#127385">Join <code>heavy_users</code> with <code>longitudinal</code> to get crash rates for heavy vs. non-heavy users</a></li>
</ul>
<h2><a class="header" href="#scheduling-18" id="scheduling-18">Scheduling</a></h2>
<p>This dataset is updated daily via the <a href="https://github.com/mozilla/telemetry-airflow">telemetry-airflow</a> infrastructure.
The job DAG runs every day after <code>main_summary</code> is complete.
You can find the job definition
<a href="https://github.com/mozilla/telemetry-airflow/blob/master/dags/main_summary.py#L187-L195">here</a>.</p>
<h2><a class="header" href="#schema-19" id="schema-19">Schema</a></h2>
<p>As of 2017-10-05, the current version of the <code>heavy_users</code> dataset is <code>v1</code>, and has a schema as follows:</p>
<pre><code>root
 |-- client_id: string (nullable = true)
 |-- sample_id: integer (nullable = true)
 |-- profile_creation_date: long (nullable = true)
 |-- active_ticks: long (nullable = true)
 |-- active_ticks_period: long (nullable = true)
 |-- heavy_user: boolean (nullable = true)
 |-- prev_year_heavy_user: boolean (nullable = true)
 |-- submission_date_s3: string (nullable = true)
</code></pre>
<h1><a class="header" href="#code-reference-9" id="code-reference-9">Code Reference</a></h1>
<p>This dataset is generated by
<a href="https://github.com/mozilla/telemetry-batch-view/blob/master/GRAVEYARD.md#heavy-users">telemetry-batch-view</a>.
Refer to this repository for information on how to run or augment the dataset.</p>
<h1><a class="header" href="#longitudinal-reference" id="longitudinal-reference">Longitudinal Reference</a></h1>
<ul>
<li><a href="datasets/obsolete/longitudinal/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/obsolete/longitudinal/reference.html#contents">Contents</a></li>
<li><a href="datasets/obsolete/longitudinal/reference.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="datasets/obsolete/longitudinal/reference.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/longitudinal/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/obsolete/longitudinal/reference.html#sampling">Sampling</a>
<ul>
<li><a href="datasets/obsolete/longitudinal/reference.html#pings-within-last-6-months">Pings Within Last 6 Months</a></li>
<li><a href="datasets/obsolete/longitudinal/reference.html#1-sample">1% Sample</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/longitudinal/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/obsolete/longitudinal/reference.html#schema">Schema</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/longitudinal/reference.html#code-reference">Code Reference</a></li>
</ul>
<h1><a class="header" href="#introduction-25" id="introduction-25">Introduction</a></h1>
<p>The <code>longitudinal</code> dataset is a 1% sample of main ping data
organized so that each row corresponds to a <code>client_id</code>.
If you're not sure which dataset to use for your analysis,
this is probably what you want.</p>
<h4><a class="header" href="#contents-21" id="contents-21">Contents</a></h4>
<p>Each row in the <code>longitudinal</code> dataset represents one <code>client_id</code>,
which is approximately a user.
Each column represents a field from the main ping.
Most fields contain <strong>arrays of values</strong>, with one value for each ping associated with a <code>client_id</code>.
Using arrays give you access to the raw data from each ping,
but can be difficult to work with from SQL.
Here's a <a href="https://sql.telemetry.mozilla.org/queries/4188#table">query showing some sample data</a>
to help illustrate.</p>
<h4><a class="header" href="#background-and-caveats-15" id="background-and-caveats-15">Background and Caveats</a></h4>
<p>Think of the longitudinal table as wide and short.
The dataset contains more columns than <code>main_summary</code>
and down-samples to 1% of all clients to reduce query computation time and save resources.</p>
<p>In summary, the longitudinal table differs from <code>main_summary</code> in two important ways:</p>
<ul>
<li>The longitudinal dataset groups all data so that one row represents a <code>client_id</code></li>
<li>The longitudinal dataset samples to 1% of all <code>client_id</code>s</li>
</ul>
<p>Please note that this dataset only contains release (or opt-out) histograms and scalars.</p>
<h4><a class="header" href="#accessing-the-data-32" id="accessing-the-data-32">Accessing the Data</a></h4>
<p>The <code>longitudinal</code> is available in re:dash,
though it can be difficult to work with the array values in SQL.
Take a look at this <a href="https://sql.telemetry.mozilla.org/queries/4189/source">example query</a>.</p>
<p>The data is stored as a parquet table in S3 at the following address.</p>
<pre><code>s3://telemetry-parquet/longitudinal/
</code></pre>
<h1><a class="header" href="#data-reference-23" id="data-reference-23">Data Reference</a></h1>
<h2><a class="header" href="#sampling-7" id="sampling-7">Sampling</a></h2>
<h3><a class="header" href="#pings-within-last-6-months" id="pings-within-last-6-months">Pings Within Last 6 Months</a></h3>
<p>The <code>longitudinal</code> filters to <code>main</code> pings from within the last 6 months.</p>
<h3><a class="header" href="#1-sample" id="1-sample">1% Sample</a></h3>
<p>The longitudinal dataset samples down to 1% of all clients in the above sample.
The sample is generated by the following process:</p>
<ul>
<li>hash the <code>client_id</code> for each ping from the last 6 months.</li>
<li>project that hash onto an integer from 1:100, inclusive</li>
<li>filter to pings with <code>client_id</code>s matching a 'magic number' (in this case 42)</li>
</ul>
<p>This process has a couple of nice properties:</p>
<ul>
<li>The sample is consistent over time.
The <code>longitudinal</code> dataset is regenerated weekly.
The clients included in each run are very similar with this process.
The only change will come from never-before-seen clients,
or clients without a ping in the last 180 days.</li>
<li>We don't need to adjust the sample as new clients enter or exit our pool.</li>
</ul>
<p>More practically,
the sample is created by filtering to pings with <code>main_summary.sample_id == 42</code>.
If you're working with <code>main_summary</code>,
you can recreate this sample by doing this filter manually.</p>
<h2><a class="header" href="#scheduling-19" id="scheduling-19">Scheduling</a></h2>
<p>The <code>longitudinal</code> job is run weekly, early on Sunday morning UTC.
The job is scheduled on <a href="https://github.com/mozilla/telemetry-airflow">Airflow</a>.
The DAG is <a href="https://github.com/mozilla/telemetry-airflow/blob/54cffc42a2ca24e46056b7030735f0d4d093c0c7/dags/longitudinal.py">here</a>.</p>
<h2><a class="header" href="#schema-20" id="schema-20">Schema</a></h2>
<p><code>TODO(harter)</code>: https://bugzilla.mozilla.org/show_bug.cgi?id=1361862</p>
<h1><a class="header" href="#code-reference-10" id="code-reference-10">Code Reference</a></h1>
<p>This dataset is generated by
<a href="https://github.com/mozilla/telemetry-batch-view/blob/master/GRAVEYARD.md#longitudinal">telemetry-batch-view</a>.
Refer to this repository for information on how to run or augment the dataset.</p>
<h1><a class="header" href="#1-day-retention" id="1-day-retention">1 Day Retention</a></h1>
<p><em><strong>As of 2019-08-13, this dataset has been deprecated and is no longer
maintained. See <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1571565">Bug
1571565</a> for historical
sources. See the <a href="datasets/obsolete/retention/../../../cookbooks/retention.html">retention cookbook</a> for
current best practices.</strong></em></p>
<ul>
<li><a href="datasets/obsolete/retention/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/obsolete/retention/reference.html#contents">Contents</a>
<ul>
<li><a href="datasets/obsolete/retention/reference.html#background-and-caveats">Background and Caveats</a></li>
<li><a href="datasets/obsolete/retention/reference.html#accessing-the-data">Accessing the Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="datasets/obsolete/retention/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/obsolete/retention/reference.html#example-queries">Example Queries</a></li>
<li><a href="datasets/obsolete/retention/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/obsolete/retention/reference.html#schema">Schema</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/retention/reference.html#code-reference">Code Reference</a></li>
</ul>
<h1><a class="header" href="#introduction-26" id="introduction-26">Introduction</a></h1>
<p>The <code>retention</code> table provides client counts relevant to client retention at a
1-day granularity. The project is tracked in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1381840">Bug 1381840</a></p>
<h3><a class="header" href="#contents-22" id="contents-22">Contents</a></h3>
<p>The <code>retention</code> table contains a set of attribute columns used to specify a
cohort of users and a set of metric columns to describe cohort activity. Each
row contains a permutation of attributes, an approximate set of clients in a
cohort, and the aggregate engagement metrics.</p>
<p>This table uses the HyperLogLog (HLL) sketch to create an approximate set of
clients in a cohort. HLL allows counting across overlapping cohorts in a single
pass while avoiding the problem of double counting. This data-structure has the
benefit of being compact and performant in the context of retention analysis,
at the expense of precision. For example, calculating a 7-day retention period
can be obtained by aggregating over a week of retention data using the union
operation. With SQL primitive, this requires a recalculation of COUNT DISTINCT
over <code>client_id</code>'s in the 7-day window.</p>
<h4><a class="header" href="#background-and-caveats-16" id="background-and-caveats-16">Background and Caveats</a></h4>
<ol>
<li>The data starts at 2017-03-06, the <a href="https://wiki.mozilla.org/RapidRelease/Calendar">merge date where Nightly started to
track Firefox 55 in Mozilla-Central</a>. However, there was
not a consistent view into the behavior of first session profiles until the
<a href="datasets/obsolete/retention//datasets/batch_view/new_profile/reference.html"><code>new_profile</code> ping</a>. This means much of the data is inaccurate
before 2017-06-26.</li>
<li>This dataset uses 4 day reporting latency to aggregate at least 99% of the
data in a given submission date. This figure is derived from the
<a href="https://sql.telemetry.mozilla.org/dashboard/telemetry-health">telemetry-health measurements on submission latency</a>, with
the discussion in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1407410">Bug 1407410</a>. This latency metric was reduced
Firefox 55 with the introduction of the shutdown ping-sender mechanism.</li>
<li>Caution should be taken before adding new columns. Additional attribute
columns will grow the number of rows exponentially.</li>
<li>The number of HLL bits chosen for this dataset is 13. This means the default
size of the HLL object is 2^13 bits or 1KiB. This maintains about a 1% error
on average. See <a href="https://github.com/twitter/algebird/blob/develop/algebird-core/src/main/scala/com/twitter/algebird/HyperLogLog.scala#L230-L255">this table from Algebird's HLL implementation</a> for
more details.</li>
</ol>
<h4><a class="header" href="#accessing-the-data-33" id="accessing-the-data-33">Accessing the Data</a></h4>
<p>The data is primarily available through <a href="https://sql.telemetry.mozilla.org">Re:dash on STMO</a> via
the Presto source. This service has been configured to use predefined HLL
functions.</p>
<p>The column should first be cast to the HLL type. The scalar
<code>cardinality(&lt;hll_column&gt;)</code> function will approximate the number of unique
items per HLL object. The aggregate <code>merge(&lt;hll_column&gt;)</code> function will perform
the set union between all objects in a column.</p>
<p>Example: Cast the count column into the appropriate type.</p>
<pre><code class="language-sql">SELECT cast(hll as HLL) as n_profiles_hll FROM retention
</code></pre>
<p>Count the number of clients seen over all attribute combinations.</p>
<pre><code class="language-sql">SELECT cardinality(cast(hll as HLL)) FROM retention
</code></pre>
<p>Group-by and aggregate client counts over different release channels.</p>
<pre><code class="language-sql">SELECT channel, cardinality(merge(cast(hll AS HLL))
FROM retention
GROUP BY channel
</code></pre>
<p>The HyperLogLog library wrappers are available for use outside of the
configured STMO environment, <a href="https://github.com/mozilla/spark-hyperloglog"><code>spark-hyperloglog</code></a> and
<a href="https://github.com/vitillo/presto-hyperloglog"><code>presto-hyperloglog</code></a>.</p>
<p>Also see the <a href="datasets/obsolete/retention//datasets/obsolete/client_count_daily/reference.html"><code>client_count_daily</code> dataset</a>.</p>
<h1><a class="header" href="#data-reference-24" id="data-reference-24">Data Reference</a></h1>
<h2><a class="header" href="#example-queries-16" id="example-queries-16">Example Queries</a></h2>
<p>See the <a href="https://sql.telemetry.mozilla.org/dashboard/firefox-telemetry-retention-dataset-example-usage">Example Usage Dashboard</a> for more usages of datasets of
the same shape.</p>
<h2><a class="header" href="#scheduling-20" id="scheduling-20">Scheduling</a></h2>
<p>The job is scheduled on Airflow on a daily basis after <code>main_summary</code> is run
for the day. This job requires both <code>mozetl</code> and <code>telemetry-batch-view</code> as
dependencies.</p>
<h2><a class="header" href="#schema-21" id="schema-21">Schema</a></h2>
<p>As of 2017-10-10, the current version of <code>retention</code> is <code>v1</code> and has a schema
as follows:</p>
<pre><code>root
 |-- subsession_start: string (nullable = true)
 |-- profile_creation: string (nullable = true)
 |-- days_since_creation: long (nullable = true)
 |-- channel: string (nullable = true)
 |-- app_version: string (nullable = true)
 |-- geo: string (nullable = true)
 |-- distribution_id: string (nullable = true)
 |-- is_funnelcake: boolean (nullable = true)
 |-- source: string (nullable = true)
 |-- medium: string (nullable = true)
 |-- content: string (nullable = true)
 |-- sync_usage: string (nullable = true)
 |-- is_active: boolean (nullable = true)
 |-- hll: binary (nullable = true)
 |-- usage_hours: double (nullable = true)
 |-- sum_squared_usage_hours: double (nullable = true)
 |-- total_uri_count: long (nullable = true)
 |-- unique_domains_count: double (nullable = true)
</code></pre>
<h1><a class="header" href="#code-reference-11" id="code-reference-11">Code Reference</a></h1>
<p>The ETL script for processing the data before aggregation is found in
<a href="https://github.com/mozilla/python_mozetl/blob/ba51f539e5f1218954b7f3536e96f50c57a1b55c/mozetl/engagement/retention/job.py"><code>mozetl.engagement.retention</code></a>. The aggregate job is found in
<a href="https://github.com/mozilla/telemetry-batch-view/blob/9428b1951545dcd7517a3e72c81e7891a6dfa1fa/src/main/scala/com/mozilla/telemetry/views/RetentionView.scala">telemetry-batch-view</a> as the <code>RetentionView</code>.</p>
<p>The <a href="https://github.com/acmiyaguchi/telemetry-airflow/blob/1b4b11d23cdd1191ed2d2be905f116d7c3c67533/jobs/retention.sh">runner script</a> performs all the necessary setup to run on
EMR. This script can be used to perform backfill.</p>
<h1><a class="header" href="#sync-summary-and-sync-flat-summary-reference" id="sync-summary-and-sync-flat-summary-reference">Sync Summary and Sync Flat Summary Reference</a></h1>
<ul>
<li><a href="datasets/obsolete/sync_summary/reference.html#introduction">Introduction</a>
<ul>
<li><a href="datasets/obsolete/sync_summary/reference.html#which-dataset-should-i-use">Which dataset should I use?</a></li>
</ul>
</li>
<li><a href="datasets/obsolete/sync_summary/reference.html#data-reference">Data Reference</a>
<ul>
<li><a href="datasets/obsolete/sync_summary/reference.html#a-note-about-user-ids">A note about user IDs</a></li>
<li><a href="datasets/obsolete/sync_summary/reference.html#which-apps-send-sync-telemetry-what-about-fenix">Which apps send sync telemetry? What about Fenix?</a></li>
<li><a href="datasets/obsolete/sync_summary/reference.html#whats-an-engine">What's an engine?</a></li>
<li><a href="datasets/obsolete/sync_summary/reference.html#example-queries">Example Queries</a></li>
<li><a href="datasets/obsolete/sync_summary/reference.html#sampling">Sampling</a></li>
<li><a href="datasets/obsolete/sync_summary/reference.html#scheduling">Scheduling</a></li>
<li><a href="datasets/obsolete/sync_summary/reference.html#sync-summary-schema">Sync Summary Schema</a></li>
<li><a href="datasets/obsolete/sync_summary/reference.html#sync-flat-summary-schema">Sync Flat Summary Schema</a></li>
</ul>
</li>
</ul>
<h1><a class="header" href="#introduction-27" id="introduction-27">Introduction</a></h1>
<p><em>Note: some of the information in this chapter is a duplication of the info found on <a href="https://wiki.mozilla.org/CloudServices/Sync/ReDash">this</a> wiki page. You can also find more detailed information about the data contained in the sync ping <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/sync-ping.html">here</a></em></p>
<p><code>sync_summary</code> and <code>sync_flat_summary</code> are the primary datasets that track the health of sync. <code>sync_flat_summary</code> is derived from <code>sync_summary</code> by unpacking/exploding the <code>engines</code> field of the latter, so they ultimately contain the same data (see below).</p>
<h2><a class="header" href="#which-dataset-should-i-use" id="which-dataset-should-i-use">Which dataset should I use?</a></h2>
<p>Which dataset to use depends on whether you are interested in <em>per-engine</em> sync success or <em>per-sync</em> sync success (see below). If you are interested in whether a sync failed overall, regardless of which engine may have caused the failure, then you can use <code>sync_summary</code>. Otherwise, if you are interested in per-engine data, you should use <code>sync_flat_summary</code>.</p>
<p>If you aren't sure, or just trying to get acquainted, you should probably just use <code>sync_flat_summary</code>.</p>
<h1><a class="header" href="#data-reference-25" id="data-reference-25">Data Reference</a></h1>
<h2><a class="header" href="#a-note-about-user-ids" id="a-note-about-user-ids">A note about user IDs</a></h2>
<p>Unlike most other telemetry datasets, these do not contain the profile-level identifier <code>client_id</code>. Because you need to sign up for a <a href="https://www.mozilla.org/en-US/firefox/accounts/">Firefox Account</a> in order to use sync, these datasets instead include an anonymised version of the user's Firefox Account user id <code>uid</code> and an anonymised version of their individual devices' <code>device_id</code>s. Put another way, each <code>uid</code> can have many associated <code>device_id</code>s.</p>
<p><strong>Q:</strong> Why not include <code>client_id</code> in these datasets so that they can be joined on (e.g.) <code>main_summary</code>?</p>
<p><strong>A:</strong> We've had a policy to keep main browser telemetry separate from sync and FxA telemetry. This is in part because FxA <code>uid</code>s are ultimately associated with email addresses in the FxA database, and thus a breach of that database in combination with access to telemetry could in theory de-anonymise client-side browser metrics.</p>
<h2><a class="header" href="#which-apps-send-sync-telemetry-what-about-fenix" id="which-apps-send-sync-telemetry-what-about-fenix">Which apps send sync telemetry? What about Fenix?</a></h2>
<p>Currently, Firefox for desktop, Firefox for iOS and Firefox for Android (fennec) all have sync implemented, and they all send sync telemetry. Though there are some differences in the telemetry that each application sends, it all ends up in the <code>sync_summary</code> and <code>sync_flat_summary</code> datasets.</p>
<p>Starting with Fenix, however, sync telemetry will start to be sent through <a href="https://github.com/mozilla-mobile/android-components/tree/master/components/service/glean">glean</a>. This means that, in all likelihood, Fenix sync telemetry will initially be segregated from existing sync telemetry (one reason is that current sync telemetry is on AWS while glean pings are ingested to GCP).</p>
<h2><a class="header" href="#whats-an-engine" id="whats-an-engine">What's an engine?</a></h2>
<p>Firefox syncs many different types of browser data and (generally speaking) each one of these data types are synced by their own engine. When the app triggers a &quot;sync&quot; each engine makes their own determination of what needs to be synced (if anything). Many syncs can happen in a day (dozens or more on desktop, usually less on mobile). Telemetry about each sync is logged, and each <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/sync-ping.html">sync ping</a> (sent once a day, and whenever the user logs in or out of sync) contains information about multiple syncs. The scala code responsible for creating the <code>sync_summary</code> dataset unpacks each sync ping into one row per sync. The resulting <code>engines</code> field is an array of &quot;engine records&quot;: data about how each engine performed during that sync. <code>sync_flat_summary</code> further unpacking/exploding the <code>engines</code> field and creates a dataset that is one row per engine record.</p>
<p>Existing engines (<code>engine_name</code> in <code>sync_flat_summary</code>) are listed below with brief descriptions in cases where their name isn't transparent.</p>
<p>Note that not every device syncs each of these engines. They can be disabled individually and some are off by default.</p>
<ul>
<li><code>addons</code></li>
<li><code>addresses</code> mailing addresses e.g. for e-commerce; part of form autofill.</li>
<li><code>bookmarks</code></li>
<li><code>clients</code> non-user-facing list of the sync account's associated devices</li>
<li><code>creditcards</code> this used to be nightly only but was recently removed entirely</li>
<li><code>extension-storage</code> WebExtension storage, in support of the <code>storage.sync</code> WebExtension API.</li>
<li><code>history</code> browsing history.</li>
<li><code>passwords</code></li>
<li><code>forms</code> saved values in web forms</li>
<li><code>prefs</code> not all prefs are synced</li>
<li><code>tabs</code> note that this is not the same as the &quot;send tab&quot; feature, this is the engine that syncs the tabs you have open across your devices (used to populate the synced tabs sidebar). For data on the send-tab feature use the <code>sync_events</code> dataset.</li>
</ul>
<h2><a class="header" href="#example-queries-17" id="example-queries-17">Example Queries</a></h2>
<p>See <a href="https://sql.telemetry.mozilla.org/dashboard/sync-leif-status-dashboard-wip">this dashboard</a> to get a general sense of what this dataset is typically used for.</p>
<p>Here's an example of a query that will calculate the failure and success rates for a subset of engines per day.</p>
<pre><code class="language-sql">WITH
    counts AS (
        SELECT
          submission_date_s3 AS day,
          engine_name AS engine,
          COUNT(*) AS total,
          COUNT(CASE WHEN engine_status IS NOT NULL THEN true ELSE NULL END) AS count_errors,
          /* note that `engine_status` is null on sync success. */  
          COUNT(CASE WHEN engine_status IS NULL THEN true ELSE NULL END) AS count_success
        FROM telemetry.sync_flat_summary
        WHERE engine_name IN ('bookmarks','history','tabs','addons','addresses','passwords','prefs')
        AND cast(submission_date_s3 AS integer) &gt;= 20190101
        GROUP BY 1,2
        ORDER BY 1
    ),

    rates AS (
        SELECT
          day,
          engine,
          total,
          count_errors,
          count_success,
          CAST(count_errors AS double) / CAST(total AS double) * 100 AS error_rate,
          CAST(count_success AS double) / CAST(total AS double) * 100 AS success_rate
        FROM counts
        ORDER BY 1
    )

SELECT * FROM rates
</code></pre>
<h2><a class="header" href="#sampling-8" id="sampling-8">Sampling</a></h2>
<p>Sadly, these datasets are not sampled. It should be possible to derive a <code>sample_id</code> on <code>uid</code>, however. Someone should do that because querying these datasets for long time horizons is very expensive.</p>
<h2><a class="header" href="#scheduling-21" id="scheduling-21">Scheduling</a></h2>
<p>This dataset was updated daily, shortly after midnight UTC.
The job was scheduled on <a href="https://github.com/mozilla/telemetry-airflow">Airflow</a>.
The DAG was <a href="https://github.com/mozilla/telemetry-airflow/blob/27d34a73db02131a39f469f3950c1da747bc8a95/dags/sync_view.py">here</a>.</p>
<h2><a class="header" href="#sync-summary-schema" id="sync-summary-schema">Sync Summary Schema</a></h2>
<pre><code>root
 |-- app_build_id: string (nullable = true)
 |-- app_display_version: string (nullable = true)
 |-- app_name: string (nullable = true)
 |-- app_version: string (nullable = true)
 |-- app_channel: string (nullable = true)
 |-- uid: string
 |-- device_id: string (nullable = true)
 |-- when: integer
 |-- took: integer
 |-- why: string (nullable = true)
 |-- failure_reason: struct (nullable = true)
 |    |-- name: string
 |    |-- value: string (nullable = true)
 |-- status: struct (nullable = true)
 |    |-- sync: string (nullable = true)
 |    |-- status: string (nullable = true)
 |-- devices: array (nullable = true)
 |    |-- element: struct (containsNull = false)
 |    |    |-- id: string
 |    |    |-- os: string
 |    |    |-- version: string
 |-- engines: array (nullable = true)
 |    |-- element: struct (containsNull = false)
 |    |    |-- name: string
 |    |    |-- took: integer
 |    |    |-- status: string (nullable = true)
 |    |    |-- failure_reason: struct (nullable = true)
 |    |    |    |-- name: string
 |    |    |    |-- value: string (nullable = true)
 |    |    |-- incoming: struct (nullable = true)
 |    |    |    |-- applied: integer
 |    |    |    |-- failed: integer
 |    |    |    |-- new_failed: integer
 |    |    |    |-- reconciled: integer
 |    |    |-- outgoing: array (nullable = true)
 |    |    |    |-- element: struct (containsNull = false)
 |    |    |    |    |-- sent: integer
 |    |    |    |    |-- failed: integer
 |    |    |-- validation: struct (containsNull = false)
 |    |    |    |-- version: integer
 |    |    |    |-- checked: integer
 |    |    |    |-- took: integer
 |    |    |    |-- failure_reason: struct (nullable = true)
 |    |    |    |    |-- name: string
 |    |    |    |    |-- value: string (nullable = true)
 |    |    |    |-- problems: array (nullable = true)
 |    |    |    |    |-- element: struct (containsNull = false)
 |    |    |    |    |    |-- name: string
 |    |    |    |    |    |-- count: integer
</code></pre>
<h2><a class="header" href="#sync-flat-summary-schema" id="sync-flat-summary-schema">Sync Flat Summary Schema</a></h2>
<pre><code>root
|-- app_build_id: string (nullable = true)
|-- app_display_version: string (nullable = true)
|-- app_name: string (nullable = true)
|-- app_version: string (nullable = true)
|-- app_channel: string (nullable = true)
|-- os: string
|-- os_version: string
|-- os_locale: string
|-- uid: string
|-- device_id: string (nullable = true)
|-- when: integer
|-- took: integer
|-- failure_reason: struct (nullable = true)
|    |-- name: string
|    |-- value: string (nullable = true)
|-- status: struct (nullable = true)
|    |-- sync: string (nullable = true)
|    |-- status: string (nullable = true)
|-- why: string (nullable = true)
|-- devices: array (nullable = true)
|    |-- element: struct (containsNull = false)
|    |    |-- id: string
|    |    |-- os: string
|    |    |-- version: string
|-- sync_id: string
|-- sync_day: string
|-- engine_name: string
|-- engine_took: integer
|-- engine_status: string (nullable = true)
|-- engine_failure_reason: struct (nullable = true)
|    |-- name: string
|    |-- value: string (nullable = true)
|-- engine_incoming_applied: integer (nullable = true)
|-- engine_incoming_failed: integer (nullable = true)
|-- engine_incoming_new_failed: integer (nullable = true)
|-- engine_incoming_reconciled: integer (nullable = true)
|-- engine_outgoing_batch_count: integer (nullable = true)
|-- engine_outgoing_batch_total_sent: integer (nullable = true)
|-- engine_outgoing_batch_total_failed: integer (nullable = true)
|-- submission_date_s3: string
</code></pre>
<h1><a class="header" href="#firefox-accounts-data" id="firefox-accounts-data">Firefox Accounts Data</a></h1>
<h2><a class="header" href="#table-of-contents-6" id="table-of-contents-6">Table of Contents</a></h2>
<ul>
<li><a href="datasets/fxa.html#introduction">Introduction</a></li>
<li><a href="datasets/fxa.html#what-is-firefox-accounts">What is Firefox Accounts?</a></li>
<li><a href="datasets/fxa.html#metrics-background">Metrics Background</a></li>
<li><a href="datasets/fxa.html#metrics-taxonomies">Metrics Taxonomies</a></li>
</ul>
<h2><a class="header" href="#introduction-28" id="introduction-28">Introduction</a></h2>
<p>This article provides an overview of Firefox Accounts metrics: what is measured and how. See the other articles in this chapter for more details about the specific measurements that are available for analysis.</p>
<h2><a class="header" href="#what-is-firefox-accounts" id="what-is-firefox-accounts">What is Firefox Accounts?</a></h2>
<p><a href="https://www.mozilla.org/en-US/firefox/accounts/">Firefox Accounts</a> is Mozilla's authentication solution for account-based end-user services and features. At the time of writing, sync is by far the most popular account-relying service. Below is a partial list of current FxA-relying services (by the time you are reading this others will likely have been added; we will endeavor to update the list periodically):</p>
<ul>
<li><a href="https://support.mozilla.org/en-US/kb/how-do-i-set-sync-my-computer">Sync</a>
<ul>
<li>Requires FxA.</li>
</ul>
</li>
<li><a href="https://send.firefox.com/">Firefox Send</a>
<ul>
<li>FxA Optional; Required to send large files.</li>
</ul>
</li>
<li><a href="https://lockwise.firefox.com/">Lockwise</a>
<ul>
<li>Requires FxA and sync.</li>
</ul>
</li>
<li><a href="https://addons.mozilla.org/en-US/firefox/">AMO</a>
<ul>
<li>For developer accounts; not required by end-users to use or download addons.</li>
</ul>
</li>
<li><a href="https://getpocket.com/login/?ep=1">Pocket</a>
<ul>
<li>FxA is an optional authentication method among others.</li>
</ul>
</li>
<li><a href="http://monitor.firefox.com/">Monitor</a>
<ul>
<li>Required to receive email alerts. Not required for email scans.</li>
</ul>
</li>
<li><a href="https://wiki.mozilla.org/IAM/Frequently_asked_questions">Mozilla IAM</a>
<ul>
<li>Optional authentication method among others.</li>
</ul>
</li>
</ul>
<p>A single account can be used to authenticate with all of the services listed above (though see the note below about Chinese users).</p>
<p>Note that in addition to being the most commonly used relier of FxA, sync is also unique in its integration with FxA - unlike the other reliers in the list above, sync is currently <strong>not</strong> an FxA oauth client. When someone signs into an oauth client using Firefox, nothing in the browser changes - more specifically, client-side telemetry probes such as <a href="https://telemetry.mozilla.org/probe-dictionary/?detailView=histogram%2FFXA_CONFIGURED"><code>FXA_CONFIGURED</code></a> do not change state. Thus at the present time the only way to measure usage of FxA oauth reliers is to use the FxA server-side measures described below.</p>
<p>One more thing: China runs its own stack for sync, but Chinese sign-ups for oauth reliers still go through the &quot;one and only&quot; oauth server. This means that Chinese users who want to use both sync and an oauth service (e.g. Monitor) will have to register for two accounts. It also means that only metrics for Chinese oauth users will show up in the datasets described below; any sync-related measures will not. At present, you must contact those responsible for maintaining the FxA stack in China for metrics on Chinese sync users.</p>
<h2><a class="header" href="#metrics-background" id="metrics-background">Metrics Background</a></h2>
<p>Unlike most telemetry described in these docs, FxA metrics are logged server-side. There are many <a href="https://github.com/mozilla/fxa/tree/master/packages">FxA &quot;servers&quot;</a> that handle different aspects of account authentication and management. The metrics of most interest to data analysts are logged by the FxA auth server, content server and oauth server. Each server writes their metrics into their log stream, and some post-processing scripts combine the metrics events from all three servers into datasets that are available in Databricks, BigQuery, STMO and Amplitude.</p>
<p>In general, metrics logged by the <a href="https://github.com/mozilla/fxa/tree/master/packages/fxa-auth-server">FxA auth server</a> reflect authentication events such as account creation, logins to existing accounts, etc.
Metrics logged by the <a href="https://github.com/mozilla/fxa/tree/master/packages/fxa-content-server">FxA content server</a> reflect user interaction and progression through the FxA web UI - form views, form engagement, form submission, etc.
The <a href="https://github.com/mozilla/fxa/pull/3176">FxA oauth server</a> logs metrics events when oauth clients (Monitor, Lockwise, etc) create and check authentication tokens.</p>
<h2><a class="header" href="#metrics-taxonomies" id="metrics-taxonomies">Metrics Taxonomies</a></h2>
<p>There are two overlapping taxonomies or sets of FxA event metrics.</p>
<p><a href="https://github.com/mozilla/fxa-auth-server/blob/master/docs/metrics-events.md"><strong>Flow Metrics</strong></a>: these are an older set of metrics events that can be queried through redshift and via the <code>FxA Activity Metrics</code> data source in re:dash. The <a href="https://github.com/mozilla/fxa-activity-metrics/">re:dash import jobs</a> are run once a day. See <a href="https://github.com/mozilla/fxa-auth-server/blob/master/docs/metrics-events.md">this documentation</a> for detailed description of the types of flow events that are logged and the tables that contain them (note this documentation does not contain an exhaustive list of all flow metrics but is generally still accurate about the ones that are described). Note there are 50% and 10% sampled versions of the major tables, which contain more historical data than their complete counterparts. Complete tables go back 3 months, 50% tables go back 6 months, and 10% tables go back 24 months. Sampling is done at the level of the FxA user id <code>uid</code> (i.e. integer(<code>uid</code>) % 100).</p>
<p><a href="https://analytics.amplitude.com/mozilla-corp/manage/project/178231/advanced/events"><strong>Amplitude Events</strong></a>: FxA started to send metrics events to amplitude circa October 2017. The <a href="https://github.com/mozilla/fxa-amplitude-send">code responsible for batching events to amplitude</a> over HTTP is run in more-or-less real-time. Amplitude events can be queried through the <a href="https://analytics.amplitude.com/mozilla-corp/space/vj9qof9">amplitude UI</a> as well as various tables in <a href="https://console.cloud.google.com/bigquery?project=moz-fx-data-derived-datasets">BigQuery</a> that maintain copies of the events that are sent to Amplitude. <a href="https://github.com/mozilla/bigquery-etl/blob/master/sql/telemetry/fxa_content_auth_events_v1/view.sql"><code>moz-fx-data-derived-datasets.telemetry.fxa_content_auth_events_v1</code></a> is probably the easiest BigQuery table to use, though it does not contain email bounce events and (at the time of writing) only contains data starting at 2019-03-01.</p>
<p>Note that the BigQuery <a href="https://github.com/mozilla/bigquery-etl/tree/master/sql">ETL jobs</a> run daily while real-time data is accessible through the amplitude UI.</p>
<p>FxA's amplitude metrics were originally just re-configured and re-named versions of the flow metrics. However things have since diverged a bit and there are now metrics events that only have an amplitude version but no corresponding flow event, and vice-versa. If you are wondering whether a certain event is logged its likely you will have to check both data sources.</p>
<p><strong>Generally speaking, one should first try to use the amplitude metrics rather than the flow events</strong> for these reasons:</p>
<ol>
<li>For quick answers to simple questions the amplitude UI is often more efficient than writing SQL.
<ul>
<li>The caveat here is that is can sometimes be <em>too</em> easy to build a chart in amplitude - it doesn't exactly encourage the careful consideration that having to write a query out by hand implicitly encourages.</li>
</ul>
</li>
<li>By-country data is currently not available in redshift.</li>
<li>There have been outages in the redshift data that have not affected the amplitude data.</li>
<li>Querying redshift is (generally) slower.</li>
</ol>
<p>It is also possible to query the FxA server logs directly through BigQuery (ask an FxA team member for access), though virtually all analytics-related questions are more easily answered using the data sources described above.</p>
<h1><a class="header" href="#attribution-of-firefox-accounts" id="attribution-of-firefox-accounts">Attribution of Firefox Accounts</a></h1>
<h2><a class="header" href="#table-of-contents-7" id="table-of-contents-7">Table of Contents</a></h2>
<ul>
<li><a href="datasets/fxa_metrics/attribution.html#introduction">Introduction</a></li>
<li><a href="datasets/fxa_metrics/attribution.html#types-of-attribution">Types of Attribution</a>
<ul>
<li><a href="datasets/fxa_metrics/attribution.html#service-attribution">Service Attribution</a></li>
<li><a href="datasets/fxa_metrics/attribution.html#funnel-attribution-entrypoint-and-utm-parameters">Funnel Attribution (entrypoint and utm parameters)</a></li>
</ul>
</li>
</ul>
<h2><a class="header" href="#introduction-29" id="introduction-29">Introduction</a></h2>
<p>Users can create or login to an account through an increasingly large number of relying services and entrypoints. This article describes how we attribute authentications to their point of origin, and documents some of the most frequently trafficked entrypoints (it would not be feasible to list them all, but we will try to update this document when there are substantial changes).</p>
<h2><a class="header" href="#types-of-attribution" id="types-of-attribution">Types of Attribution</a></h2>
<p>We can attribute accounts to the <strong>service</strong> that they sign up for, as well as the <strong>entrypoint</strong> that they use to begin the authentication flow. Each service typically has many entrypoints; sync, for example, has web-based entrypoints and browser-based entrypoints (see below).</p>
<h3><a class="header" href="#service-attribution" id="service-attribution">Service Attribution</a></h3>
<p>There is a variable called <code>service</code> that we use to (1) attribute users to the relying services of FxA that they have authenticated with and (2) attribute individual events to the services they are associated with. <strong>Except in the case of sync</strong>, <code>service</code> is a mapping from the oauth <code>client_id</code> of the relying service/product to a human readable string. Note that this mapping is currently maintained by hand, and is done after the events have been logged by the server. Currently, mapping to the human-readable <code>service</code> variable is only done for amplitude metrics, where it is treated as a user property. There is also a <code>service</code> variable in the <code>activity_events</code> and <code>flow_metadata</code> re:dash tables (FxA Activity Metrics data source), however it only contains the opaque oauth <code>client_id</code>, not the human-readable string. A table of some of the most common oauth <code>client_id</code>s along with their corresponding <code>service</code> mapping is shown below. This is not a complete list.</p>
<table><thead><tr><th><code>service</code></th><th>oauth <code>client_id</code></th><th>Description</th></tr></thead><tbody>
<tr><td><code>lockbox</code></td><td><code>e7ce535d93522896</code></td><td>Lockwise App for Android</td></tr>
<tr><td><code>lockbox</code></td><td><code>98adfa37698f255b</code></td><td>Lockwise App for iOS</td></tr>
<tr><td><code>fenix</code></td><td><code>a2270f727f45f648</code></td><td>Sync implementation for Fenix</td></tr>
<tr><td><code>fx-monitor</code></td><td><code>802d56ef2a9af9fa</code></td><td>Firefox Monitor (<a href="https://monitor.firefox.com/">website</a>)</td></tr>
<tr><td><code>send</code></td><td><code>1f30e32975ae5112</code></td><td>Firefox Send (<a href="https://send.firefox.com/">website</a>)</td></tr>
<tr><td><code>send</code></td><td><code>20f7931c9054d833</code></td><td>Firefox Send (android app)</td></tr>
<tr><td><code>pocket-mobile</code></td><td><code>7377719276ad44ee</code></td><td>Pocket Mobile App</td></tr>
<tr><td><code>pocket-web</code></td><td><code>749818d3f2e7857f</code></td><td>Pocket Website</td></tr>
<tr><td><code>firefox-addons</code></td><td><code>3a1f53aabe17ba32</code></td><td><code>addons.mozilla.org</code></td></tr>
<tr><td><code>amo-web</code></td><td><code>a4907de5fa9d78fc</code></td><td><code>addons.mozilla.org</code> (still unsure how this differs from <code>firefox-addons</code>)</td></tr>
<tr><td><code>screenshots</code></td><td><code>5e75409a5a3f096d</code></td><td>Firefox Screenshots (<a href="https://screenshots.firefox.com/">website</a>, no longer supported)</td></tr>
<tr><td><code>notes</code></td><td><code>a3dbd8c5a6fd93e2</code></td><td>Firefox Notes (desktop extension)</td></tr>
<tr><td><code>notes</code></td><td><code>7f368c6886429f19</code></td><td>Firefox Notes (android app)</td></tr>
<tr><td><code>fxa-content</code></td><td><code>ea3ca969f8c6bb0d</code></td><td>Oauth ID used when a user is signing in with cached credentials (i.e. does not have to re-enter username/password) and when the user is logging into the FxA settings page.</td></tr>
<tr><td><code>mozilla-email-preferences</code></td><td><code>c40f32fd2938f0b6</code></td><td>Oauth ID used when a user is signing in to modify their marketing email preferences (e.g., to opt-out.)</td></tr>
</tbody></table>
<p>In amplitude, there is also a <code>fxa_services_used</code> user property which maintains an array of all the services a user has authenticated with.</p>
<p>Some amplitude charts segmenting by service can be found <a href="https://analytics.amplitude.com/mozilla-corp/notebook/detelo9">here</a>.</p>
<h3><a class="header" href="#funnel-attribution-entrypoint-and-utm-parameters" id="funnel-attribution-entrypoint-and-utm-parameters">Funnel Attribution (entrypoint and utm parameters)</a></h3>
<p>We can also attribute users to where they began the authentication process, be it from a website or an application. Attribution is done through query parameters appended to links that point at <code>accounts.firefox.com</code> (which hosts the actual authentication process). These parameters are logged along with with any metrics events that the user generates during the authentication flow. The table below lists the query parameters that are currently in use, along with the values associated with some of the most common funnels. Note that only <code>entrypoint</code> is typically logged for flows beginning within the browser. Web-based entrypoints are listed first, followed by entrypoints that are found within the browser chrome itself.</p>
<p>See <a href="https://mozilla.github.io/application-services/docs/accounts/metrics.html">this documentation</a> for more implementational detail on utm/entrypoint parameters.</p>
<table><thead><tr><th><code>entrypoint</code></th><th>utm parameters</th><th>Description &amp; Notes</th></tr></thead><tbody>
<tr><td><code>activity-stream-firstrun</code></td><td><strong><code>utm_source</code></strong> = <code>activity-stream</code>, <strong><code>utm_campaign</code></strong> = <code>firstrun</code>, <strong><code>utm_medium</code></strong> = <code>referral</code> or <code>email</code></td><td>The <a href="about:welcome">about:welcome</a> page that is shown to new profiles on browser <code>firstrun</code>. <code>utm_term</code> is sometimes used to track variations for experiments.</td></tr>
<tr><td><code>firstrun</code> (not supported for current versions)</td><td><strong><code>utm_source</code></strong> = <code>firstrun</code></td><td>This is the old version of the <code>firstrun</code> page that was hosted on the web as part of mozilla.org (<a href="https://www.mozilla.org/en-US/firefox/62.0/firstrun/">example</a>). Starting with Firefox version 62, it was replaced by an in-browser version (see row above). Although it is not used for newer versions, it is still hosted for the sake of e.g. profiles coming through the dark funnel on older versions.</td></tr>
<tr><td><code>mozilla.org-whatsnewXX</code></td><td><strong><code>utm_source</code></strong> = <code>whatsnewXX</code>, <strong><code>utm_campaign</code></strong> = <code>fxa-embedded-form</code>, <strong><code>utm_content</code></strong> = <code>whatsnew</code>, <strong><code>utm_medium</code></strong> = <code>referral</code> or <code>email</code></td><td>Where <code>XX</code> = the browser version, e.g. 67 (<a href="https://www.mozilla.org/en-US/firefox/67.0.1/whatsnew/">example</a>). The &quot;what's new&quot; page that is shown to users after they upgrade browser versions. Important notes: <strong>(1)</strong> Users who are signed into a Firefox account have a different experience than those that are signed out. Signed-in users typically see a promotion of FxA-relying services, while signed-out users see a Call to Action to create an account. <strong>(2)</strong> The attribution parameters for this page were standardized starting on version 66. <strong>Previous values for entrypoint</strong> include <code>whatsnew</code> and <code>mozilla.org-wnp64</code> - these values should be used when doing historical analysis of versions prior to 66.</td></tr>
<tr><td><code>new-install-page</code> (current), <code>firefox-new</code> (previously)</td><td>varies (can contain values passed through by referrals)</td><td><a href="https://www.mozilla.org/en-US/firefox/new/">example</a>. The &quot;install Firefox&quot; page. This page doesn't always promote FxA and it will often only promote it to a certain % of traffic or to certain segments.</td></tr>
<tr><td><code>fxa-discoverability-native</code></td><td>NA</td><td>The in-browser toolbar icon. This was introduced with version 67.0</td></tr>
<tr><td><code>menupanel</code></td><td>NA</td><td>The in-browser account item in the &quot;hamburger&quot; menu on desktop (three-line menu in the upper right corner) as well as the sync/FxA menu item on android and iOS.</td></tr>
<tr><td><code>preferences</code></td><td>NA</td><td>The &quot;sign into sync&quot; button found in the sync section in desktop preferences.</td></tr>
<tr><td><code>synced-tabs</code></td><td>NA</td><td>The &quot;sign into sync&quot; button found in synced-tabs section under the library menu.</td></tr>
<tr><td><code>sendtab</code></td><td>NA</td><td>The &quot;sign into sync&quot; button found in the &quot;send tab to device&quot; menu accessible by right-clicking on a tab.</td></tr>
<tr><td><code>lockbox-addon</code></td><td>NA</td><td>The &quot;sign into sync&quot; button found within the the Lockwise desktop extension. This is likely to change once Lockwise becomes fully integrated into the browser.</td></tr>
</tbody></table>
<p>Example amplitude charts: <a href="https://analytics.amplitude.com/mozilla-corp/chart/1ush8xd">registrations by <code>entrypoint</code></a>, <a href="https://analytics.amplitude.com/mozilla-corp/chart/y8t2k1z">logins by <code>entrypoint</code></a>, <a href="https://analytics.amplitude.com/mozilla-corp/chart/jjbkusl">registrations by <code>utm_source</code></a>.</p>
<h1><a class="header" href="#firefox-account-funnels" id="firefox-account-funnels">Firefox Account Funnels</a></h1>
<h2><a class="header" href="#table-of-contents-8" id="table-of-contents-8">Table of Contents</a></h2>
<ul>
<li><a href="datasets/fxa_metrics/funnels.html#introduction">Introduction</a></li>
<li><a href="datasets/fxa_metrics/funnels.html#registration-funnel">Registration Funnel</a></li>
<li><a href="datasets/fxa_metrics/funnels.html#login-funnel">Login Funnel</a></li>
<li><a href="datasets/fxa_metrics/funnels.html#branches-off-the-login-funnel-password-reset-account-recovery-2fa">Branches off the Login Funnel: Password Reset, Account Recovery, 2FA.</a>
<ul>
<li><a href="datasets/fxa_metrics/funnels.html#password-reset-and-recovery-codes">Password Reset and Recovery Codes</a>
<ul>
<li><a href="datasets/fxa_metrics/funnels.html#password-reset-funnel-without-recovery-key">Password Reset Funnel Without Recovery Key</a></li>
<li><a href="datasets/fxa_metrics/funnels.html#password-reset-funnel-with-recovery-key">Password Reset Funnel With Recovery Key</a></li>
</ul>
</li>
<li><a href="datasets/fxa_metrics/funnels.html#login-with-2fa-totp">Login with 2FA (TOTP)</a>
<ul>
<li><a href="datasets/fxa_metrics/funnels.html#login-with-2fatotp-funnel-no-recovery-code">Login with 2FA/TOTP Funnel (No Recovery Code)</a></li>
<li><a href="datasets/fxa_metrics/funnels.html#login-with-2fatotp-funnel-w-recovery-code">Login with 2FA/TOTP Funnel w/ Recovery Code</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="datasets/fxa_metrics/funnels.html#connect-another-device--sms">Connect Another Device / SMS</a>
<ul>
<li><a href="datasets/fxa_metrics/funnels.html#sms-funnel">SMS Funnel</a></li>
<li><a href="datasets/fxa_metrics/funnels.html#connect-another-device-funnel-non-sms">Connect Another Device Funnel (Non-SMS)</a></li>
</ul>
</li>
<li><a href="datasets/fxa_metrics/funnels.html#settings">Settings</a></li>
</ul>
<h2><a class="header" href="#introduction-30" id="introduction-30">Introduction</a></h2>
<p>There are two primary &quot;funnels&quot; that users step through when authenticating with FxA. The <strong>registration</strong> funnel reflects the steps required for a <strong>new</strong> FxA user (or more precisely, email address) to create an account. The <strong>login</strong> funnel reflects the steps necessary for an <strong>existing</strong> FxA user to sign into their account.</p>
<p>We are also in the process of developing funnels for paying subscribers. We will add documentation on that once the work is is closer to complete.</p>
<h2><a class="header" href="#registration-funnel" id="registration-funnel">Registration Funnel</a></h2>
<p>While there are some variations, the typical registration funnel is comprised of the steps described in the chart below. Except where noted, these events are emitted by the FxA content server.</p>
<table><thead><tr><th>Step</th><th>Amplitude Event</th><th>Flow Event</th><th>Description</th></tr></thead><tbody>
<tr><td>1</td><td><code>fxa_email_first - view</code></td><td><code>flow.enter-email.view</code></td><td>View (impression) of the form that the user enters their email address into to start the process. Note that this form can be hosted by FxA, or hosted by the relying party. In the latter case, the relier is responsible for handing the user's email address off to the FxA funnel. See &quot;counting top of funnel events&quot; below.</td></tr>
<tr><td>2</td><td><code>fxa_reg - view</code></td><td><code>flow.signup.view</code></td><td>View of the registration form. If the user got to this step via step 1, FxA has detected that their email address is not present in the DB, and thus a new account can be created. The user creates their password and enters their age.</td></tr>
<tr><td>3</td><td><code>fxa_reg - engage</code></td><td><code>flow.signup.engage</code></td><td>A user focuses/clicks on one of the registration form fields.</td></tr>
<tr><td>4</td><td><code>fxa_reg - submit</code></td><td><code>flow.signup.submit</code></td><td>A user submits the registration form (could be unsuccessfully).</td></tr>
<tr><td>5</td><td><code>fxa_reg - created</code></td><td><code>account.created</code></td><td>This event is emitted by the auth server. It indicates that user has entered a valid email address and password, and that their account has been created and added to the DB. However, the account is still &quot;unverified&quot; at this point and therefore not accessible by the user.</td></tr>
<tr><td>6</td><td><code>fxa_email - sent</code> (<code>email_type</code> = <code>registration</code>)</td><td><code>email.verification.sent</code></td><td>An email is sent to the user to verify their new account. Depending on the service, it either contains a verification link or a verification code that the user enters into the registration form to verify their email address.</td></tr>
<tr><td>7</td><td><code>fxa_reg - cwts_view</code></td><td><code>flow.signup.choose-what-to-sync.view</code></td><td>User views the &quot;choose what to sync&quot; screen which allows the users to select what types of browser data they want to synchronize. <strong>Note that the user is not required to submit this page</strong> - if they do not take any action then all the data types will be synced by default. Thus you may not want to include this (and the following two events) in your funnel analysis if you do not care about the user's actions here.</td></tr>
<tr><td>8</td><td><code>fxa_reg - cwts_engage</code></td><td>Not Implemented</td><td>User clicks on the &quot;choose what to sync&quot; screen.</td></tr>
<tr><td>9</td><td><code>fxa_reg - cwts_submit</code></td><td>Not Implemented</td><td>User submits the &quot;choose what to sync&quot; screen. See also the amplitude user property <code>sync_engines</code> which stores which data types the user selected.</td></tr>
<tr><td>10</td><td><code>fxa_email - click</code></td><td><code>email.verify_code.clicked</code></td><td>A user has clicked on the verification link contained in the email sent in step 6. Note this only applies to cases where a clickable link is sent; for reliers that use activation codes, this event will not be emitted (so be aware of this when constructing your funnels).</td></tr>
<tr><td>11</td><td><code>fxa_reg - email_confirmed</code></td><td><code>account.verified</code></td><td>This event is emitted by the auth server. A user has successfully verified their account. They should now be able to use it.</td></tr>
<tr><td>12</td><td><code>fxa_reg - complete</code></td><td><code>flow.complete</code></td><td>The account registration process is complete. Note there are NO actions required of the user to advance from step 8 to step 9; there should be virtually no drop-off there. The flow event is identical for registration and login.</td></tr>
</tbody></table>
<p>See <a href="https://analytics.amplitude.com/mozilla-corp/chart/a9yjkzf">this chart</a> for an example of how this funnel can be constructed for the <code>firstrun</code> (about:welcome) page in amplitude. <a href="https://sql.telemetry.mozilla.org/queries/62595#160701">Here</a> is a version in re:dash using the flow events.</p>
<p>The chart above provides the most detailed version of the registration funnel that can currently be constructed. However, it should not be considered the &quot;canonical&quot; version of the funnel - depending on the question it may make sense to omit some of the steps. For example, at the time of writing some browser entrypoints (e.g. <code>menupanel</code>) link directly to step 2 and skip the initial email form. Having both steps 7 and 8 may also be redundant in some cases, etc. Also, as noted above, you may want to omit the &quot;choose what to sync&quot; steps if you do not care about the users' actions there.</p>
<h2><a class="header" href="#login-funnel" id="login-funnel">Login Funnel</a></h2>
<p>The login funnel describes the steps required for an existing FxA user to login to their account. With some exceptions, most of the steps here are parallel to the registration funnel (but named differently).</p>
<p>Users must confirm their login via email in the following cases:</p>
<ol>
<li>A user is logging into sync with an account that is more than 4 hours old.</li>
<li>A user is logging into an oauth relier that uses encryption keys (e.g., Firefox send), if the user had not logged into their account in the previous 72? (check this) hours.</li>
</ol>
<table><thead><tr><th>Step</th><th>Amplitude Event</th><th>Flow Event</th><th>Description</th></tr></thead><tbody>
<tr><td>1</td><td><code>fxa_email_first - view</code></td><td><code>flow.enter-email.view</code></td><td>Similar to the registration funnel, a view (impression) of the form that the user enters their email address into to start the process. Note that this form can be hosted by FxA, or hosted by the relying party. In the latter case, the relier is responsible for handing the user's email address off to the FxA funnel. See &quot;counting top of funnel events&quot; below.</td></tr>
<tr><td>2</td><td><code>fxa_login - view</code></td><td><code>flow.signin.view</code></td><td>View of the login form. If the user got to this step via step 1, FxA has detected that their email address IS present in the DB, and thus an existing account can be logged into. The user enters their password on this form.</td></tr>
<tr><td>3</td><td><code>fxa_login - engage</code></td><td><code>flow.signup.engage</code></td><td>A user focuses/clicks on the login form field</td></tr>
<tr><td>4</td><td><code>fxa_login - submit</code></td><td><code>flow.signup.submit</code></td><td>A user submits the login form (could be unsuccessfully).</td></tr>
<tr><td>5</td><td><code>fxa_login - success</code></td><td><code>account.login</code></td><td>This event is emitted by the auth server. It indicates that user has submitted the correct password. However, in some cases the user may still have to confirm their login via email (see above).</td></tr>
<tr><td>6</td><td><code>fxa_email - sent</code> (<code>email_type</code> = <code>login</code>)</td><td><code>email.confirmation.sent</code></td><td>An email is sent to the user to confirm the login. Depending on the service, it either contains a confirmation link or a verification code that the user enters into the login form.</td></tr>
<tr><td>7</td><td><code>fxa_email - click</code></td><td><code>email.verify_code.clicked</code></td><td>A user has clicked on the confirmation link contained in the email sent in step 6. Note this only applies to cases where a clickable link is sent; for reliers that use confirmation codes, this event will not be emitted (so be aware of this when constructing your funnels). Note that this event is identical to its counterpart in the registration funnel.</td></tr>
<tr><td>8</td><td><code>fxa_login - email_confirmed</code></td><td><code>account.confirmed</code></td><td>This event is emitted by the auth server. A user has successfully confirmed the login via email.</td></tr>
<tr><td>9</td><td><code>fxa_login - complete</code></td><td><code>flow.complete</code></td><td>The account registration process is complete. Note there are NO actions required of the user to advance from step 8 to step 9; there should be virtually no drop-off there. The flow event is identical for registration and login.</td></tr>
</tbody></table>
<p>See <a href="https://analytics.amplitude.com/mozilla-corp/chart/53dqtlo">this chart</a> for an example of how this funnel can be constructed for the <code>firstrun</code> (about:welcome) page. <a href="https://sql.telemetry.mozilla.org/queries/63048#161676">Here</a> is a version in re:dash using the flow events.</p>
<p>Note again that you may want to check whether the service you are analyzing requires email confirmation on login.</p>
<h2><a class="header" href="#branches-off-the-login-funnel-password-reset-account-recovery-2fa" id="branches-off-the-login-funnel-password-reset-account-recovery-2fa">Branches off the Login Funnel: Password Reset, Account Recovery, 2FA.</a></h2>
<p>Some additional funnels are &quot;branches&quot; off the main login funnel above:</p>
<ol>
<li>The password reset funnel</li>
</ol>
<ul>
<li>Optionally - the user resets their password with a recovery key</li>
</ul>
<ol start="2">
<li>Login with 2FA (TOTP)</li>
</ol>
<ul>
<li>Optionally - user uses a 2FA recovery code to login to their 2FA-enabled account (e.g. if they misplace their second factor.)</li>
</ul>
<h3><a class="header" href="#password-reset-and-recovery-codes" id="password-reset-and-recovery-codes">Password Reset and Recovery Codes</a></h3>
<p>Users can click &quot;Forgot Password?&quot; during sign-in to begin the password reset process. The funnel is described in the chart below.</p>
<p><strong>An important &quot;FYI&quot; here</strong>: passwords are used to encrypt accounts' sync data. This implies a <strong>bad scenario</strong> where a change of password can lead to loss of sync data, if there are no longer any devices that can connect to the account and re-upload/restore the data after the reset occurs. This would happen, for example, if you only had one device connected to sync, lost the device, then tried to login to a new device to access your synced data. If you do a password reset while logging into the second device, the remote copy of your sync data will be overwritten (with whatever happens to be on the second device).</p>
<p>Thus the recovery codes. If a user (1) sets up recovery codes via settings (and stores them somewhere accessible) (2) tries to reset their password and (3) enters a valid recovery code during the password reset process, sync data can be restored without risking the &quot;bad scenario&quot; above.</p>
<h4><a class="header" href="#password-reset-funnel-without-recovery-key" id="password-reset-funnel-without-recovery-key">Password Reset Funnel Without Recovery Key</a></h4>
<p><em>Note: There may be other places where a user can initiate the password reset process, but I think that its most common during login. In any case, the steps starting at 2 should all be the same.</em></p>
<table><thead><tr><th>Step</th><th>Amplitude Event</th><th>Flow Event</th><th>Description</th></tr></thead><tbody>
<tr><td>1</td><td><code>fxa_login - view</code></td><td><code>flow.signin.view</code></td><td>View of the login form, which contains the &quot;Forgot Password&quot; Link.</td></tr>
<tr><td>2</td><td><code>fxa_login - forgot_password</code></td><td><code>flow.signin.forgot-password</code></td><td>User clicks on the &quot;Forgot Password&quot; Link.</td></tr>
<tr><td>3</td><td>Not Implemented</td><td><code>flow.reset-password.view</code></td><td>View of the form asking the user to confirm that they want to reset.</td></tr>
<tr><td>4</td><td><code>fxa_login - forgot_submit</code></td><td><code>flow.reset-password.engage</code>, <code>flow.reset-password.submit</code></td><td>User clicks on the button confirming that they want to reset.</td></tr>
<tr><td>5</td><td><code>fxa_email - delivered</code> (<code>email_template</code> = <code>recoveryEmail</code>)</td><td><code>email.recoveryEmail.delivered</code></td><td>Delivery of the PW reset link to the user via email.</td></tr>
<tr><td>5-a</td><td>Not Implemented</td><td><code>flow.confirm-reset-password.view</code></td><td>View of the screen telling the user to confirm the reset via email.</td></tr>
<tr><td>6</td><td>Not Implemented</td><td><code>flow.complete-reset-password.view</code></td><td>User views the form to create a new password. (viewable after clicking the link in the email above)</td></tr>
<tr><td>7</td><td>Not Implemented</td><td><code>flow.complete-reset-password.engage</code></td><td>User clicks on the form to create a new password.</td></tr>
<tr><td>8</td><td>Not Implemented</td><td><code>flow.complete-reset-password.submit</code></td><td>User submits the form to create a new password.</td></tr>
<tr><td>9</td><td><code>fxa_login - forgot_complete</code></td><td><code>flow.complete</code> (the auth server also emits <code>account.reset</code>)</td><td>User has completed the password reset funnel.</td></tr>
</tbody></table>
<h4><a class="header" href="#password-reset-funnel-with-recovery-key" id="password-reset-funnel-with-recovery-key">Password Reset Funnel With Recovery Key</a></h4>
<p><em>Note we still need to implement amplitude events for the recovery code part of this funnel. The funnel is identical to the one above up until step 6.</em></p>
<table><thead><tr><th>Step</th><th>Amplitude Event</th><th>Flow Event</th><th>Description</th></tr></thead><tbody>
<tr><td>1</td><td><code>fxa_login - view</code></td><td><code>flow.signin.view</code></td><td>View of the login form, which contains the &quot;Forgot Password&quot; Link.</td></tr>
<tr><td>2</td><td><code>fxa_login - forgot_password</code></td><td><code>flow.signin.forgot-password</code></td><td>User clicks on the &quot;Forgot Password&quot; Link.</td></tr>
<tr><td>3</td><td>Not Implemented</td><td><code>flow.reset-password.view</code></td><td>View of the form asking the user to confirm that they want to reset.</td></tr>
<tr><td>4</td><td><code>fxa_login - forgot_submit</code></td><td><code>flow.reset-password.engage</code>, <code>flow.reset-password.submit</code></td><td>User clicks on the button confirming that they want to reset.</td></tr>
<tr><td>5</td><td><code>fxa_email - delivered</code> (<code>email_template</code> = <code>recoveryEmail</code>)</td><td><code>email.recoveryEmail.delivered</code></td><td>Delivery of the PW reset link to the user via email.</td></tr>
<tr><td>5-a</td><td>Not Implemented</td><td><code>flow.confirm-reset-password.view</code></td><td>View of the screen telling the user to confirm the reset via email.</td></tr>
<tr><td>6</td><td>Not Implemented</td><td><code>flow.account-recovery-confirm-key.view</code></td><td>User views the form to enter their account recovery key. (viewable after clicking the link in the email above)</td></tr>
<tr><td>7</td><td>Not Implemented</td><td><code>flow.account-recovery-confirm-key.engage</code></td><td>User clicks on the form to enter their account recovery key.</td></tr>
<tr><td>8</td><td>Not Implemented</td><td><code>flow.account-recovery-confirm-key.submit</code></td><td>User submits the form to enter their account recovery key.</td></tr>
<tr><td>9</td><td>Not Implemented</td><td><code>flow.account-recovery-confirm-key.success</code> or <code>flow.account-recovery-confirm-key.invalidRecoveryKey</code></td><td>User submitted a valid (success) or invalid recovery key.</td></tr>
<tr><td>10</td><td>Not Implemented</td><td><code>flow.account-recovery-reset-password.view</code></td><td>User views the form to change their password after submitting a valid recovery key.</td></tr>
<tr><td>11</td><td>Not Implemented</td><td><code>flow.account-recovery-reset-password.view</code></td><td>User clicks on the form to change their password after submitting a valid recovery key.</td></tr>
<tr><td>12</td><td>Not Implemented</td><td><code>flow.account-recovery-reset-password.view</code></td><td>User submits the form to change their password after submitting a valid recovery key.</td></tr>
<tr><td>13</td><td><code>fxa_login - forgot_complete</code></td><td><code>flow.complete</code> (the auth server also emits <code>account.reset</code>)</td><td>User has completed the password reset funnel.</td></tr>
</tbody></table>
<h3><a class="header" href="#login-with-2fa-totp" id="login-with-2fa-totp">Login with 2FA (TOTP)</a></h3>
<p>Users can setup two factor authentication (2FA) on account login. 2FA is implemented via time-based one-time password (TOTP). If a user has set up 2FA (via settings), they will be required to enter a pass code generated by their second factor whenever they login to their account.</p>
<p>Users are also provisioned a set of recovery codes as part of the 2FA setup process. These are one-time use codes that can be used to login to an account if a user loses access to their second factor. <strong>Note that these 2FA recovery codes are different than the account recovery keys described above</strong>.</p>
<h4><a class="header" href="#login-with-2fatotp-funnel-no-recovery-code" id="login-with-2fatotp-funnel-no-recovery-code">Login with 2FA/TOTP Funnel (No Recovery Code)</a></h4>
<p><em>This funnel starts after the <code>fxa_login - success</code> / <code>account.login</code> step of the login funnel</em></p>
<table><thead><tr><th>Step</th><th>Amplitude Event</th><th>Flow Event</th><th>Description</th></tr></thead><tbody>
<tr><td>1</td><td><code>fxa_login - totp_code_view</code></td><td><code>flow.signin-totp-code.view</code></td><td>View of the TOTP form.</td></tr>
<tr><td>2</td><td><code>fxa_login - totp_code_engage</code></td><td><code>flow.signin-totp-code.engage</code></td><td>Click on the TOTP form.</td></tr>
<tr><td>3</td><td><code>fxa_login - totp_code_submit</code></td><td><code>flow.signin-totp-code.submit</code></td><td>Submission of the TOTP form.</td></tr>
<tr><td>4</td><td><code>fxa_login - totp_code_success</code></td><td><code>flow.signin-totp-code.success</code></td><td>Successful submission of the TOTP form. Auth server also emits <code>totpToken.verified</code></td></tr>
</tbody></table>
<h4><a class="header" href="#login-with-2fatotp-funnel-w-recovery-code" id="login-with-2fatotp-funnel-w-recovery-code">Login with 2FA/TOTP Funnel w/ Recovery Code</a></h4>
<p><em>This funnel starts after user clicks to use a recovery code during the TOTP funnel.</em></p>
<table><thead><tr><th>Step</th><th>Amplitude Event</th><th>Flow Event</th><th>Description</th></tr></thead><tbody>
<tr><td>1</td><td><code>fxa_login - totp_code_view</code></td><td><code>flow.signin-totp-code.view</code></td><td>View of the TOTP form.</td></tr>
<tr><td>2</td><td>Not Implemented</td><td><code>flow.sign_in_recovery_code.view</code></td><td>View of the TOTP recovery code form.</td></tr>
<tr><td>3</td><td>Not Implemented</td><td><code>recoveryCode.verified</code> (auth server)</td><td>User submitted a valid recovery code.</td></tr>
</tbody></table>
<h2><a class="header" href="#connect-another-device--sms" id="connect-another-device--sms">Connect Another Device / SMS</a></h2>
<p>Sync is most valuable to users who have multiple devices connected to their account. Thus after a user completes a sync login or registration funnel, they are shown the &quot;connect another device&quot; form. This Call to Action contains a form for a phone number, as well as links to the Google Play and Apple stores where users can download mobile versions of Firefox. If a user submits a valid phone number (associated with a country that our service supports), then we send them an SMS message with links to their mobile phone's app store.</p>
<p>At one point, at least for iOS, the SMS message contained a deep link that pre-filled the user's email address on the sign-in form once they installed the mobile browser. There is some uncertainty about whether this still works...</p>
<h3><a class="header" href="#sms-funnel" id="sms-funnel">SMS Funnel</a></h3>
<p><em>This funnel begins either (1) after a user has completed the login or registration funnel, or (2) if they click on &quot;connect another device&quot; from the FxA toolbar menu within the desktop browser (provided they are signed in). In the latter case the <code>signin</code> segment of the flow event will be omitted.</em></p>
<table><thead><tr><th>Step</th><th>Amplitude Event</th><th>Flow Event</th><th>Description</th></tr></thead><tbody>
<tr><td>1</td><td><code>fxa_connect_device - view</code> (<code>connect_device_flow</code> = <code>sms</code>)</td><td><code>flow.signin.sms.view</code></td><td>User viewed the SMS form.</td></tr>
<tr><td>2</td><td><code>fxa_connect_device - engage</code> (<code>connect_device_flow</code> = <code>sms</code>)</td><td><code>flow.signin.sms.engage</code></td><td>User clicked somewhere on the SMS form.</td></tr>
<tr><td>3</td><td><code>fxa_connect_device - submit</code> (<code>connect_device_flow</code> = <code>sms</code>)</td><td><code>flow.signin.sms.submit</code></td><td>User submitted the SMS form.</td></tr>
<tr><td>4</td><td>Not Implemented</td><td><code>sms.region.{country_code}</code></td><td>An SMS was sent to a number with the two letter <code>country_code</code>.</td></tr>
<tr><td>5</td><td>Not Implemented</td><td><code>flow.sms.sent.view</code></td><td>User views the message confirming that the SMS has been sent.</td></tr>
</tbody></table>
<p>The SMS form also contains app store links. If they are clicked, flow events <code>flow.signin.sms.link.app-store.android</code> or <code>flow.signin.sms.link.app-store.ios</code> will be logged.</p>
<h3><a class="header" href="#connect-another-device-funnel-non-sms" id="connect-another-device-funnel-non-sms">Connect Another Device Funnel (Non-SMS)</a></h3>
<table><thead><tr><th>Step</th><th>Amplitude Event</th><th>Flow Event</th><th>Description</th></tr></thead><tbody>
<tr><td>1</td><td><code>fxa_connect_device - view</code> (<code>connect_device_flow</code> = <code>cad</code>)</td><td><code>flow.signin.connect-another-device.view</code></td><td>User viewed the CAD form.</td></tr>
<tr><td>2</td><td><code>fxa_connect_device - view</code> (<code>connect_device_flow</code> = <code>cad</code>)</td><td><code>flow.signin.connect-another-device.link.app-store.(android\|ios)</code></td><td>User clicked on either the android or iOS app store button. In amplitude, use the event property <code>connect_device_os</code> to disambiguate which link was clicked.</td></tr>
</tbody></table>
<h2><a class="header" href="#settings" id="settings">Settings</a></h2>
<p>A variety of metrics are logged that reflect user interaction with the settings page (https://accounts.firefox.com/settings). The chart below outlines some of these events (this may not be an exhaustive list).</p>
<table><thead><tr><th>Amplitude Event</th><th>Flow Event</th><th>Description</th></tr></thead><tbody>
<tr><td><code>fxa_pref - view</code></td><td><code>flow.settings.view</code></td><td>User viewed the settings page.</td></tr>
<tr><td><code>fxa_pref - engage</code></td><td><code>flow.settings.*.engage</code></td><td>User clicked somewhere on the settings page.</td></tr>
<tr><td><code>fxa_pref - two_step_authentication_view</code></td><td><code>flow.settings.two-step-authentication.view</code></td><td>User viewed 2FA settings.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.two-step-authentication.recovery-codes.view</code></td><td>User viewed their 2FA recovery codes. These are only viewable one time only, after a user sets up 2FA, or after they generate new codes.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.two-step-authentication.recovery-codes.print-option</code></td><td>User clicks to print their 2FA recovery codes.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.two-step-authentication.recovery-codes.download-option</code></td><td>User clicks to download their 2FA recovery codes.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.two-step-authentication.recovery-codes.copy-option</code></td><td>User clicks to copy their 2FA recovery codes to the clipboard (this is fired only when they click the copy button, not if they copy using e.g. a keyboard shortcut).</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.change-password.view</code></td><td>User viewed the form to change their password.</td></tr>
<tr><td><code>fxa_pref - password</code></td><td><code>settings.change-password.success</code></td><td>User changed their password via settings.</td></tr>
<tr><td><code>fxa_pref - newsletter</code> (see also user property <code>newsletter_state</code>)</td><td><code>settings.communication-preferences.(optIn\|optOut).success</code></td><td>User changed their newsletter email preferences.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.account_recovery.view</code></td><td>User viewed account recovery settings.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.account_recovery.engage</code></td><td>User clicked somewhere in account recovery settings.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.account-recovery.confirm-password.view</code></td><td>User viewed the password form prior to turning on account recovery. (user first has to verify their email address)</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.account-recovery.confirm-password.view</code></td><td>User clicked the password form prior to turning on account recovery.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.account-recovery.confirm-password.submit</code></td><td>User submitted the password form prior to turning on account recovery.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.account-recovery.confirm-password.success</code></td><td>User successfully submitted the password form prior to turning on account recovery.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.account-recovery.recovery-key.view</code></td><td>User viewed their recovery key. This is viewable one time only, after a user sets up account recovery, or after they generate a new key.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.account-recovery.recovery-key.print-option</code></td><td>User clicks to print their recovery key.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.account-recovery.recovery-key.download-option</code></td><td>User clicks to download their recovery key.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.account-recovery.recovery-key.copy-option</code></td><td>User clicks to copy their recovery key to the clipboard (this is fired only when they click the copy button, not if they copy using e.g. a keyboard shortcut).</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.account-recovery.refresh</code></td><td>User generated a new recovery key.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.clients.view</code></td><td>User viewed the list of clients (&quot;Devices &amp; Apps&quot;) connected to their account. AKA the device manager.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.clients.engage</code></td><td>User clicked somewhere the list of clients connected to their account.</td></tr>
<tr><td>Not Implemented</td><td><code>flow.settings.clients.disconnect.view</code></td><td>User viewed the dialog asking to confirm disconnection of a device.</td></tr>
</tbody></table>
<h1><a class="header" href="#fxa-email-metrics" id="fxa-email-metrics">FxA Email Metrics</a></h1>
<h2><a class="header" href="#table-of-contents-9" id="table-of-contents-9">Table of Contents</a></h2>
<ul>
<li><a href="datasets/fxa_metrics/emails.html#introduction">Introduction</a></li>
<li><a href="datasets/fxa_metrics/emails.html#email-templates-and-email-types">Email Templates and Email Types</a></li>
</ul>
<h2><a class="header" href="#introduction-31" id="introduction-31">Introduction</a></h2>
<p>Users must provide an email address when they sign up for a Firefox Account. Emails are sent to users to confirm authentication, alert them to new sign-ins, and to complete password resets. Users can also opt-in to marketing emails, however metrics for those are not covered in this article.</p>
<p>Events that we track relating to email:</p>
<ol>
<li>When the email is sent.</li>
<li>If the email bounces.</li>
<li>If the email contains a verification/confirmation link, whether the user clicked on it.</li>
</ol>
<p>Metrics relating to emails also contain the following properties:</p>
<ol>
<li>The email service of the recipient</li>
<li>The <code>email_template</code> - the <a href="https://github.com/mozilla/fxa/tree/master/packages/fxa-auth-server/lib/senders/templates">template</a> of the email that was sent (we currently only track this for sending events, not click events). This is more specific than the</li>
<li><code>email_type</code>, which is broader grouping of many email templates into related categories, see chart below.</li>
</ol>
<h2><a class="header" href="#email-templates-and-email-types" id="email-templates-and-email-types">Email Templates and Email Types</a></h2>
<p>Only emails sent by the FxA auth server are represented in the table below. TBD on marketing emails.</p>
<table><thead><tr><th><code>email_template</code></th><th><code>email_type</code></th><th>Description &amp; Notes</th></tr></thead><tbody>
<tr><td><code>verifySyncEmail</code></td><td><code>registration</code></td><td>Sent to users setting up a new sync account. Contains a verification link (user must click it for their account to become functional).</td></tr>
<tr><td><code>verifyEmail</code></td><td><code>registration</code></td><td>Sent to users setting up a new NON-sync account. Contains a verification link (user must click it for their account to become functional).</td></tr>
<tr><td><code>postVerifyEmail</code></td><td><code>registration</code></td><td>Sent after users confirm their email. Contains instructions for how to connect another device to sync.</td></tr>
<tr><td><code>verifyTrailheadEmail</code></td><td><code>registration</code></td><td>Updated version of <code>verifySyncEmail</code> for the trailhead promotion.</td></tr>
<tr><td><code>postVerifyTrailheadEmail</code></td><td><code>registration</code></td><td>Updated version of <code>postVerifyEmail</code> for the trailhead promotion.</td></tr>
<tr><td><code>verificationReminderFirstEmail</code></td><td><code>registration</code></td><td>If a users does not verify their account within 24 hours, they receive this email with an additional verification link.</td></tr>
<tr><td><code>verificationReminderSecondEmail</code></td><td><code>registration</code></td><td>If a users does not verify their account within 48 hours, they receive this email with an additional verification link.</td></tr>
<tr><td><code>verifyLoginEmail</code></td><td><code>login</code></td><td>Sent to existing accounts when they try to login to sync. User must click the verification link before the logged-in device can begin syncing.</td></tr>
<tr><td><code>newDeviceLoginEmail</code></td><td><code>login</code></td><td>Sent to existing accounts after they have logged into a device that FxA has not previously recognized.</td></tr>
<tr><td><code>verifyLoginCodeEmail</code></td><td><code>login</code></td><td>Sent to existing accounts when they try to login to sync, containing a code (rather than a link) the user must enter into the login form. Note that currently the use of confirmation codes is limited to some login contexts only - they are never used for registration.</td></tr>
<tr><td><code>recoveryEmail</code></td><td><code>reset_password</code></td><td>After a user opts to reset their password (during login, because they clicked &quot;forgot password&quot;), they receive this email with a link to reset their password (without using a recovery key).</td></tr>
<tr><td><code>passwordResetEmail</code></td><td><code>reset_password</code></td><td>Sent to users after they reset their password (without using a recovery key).</td></tr>
<tr><td><code>postAddAccountRecoveryEmail</code></td><td><code>account_recovery</code></td><td>Sent to users after they successfully add account recovery capabilities to their account (i.e. after generating recovery codes).</td></tr>
<tr><td><code>postRemoveAccountRecoveryEmail</code></td><td><code>account_recovery</code></td><td>Sent to users after they successfully REMOVE account recovery capabilities from their account.</td></tr>
<tr><td><code>passwordResetAccountRecoveryEmail</code></td><td><code>account_recovery</code></td><td>After a user resets their password using a recovery key, they receive this email telling them to generate a new recovery key.</td></tr>
<tr><td><code>passwordChangedEmail</code></td><td><code>change_password</code></td><td>Sent to users after they change their password via FxA settings (NOT during password reset; they must be logged in to do this).</td></tr>
<tr><td><code>verifyPrimaryEmail</code></td><td><code>verify</code></td><td>Sent to users when they request to change their primary email address via settings (is sent to their new email).</td></tr>
<tr><td><code>postChangePrimaryEmail</code></td><td><code>change_email</code></td><td>Sent to users after they successfully change their primary email address (is sent to their new email).</td></tr>
<tr><td><code>verifySecondaryEmail</code></td><td><code>secondary_email</code></td><td>Sent to users when they add a secondary email address via account settings. Contains a verification link (sent to the secondary email address).</td></tr>
<tr><td><code>postVerifySecondaryEmail</code></td><td><code>secondary_email</code></td><td>Sent to users after they successfully verified a secondary email address (sent to the secondary email address).</td></tr>
<tr><td><code>postRemoveSecondaryEmail</code></td><td><code>secondary_email</code></td><td>Sent to users after they successfully remove a secondary email address (sent to the secondary email address).</td></tr>
<tr><td><code>postAddTwoStepAuthenticationEmail</code></td><td><code>2fa</code></td><td>Sent to users after they successfully add 2 factor authentication to their account (TOTP)</td></tr>
<tr><td><code>postRemoveTwoStepAuthenticationEmail</code></td><td><code>2fa</code></td><td>Sent to users after they successfully REMOVE 2 factor authentication from their account (TOTP)</td></tr>
<tr><td><code>postConsumeRecoveryCodeEmail</code></td><td><code>2fa</code></td><td>Sent to users after they successfully use a recovery code to login to their account after not being able to use their second factor.</td></tr>
<tr><td><code>postNewRecoveryCodesEmail</code></td><td><code>2fa</code></td><td>Sent to users after they successfully generate a new set of 2FA recovery codes.</td></tr>
<tr><td><code>lowRecoveryCodesEmail</code></td><td><code>2fa</code></td><td>Sent when a user is running low on 2FA recovery codes.</td></tr>
</tbody></table>
<h1><a class="header" href="#telemetry-reference" id="telemetry-reference">Telemetry Reference</a></h1>
<h1><a class="header" href="#a-brief-history-of-firefox-data-collection" id="a-brief-history-of-firefox-data-collection">A brief history of Firefox data collection</a></h1>
<blockquote>
<p>This section was originally included in the <a href="https://mozilla-private.report/smoot-existing-metrics/book/05_overview.html">Project Smoot existing metrics report</a>
(Mozilla internal link).</p>
</blockquote>
<h2><a class="header" href="#blocklistxml-and-active-daily-installs-adi" id="blocklistxml-and-active-daily-installs-adi"><code>blocklist.xml</code> and Active Daily Installs (ADI)</a></h2>
<p>The <a href="https://wiki.mozilla.org/Blocklisting">blocklist</a> is a mechanism
for informing Firefox clients about malicious add-ons, DLLs, and other
extension content that should be blocked. The blocklist also notes when
hardware acceleration features should be avoided on certain graphics
cards. To be effective, the blocklist needs to be updated on a faster
cadence than Firefox releases.</p>
<p>The blocklist was <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=271166">first
implemented</a> in
2006 for Firefox 2, and reported the app ID and version to the blocklist
server.</p>
<p>Several additional variables, including OS version, locale, and
distribution, were <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=430120">added to the
URL</a> for Firefox 3
in 2008. Being able to count users was already expressed as a priority
in the bug comments.</p>
<p>A count of blocklist fetches was used to produce a metric called Active
Daily Users, which was <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=812282">renamed to Active Daily
Installs</a> (ADI) by
2012.</p>
<p>Work is underway to replace <code>blocklist.xml</code> with a <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1257565#c120">Remote
Settings-based</a>
replacement, though work is blocked because of the risk of interrupting
ADI measurement.</p>
<p>ADI is described in more detail in the next chapter.</p>
<h2><a class="header" href="#telemetry" id="telemetry">Telemetry</a></h2>
<p>The <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=585196">earliest telemetry
infrastructure</a>
landed in Firefox 6, and was driven <a href="https://wiki.mozilla.org/Platform/Features/Telemetry">by engineering
needs</a>.</p>
<p>Telemetry was originally opt-out on the nightly and aurora channels, and
opt-in otherwise. It originally lacked persistent client identifiers.</p>
<h2><a class="header" href="#firefox-health-report" id="firefox-health-report">Firefox Health Report</a></h2>
<p>The Firefox Health Report (FHR) was specified to enable longitudinal and
retention analyses. FHR aimed to enable analyses that were not possible
based on the blocklist ping, update ping, telemetry, Test Pilot and
crash stats datasets that were already available.</p>
<p>FHR was <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=718066">first
implemented</a> in
Firefox 20. It was introduced in blog posts by <a href="https://blog.lizardwrangler.com/2012/09/21/firefox-health-report/">Mitchell
Baker</a>
and <a href="https://blog.mozilla.org/metrics/2012/09/21/firefox-health-report/">Gilbert
Fitzgerald</a>.</p>
<p>To avoid introducing a persistent client identifier, FHR originally
relied on a document ID system. The client would generate a new UUID
(a random, unique ID) for each FHR document, and remember a list of its
most recent previous document IDs. While uploading a new FHR document,
the client would ask the server to remove its previous documents. The
intent was that the server would end up holding at most one document
from each user, and longitudinal metrics could be accumulated by the
client. This approach proved fragile and was abandoned. A <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=968419">persistent
client identifier</a>
was implemented for Firefox 30.</p>
<h2><a class="header" href="#firefox-desktop-telemetry-today" id="firefox-desktop-telemetry-today">Firefox Desktop Telemetry today</a></h2>
<p>FHR was retired and merged with telemetry to produce the current
generation of telemetry data, distinguished as v4 telemetry or
unified telemetry.</p>
<p>Instead of mapping FHR probes directly to telemetry, the <a href="https://docs.google.com/document/d/1IGpzsYGi_sq3YFQDAPyKOkU_BKvXAC95fZYA2i4ceVs/edit">unified
telemetry design
document</a>
describes how unified telemetry can answer the questions Mozilla had
attempted to answer with FHR. The <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1122515">implementation of unified
telemetry</a> and
opt-out delivery to the release channel was completed for Firefox 42, in
2015.</p>
<p>Telemetry payloads are uploaded in documents called pings. Several kinds
of pings are defined, representing different kinds of measurement. These
include:</p>
<ul>
<li><code>main</code>: activity, performance, technical, and other measurements;
the workhorse of Firefox desktop telemetry</li>
<li><code>crash</code>: information about crashes, including stack traces</li>
<li><code>opt-out</code>: a farewell ping sent when a user disables telemetry</li>
<li><code>module</code>: on Windows, records DLLs injected into the Firefox process</li>
</ul>
<p>and others.</p>
<p>Browser sessions and subsessions are important concepts in telemetry. A
<strong>session</strong> begins when the browser launches and endsperhaps seconds or
days later when the parent browser process terminates.</p>
<p>A <strong>subsession</strong> ends</p>
<ul>
<li>when its parent session ends, or</li>
<li>at local midnight, or</li>
<li>when the telemetry environment changes,</li>
</ul>
<p>whichever comes first.</p>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/environment.html">telemetry
environment</a>
describes the hardware and operating system of the client computer. It
can change during a Firefox session when e.g.hardware is plugged into a
laptop.</p>
<p>The subsession is the reporting unit for activity telemetry; each <code>main</code>
ping describes a single subsession. Activity counters are reset once a
subsession ends. Data can be accumulated for analysis by summing over a
clients pings.</p>
<p>Telemetry pings can contain several different types of measurements:</p>
<ul>
<li>scalars are integers describing either an event count or a
measurement that occurs only once during a subsession;
<code>simpleMeasurement</code>s are an older, less flexible scalar
implementation in the process of being deprecated</li>
<li>histograms represent measurements that can occur repeatedly during a
subsession; histograms report the count of measurements that fell
into each of a set of predefined buckets (e.g.between zero and one,
between one and two, etc).</li>
<li>events represent discrete events; the time and ordering of the
events are preserved, which clarifies sequences of user actions</li>
</ul>
<p>Data types are discussed in more depth in the <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/collection/index.html">telemetry data
collection</a>
documentation.</p>
<h2><a class="header" href="#firefox-desktop-telemetry-the-next-generation" id="firefox-desktop-telemetry-the-next-generation">Firefox Desktop Telemetry: The Next Generation</a></h2>
<p>The next step for Firefox Desktop Telemetry is to prototype an implementation
using <a href="concepts/glean/glean.html">Glean</a>.</p>
<p>This effort is known as &quot;Firefox on Glean&quot; or FOG. This effort is expected to
begin in late 2019 / early 2020.</p>
<h1><a class="header" href="#profile-behavior" id="profile-behavior">Profile behavior</a></h1>
<h2><a class="header" href="#a-hrefconceptsprofileprofile_creationhtmlprofile-creationa" id="a-hrefconceptsprofileprofile_creationhtmlprofile-creationa"><a href="concepts/profile/profile_creation.html">Profile Creation</a></a></h2>
<h2><a class="header" href="#a-hrefconceptsprofilerealworldusagehtmlreal-world-usagea" id="a-hrefconceptsprofilerealworldusagehtmlreal-world-usagea"><a href="concepts/profile/realworldusage.html">Real World Usage</a></a></h2>
<h2><a class="header" href="#a-hrefconceptsprofileprofilehistoryhtmlprofile-historya" id="a-hrefconceptsprofileprofilehistoryhtmlprofile-historya"><a href="concepts/profile/profilehistory.html">Profile History</a></a></h2>
<h1><a class="header" href="#profile-creation---the-technical-part" id="profile-creation---the-technical-part">Profile Creation - The technical part</a></h1>
<ul>
<li><a href="concepts/profile/profile_creation.html#what-is-a-profile">What is a profile?</a></li>
<li><a href="concepts/profile/profile_creation.html#profile-behaviors">Profile Behaviors</a>
<ul>
<li><a href="concepts/profile/profile_creation.html#profile-creation">Profile Creation</a>
<ul>
<li><a href="concepts/profile/profile_creation.html#managed-first-use">Managed: First use</a></li>
<li><a href="concepts/profile/profile_creation.html#managed-profile-manager-creation">Managed: Profile Manager creation</a></li>
<li><a href="concepts/profile/profile_creation.html#unmanaged-command-line-start">Unmanaged: Command-line start</a></li>
</ul>
</li>
<li><a href="concepts/profile/profile_creation.html#profile-reset">Profile Reset</a></li>
<li><a href="concepts/profile/profile_creation.html#profile-deletion">Profile Deletion</a></li>
<li><a href="concepts/profile/profile_creation.html#telemetry-opt-out">Telemetry opt-out</a></li>
</ul>
</li>
<li><a href="concepts/profile/profile_creation.html#profile-creation-date">Profile Creation Date</a>
<ul>
<li><a href="concepts/profile/profile_creation.html#managed-during-profile-creation">Managed: During Profile Creation</a></li>
<li><a href="concepts/profile/profile_creation.html#unmanaged-empty-profile-directory">Unmanaged: Empty profile directory</a></li>
</ul>
</li>
</ul>
<h2><a class="header" href="#what-is-a-profile" id="what-is-a-profile">What is a profile?</a></h2>
<p>All of the changes a user makes in Firefox, like the home page, what toolbars you use, installed addons, saved passwords and your bookmarks, are all stored in a special folder, called a profile.
Telemetry stores archived and pending pings in the profile directory as well as metadata like the client ID.</p>
<p>Every run of Firefox needs a profile. However a single installation can use multiple profiles for different runs.
The profile folder is stored in a separate place from the Firefox program so that, if something ever goes wrong with Firefox, the profile information will still be there.</p>
<p>Firefox also comes with a Profile Manager, a different run mode to create, migrate and delete the profiles.</p>
<h2><a class="header" href="#profile-behaviors" id="profile-behaviors">Profile Behaviors</a></h2>
<p>In order to understand the behavior of users and base analysis on things like the profile creation date,
it is essential to understand how a profile is created and identified by the browser.
Also, it is important to understand how user actions with and within profiles affect our ability to reason about profiles from a data perspective.
This includes resetting or deleting profiles or opting into or out of sending Telemetry data.</p>
<p>The different cases are described in more detail in the following sections.</p>
<h3><a class="header" href="#profile-creation" id="profile-creation">Profile Creation</a></h3>
<p>There are multiple ways a Firefox profile can be created.
Some of these behave slightly differently.</p>
<p>Profiles can be created and managed by the Firefox Profile Manager:</p>
<ul>
<li>New profile on first launch</li>
<li>New profile from Profile Manager</li>
<li><code>--createprofile</code> command line argument</li>
</ul>
<p>Profiles can be created externally and not be managed by the Firefox Profile Manager:</p>
<ul>
<li><code>--profile</code> command line argument</li>
</ul>
<h4><a class="header" href="#managed-first-use" id="managed-first-use">Managed: First use</a></h4>
<p>When Firefox is opened for the first time after a fresh install, without any prior Firefox profile on disk visible to Firefox, it will create a new profile.
Firefox uses &quot;Default User&quot; as the profile name, creates the profile's directory with a random suffix and marks the new profile as default for subsequent starts of Firefox.
Read <a href="https://support.mozilla.org/en-US/kb/profiles-where-firefox-stores-user-data">where Firefox stores your profile data</a>.</p>
<h4><a class="header" href="#managed-profile-manager-creation" id="managed-profile-manager-creation">Managed: Profile Manager creation</a></h4>
<p>The user can create a new profile through the Profile Manager.
This can either be done on <code>about:profiles</code> in a running Firefox or by starting Firefox with the <code>--ProfileManager</code> flag.
The Profile Manager will ask for a name for the profile and picks a new directory for it.
The Profile Manager allows the user to create a new profile from an existing directory (in which case any files will be included) or from scratch (in which case the directory will be created).</p>
<p>The <code>--createprofile</code> flag can be used from the command line and works the same as creating a profile through the Profile Manager.</p>
<h4><a class="header" href="#unmanaged-command-line-start" id="unmanaged-command-line-start">Unmanaged: Command-line start</a></h4>
<p>Firefox can be started on the command line with a path to a profile directory: <code>firefox --profile path/to/directory</code>.
If the directory does not exist it will be created.</p>
<p>A profile created like this will not be picked up by the Profile Manager.
Its data will persist after Firefox is closed, but the Profile Manager will not know about it.
The profile will not turn up in <code>about:profiles</code>.</p>
<h3><a class="header" href="#profile-reset" id="profile-reset">Profile Reset</a></h3>
<p>A user can reset the profile (see <a href="https://support.mozilla.org/en-US/kb/refresh-firefox-reset-add-ons-and-settings">Refresh Firefox - reset addons and settings</a>).
This will copy over most user data to a new directory, keeping things like the history, bookmarks and cookies, but will remove extensions, modified preferences and added search engines.</p>
<p>A profile reset will not change the Telemetry <code>clientID</code>.
The date of the most recent profile reset is saved and will be contained in Telemetry pings in the <code>profile.resetDate</code> field.</p>
<h3><a class="header" href="#profile-deletion" id="profile-deletion">Profile Deletion</a></h3>
<p>A profile can be deleted through the Profile Manager, which will delete all stored data from disk.
The profile can also be deleted by simply removing the profile's directory.
We will never know about a deletion. We simply won't see that profile in new Telemetry data anymore.</p>
<p>Uninstalling the Firefox installation will not remove any profile data.</p>
<p><strong>Note:</strong> Removing a profile's directory while it is in use is not recommended and will lead to a corrupt state.</p>
<h3><a class="header" href="#telemetry-opt-out" id="telemetry-opt-out">Telemetry opt-out</a></h3>
<p>The user can opt out of sending Telemetry data.
When the user opts out, Telemetry sends a <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/data/deletion-request-ping.html">&quot;deletion-request&quot; ping</a>, containing an empty payload.
The local <code>clientID</code> is reset to a fixed value.</p>
<p>When a user opts into sending Telemetry data, a new <code>clientID</code> is generated and used in subsequent pings.
The profile itself and the profile creation date are unaffected by this.</p>
<h2><a class="header" href="#profile-creation-date" id="profile-creation-date">Profile Creation Date</a></h2>
<p>The <em>profile creation date</em> is the assumed date of initial profile creation.
However it proved to be not reliable for all cases.
There are multiple ways this date is determined.</p>
<h3><a class="header" href="#managed-during-profile-creation" id="managed-during-profile-creation">Managed: During Profile Creation</a></h3>
<p>When a profile is created explicitly the profile directory is created and a <code>times.json</code> containing a timestamp of the current time is stored inside that profile directory<sup class="footnote-reference"><a href="#1">1</a></sup>.
It is read at later times when the profile creation date is used.</p>
<pre class="mermaid">graph TD
A[Start Firefox] -->B[Select profile dir, default or defined]
B --> C{Selected dir exist?}
C --> |No| D[Create directory]
C --> |Yes| E[Write times.json]
D --> E
E --> F[Show Browser]
F --> G[ProfileAge.jsm is called]
G --> J[Read time from times.json]
J --> S[Return creation date]
</pre>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>Relevant parts in the code: <a href="https://searchfox.org/mozilla-central/rev/292d295d6b084b43b70de26a42e68513bb7b36a3/toolkit/xre/nsAppRunner.cpp#2394-2395,2397-2398,2527-2533"><code>nsAppRunner::SelectProfile</code></a> calling <a href="https://searchfox.org/mozilla-central/rev/196560b95f191b48ff7cba7c2ba9237bba6b5b6a/toolkit/profile/nsToolkitProfileService.cpp#789-793"><code>nsToolkitProfileService::CreateProfile</code></a>.</p>
</div>
<h3><a class="header" href="#unmanaged-empty-profile-directory" id="unmanaged-empty-profile-directory">Unmanaged: Empty profile directory</a></h3>
<p>When <code>--profile path/to/directory</code> is passed on the command line, the directory is created if it does not exist, but no <code>times.json</code> is written<sup class="footnote-reference"><a href="#2">2</a></sup>.
On the first access of the profile creation date (through <code>ProfileAge.jsm</code>) the module will detect that the <code>times.json</code> is missing.
It will then iterate through all files in the current profile's directory, reading file creation or modification timestamps.
The oldest of these timestamps is then assumed to be the profile creation date and written to <code>times.json</code>.
Subsequent runs of Firefox will then use this date.</p>
<pre class="mermaid">graph TD
A[Start Firefox --profile path/to/dir] -->H{path/to/dir exist?}
H --> |No| K[Create directory]
K --> F[Show Browser]
H --> |Yes| F
F --> O[ProfileAge.jsm is called]
O --> R{times.json exists?}
R -->|Yes| Q[Read time from times.json]
R -->|No| L[Scan profile dir for oldest file, write to times.json]
L --> S
Q --> S[Return creation date]
</pre>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p>Relevant part in the code: <a href="https://searchfox.org/mozilla-central/rev/292d295d6b084b43b70de26a42e68513bb7b36a3/toolkit/xre/nsAppRunner.cpp#2357-2363"><code>nsAppRunner::SelectProfile</code></a> creating the directory.</p>
</div>
<h1><a class="header" href="#real-world-usage" id="real-world-usage">Real World Usage</a></h1>
<p>This page backs away from our profile-focused data view and examines what Firefox Desktop usage looks like in the real world. There are many components and layers that exist between a user acquiring and running Firefox, and this documentation will illuminate what those are and how they can affect the meaning of a profile.</p>
<h2><a class="header" href="#real-life-components-of-firefox-desktop-usage" id="real-life-components-of-firefox-desktop-usage">Real Life Components of Firefox Desktop Usage</a></h2>
<p><img src="concepts/profile/images/real-life-usage-components.png" alt="" /></p>
<p>The above image illustrates all the layers that sit between a user acquiring and running Firefox Desktop and the Telemetry pings we receive.</p>
<ul>
<li>1: The user
<ul>
<li>A human being presumably.</li>
</ul>
</li>
<li>2: The machine
<ul>
<li>The physical hardware running Firefox.</li>
</ul>
</li>
<li>3: The disk image / hard drive
<ul>
<li>A single machine could have separate partitions running different OSes.</li>
<li>Multiple machines could run copies of a single disk image</li>
<li>Disk images are also used as backups to restore a machine.</li>
</ul>
</li>
<li>4: OS user profile
<ul>
<li>Most operating systems allow users to log into different user profiles with separate user directories (such as a &quot;Guest&quot; account).</li>
<li>Usually, Firefox is installed into a system directory that all users profiles will share, but Firefox profiles are saved within the user directories, effectively segregating them.</li>
</ul>
</li>
<li>5: Firefox binary / installer
<ul>
<li>The downloaded binary package or stub installer which installs Firefox into the disk image. Users can get these from our website or one of our managed properties, but they can also acquire these from 3rd party sources as well.</li>
<li>Our website is instrumented with Google Analytics to track download numbers, but other properties (FTP) and 3rd party sources are not. Google Analytics data is not directly connected to Telemetry data.</li>
<li>A user can produce multiple installations from a single Firefox binary / installer. For example, if a user copies it to a USB stick or keeps it in cloud storage, they could install Firefox on multiple machines from a single binary / installer.</li>
</ul>
</li>
<li>6: Firefox installation
<ul>
<li>The installed Firefox program on a given disk image.</li>
<li>Since Firefox is usually installed in a system directory, the single installation of Firefox will be shared by all the OS user profiles in the disk image.</li>
<li>Stub installers are instrumented with pings to report new install counts, however, full binaries are not.</li>
</ul>
</li>
<li>7: Firefox profile
<ul>
<li>The profile Firefox uses during a user's session.</li>
<li>A user can create multiple Firefox profiles using the Firefox Profile Manager, or by specifying a custom directory to use at startup. More details <a href="concepts/profile/profile_creation.html">here</a>.</li>
<li>This is the entity that we see in Telemetry. Profiles send pings to Telemetry with a client ID as its identifier.</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#desktop-browser-use-cases" id="desktop-browser-use-cases">Desktop Browser Use Cases</a></h2>
<p>Below are the rough categories of Firefox use cases that we know happen in the real world.</p>
<p>Note, these categories are rough approximations, and are not necessarily mutually exclusive.</p>
<h4><a class="header" href="#regular-user" id="regular-user">Regular User</a></h4>
<p>What we imagine a typical user to be. Someone who buys a computer, always uses a default OS user profile, downloads Firefox once, installs it, and continues using the default Firefox profile.</p>
<p><img src="concepts/profile/images/regular-user.png" alt="" /></p>
<p>In Telemetry, this user would just show up as a single client ID.</p>
<p>Assuming they went through our normal funnel, they should show up once in Google Analytics as a download and once in stub installer pings as a new installation (if they used a stub installer).</p>
<h4><a class="header" href="#multi-profile-user" id="multi-profile-user">Multi-Profile User</a></h4>
<p>A more advanced user, who uses multiple Firefox profiles in their normal, everyday use, but otherwise is pretty 'normal' (uses the same OS user profile, etc.).</p>
<p><img src="concepts/profile/images/multi-profile-user.png" alt="" /></p>
<p>In Telemetry, this user would show up as 2 (or more) separate client IDs.
We would have no way to know they came from the same computer and user without identifying that the subsessions are never overlapping and that large portions of the environment (CPU, GPU, Displays) are identical and that would be no guarantee.</p>
<p>Assuming they went through our normal funnel, they would show up once in Google Analytics as a download and once in stub installer pings as a new installation (if they used a stub installer).</p>
<p>However, any subsequent new Firefox profile creations would not have any corresponding downloads or installations.
Since Firefox 55 however, any newly created profile will send a &quot;new-profile&quot; ping.</p>
<h4><a class="header" href="#shared-computer" id="shared-computer">Shared Computer</a></h4>
<p>A situation where there is a computer that is shared across multiple users and each user uses a different OS user profile. Since Firefox profiles live at the user directory level, each user would have a separate Firefox profile. Note, users logging in under a &quot;Guest&quot; account in most machines falls into this category.</p>
<p><img src="concepts/profile/images/shared-computer.png" alt="" /></p>
<p>In this case, every user who logged into this one computer with a different OS user profile would show up as a different client ID. We have no way of knowing they came from the same computer.</p>
<p>Furthermore, if the computer wiped the user directory after use, like Guest accounts and university computer labs often do, then they would show up as a <strong>new</strong> client ID every time they logged in, even if they have used the same computer multiple times. This use case could inflate new profile counts.</p>
<p>Similar to Multi-Profile Users, in this use case, there would be only one download event and install event (assuming normal funnel and stub installer), but multiple client ID's.</p>
<h4><a class="header" href="#cloned-machines" id="cloned-machines">Cloned Machines</a></h4>
<p>In this case, there are actually multiple users with computers that all share the same disk image at some point.</p>
<p>Think of the situation where the IT staff sets up the computer for a new hire at a company. Instead of going through to trouble of installing all the required programs and setting them up correctly for each computer, they'll do it once on one computer, save the disk image, and simply copy it over each time they need to issue a new machine.</p>
<p>Or think of the case where the IT staff of a library needs to set up 2 dozen machines at once.</p>
<p><img src="concepts/profile/images/cloned-machines.png" alt="" /></p>
<p>In this case, depending on the state of the disk image when it was copied, we could see multiple client ID's for each user+machine, or we could see all the user+machines sharing the same client ID.</p>
<p>If the disk image was copied after a Firefox profile was created, then the old user+machine and new user+machine will share the same client ID, and be submitting pings to us concurrently.</p>
<p>If the disk image was copied after the Firefox installation but before an initial Firefox profile was created, then each user+machine will get their own Firefox profile and client ID when they run Firefox for the first time.</p>
<p>As with the Multi-Profile User and Shared Computer case, even though there could be multiple Firefox profiles in this use case, there will only be one download and install event.</p>
<h4><a class="header" href="#migrations" id="migrations">Migrations</a></h4>
<h5><a class="header" href="#type-1-migrate-disk-image" id="type-1-migrate-disk-image">Type 1: Migrate Disk Image</a></h5>
<p>A user has a backup of their disk image and when they switch to a new computer or their current computer crashes, they simply reboot from the old disk image.</p>
<p><img src="concepts/profile/images/migration-1.png" alt="" /></p>
<p>In this case, the old machine and the new machine will just share the same client ID (assuming that the disk was copied after a Firefox profile was created). In fact, it will look exactly like the Cloned Machines case, except that instead of sending pings concurrently, they'll be sending us pings first from the old machine and then from the new machine.</p>
<p>Also, it should be noted that their Firefox profile will 'revert' back to the state that it was in when the disk image was copied, essentially starting over from the past, and any unsent pings on the image (if they exist) will be resent.
For instance, we will see another ping with the <code>profile_subsession_count</code> (the count of how many subsessions a profile has seen in its history) we previously saw some time before.</p>
<p>Again, there will only be one download and install associated with this use case (assuming normal funnel and stub installer).</p>
<h5><a class="header" href="#type-2-migrate-os-user-directory" id="type-2-migrate-os-user-directory">Type 2: Migrate OS User Directory</a></h5>
<p>A user has a backup of their OS user directory and copies it to a new machine.</p>
<p><img src="concepts/profile/images/migration-2.png" alt="" /></p>
<p>This is similar to Type 1 migration, but instead of copying the entire disk, the user only copies the OS user directory. Since the Firefox profile lives in the OS user directory, the old machine and new machine will share the same client ID.</p>
<p>The only difference is since the Firefox Installation lives in system directories, the client might have to re-download and re-install the browser. However, if they also copy the Firefox binary / installer, there will not be a download event, only an install event.</p>
<h5><a class="header" href="#type-3-migrate-firefox-binary--installer" id="type-3-migrate-firefox-binary--installer">Type 3: Migrate Firefox Binary / Installer</a></h5>
<p>A user has the Firefox binary or installer saved on their old machine and copies it over to a new machine to install Firefox.</p>
<p><img src="concepts/profile/images/migration-3.png" alt="" /></p>
<p>In this case, there will not be a second download event, but there will be an install event and the new and old machines will have separate client ID's.</p>
<h5><a class="header" href="#type-4-migrate-firefox-profile" id="type-4-migrate-firefox-profile">Type 4: Migrate Firefox Profile</a></h5>
<p>A user copies their old Firefox profile from their old machine to a new computer, and runs Firefox using the copied Firefox profile.</p>
<p><img src="concepts/profile/images/migration-4.png" alt="" /></p>
<p>In this case, since the Firefox profile is being copied over, both the new and the old machine will have profiles with the same client ID. Again, the profile on the new computer will revert back to the point in its history where it was copied.
And since the profile contains any unsent Telemetry pings, we may receive duplicated submissions of pings from the same client ID.</p>
<p>If the Firefox binary / installer was downloaded, there will be a download and install event. If it was migrated via USB stick, it will only have an install event.</p>
<h1><a class="header" href="#profile-history" id="profile-history">Profile History</a></h1>
<p>A profile's history is simply the progression of that profile's subsessions over its lifetime. We can see this in our main pings by checking:</p>
<ul>
<li><code>profile_subsession_counter</code>
<ul>
<li>A counter which starts at 1 on the very first run of a profile and increments for each subsession. This counter will be reset to 1 if a user resets / refreshes their profile.</li>
</ul>
</li>
<li><code>subsession_start_date</code>
<ul>
<li>The date and time the subsession starts in, truncated to hours. This field is not always reliable due to local clock skew.</li>
</ul>
</li>
<li><code>previous_subsession_id</code>
<ul>
<li>The ID of the previous subsession. Will be <code>null</code> for the very first subsession, or the first subsession after a user resets / refreshes their profile.</li>
</ul>
</li>
<li><code>subsession_id</code>
<ul>
<li>The ID of the current subsession.</li>
</ul>
</li>
<li><code>submission_date_s3</code>
<ul>
<li>The date we received the ping. This date is sourced from the server's time and reliable.</li>
</ul>
</li>
<li><code>profile_reset_date</code>
<ul>
<li>The date the profile was reset. Will be <code>null</code> if the profile was not reset.</li>
</ul>
</li>
</ul>
<p><img src="concepts/profile/images/profile-history/basic-example.png" alt="" /></p>
<p>This is a nice clean example of profile history. It has a clear <strong>starting ping</strong> and it progresses linearly, with each subsession connecting to the next via <code>subsession_id</code>. However, due to the fact that profiles can be shared across machines, and restored manually, etc. strange behaviors can arise (see <a href="concepts/profile/realworldusage.html">Real World Usage</a>).</p>
<h2><a class="header" href="#profile-history-start-conditions" id="profile-history-start-conditions">Profile History Start Conditions</a></h2>
<p>Under normal assumptions, we expect to see the <strong>starting ping</strong> in a profile's history in our telemetry data. The starting ping in the profile's history is the ping from their very first subsession. We expect this ping to have <code>profile_subsession_counter = 1</code> and <code>previous_subsession_id is null</code> and <code>profile_reset_date is null</code>.</p>
<p>However, not all profiles appear in our data with a starting ping and instead appear to us mid-history.</p>
<p><img src="concepts/profile/images/profile-history/ping-diagram-start-condition.png" alt="" /></p>
<h4><a class="header" href="#history-has-beginning" id="history-has-beginning">History Has Beginning</a></h4>
<p><img src="concepts/profile/images/profile-history/example-starting.png" alt="" /></p>
<p>As you can see, this profile starts with a ping where <code>profile_subsession_counter = 1</code> and <code>previous_subsession_id is null</code>.</p>
<h4><a class="header" href="#history-has-no-beginning" id="history-has-no-beginning">History Has No Beginning</a></h4>
<p><img src="concepts/profile/images/profile-history/example-midhistory.png" alt="" /></p>
<p>In this example, the profile simply appears in our data mid-history, with presumably the 25th subsession in it's history. Its previous history is a mystery.</p>
<h2><a class="header" href="#profile-history-progression-events" id="profile-history-progression-events">Profile History Progression Events</a></h2>
<p>After a profile appears, in 'normal' conditions, there should be a linear, straightforward progression with each subsession linking to the next.</p>
<p><img src="concepts/profile/images/profile-history/ping-diagram-events.png" alt="" /></p>
<p>However, the following abnormal events can occur.</p>
<h4><a class="header" href="#history-gap" id="history-gap">History Gap</a></h4>
<p>There is a gap in the profile history.</p>
<p>It's possible this behavior is due to dropped pings.</p>
<p><img src="concepts/profile/images/profile-history/example-gap.png" alt="" /></p>
<p>Here, we see a gap between the 30th ping and the 41st ping and the 44th ping.</p>
<h4><a class="header" href="#history-splits" id="history-splits">History Splits</a></h4>
<p>The history of a profile splits, and after a single subsession, there are two (or more) subsessions that link back to it.</p>
<p>This is probably due to cloned machines or disk image restores. Note, after the profile splits, the two branches might continue concurrently or one branch might die while the other continues.
It is very hard to distinguish between the different branches of the same profile.</p>
<ul>
<li>Profile begins</li>
</ul>
<p><img src="concepts/profile/images/profile-history/example-splits-1.png" alt="" /></p>
<ul>
<li>Profile splits: branch 1</li>
</ul>
<p><img src="concepts/profile/images/profile-history/example-splits-2.png" alt="" /></p>
<ul>
<li>Profile splits: branch 2</li>
</ul>
<p><img src="concepts/profile/images/profile-history/example-splits-3.png" alt="" /></p>
<p>In this example, the profile history starts normally, but on the 5th ping, the history splits into two branches that seem to progress concurrently.</p>
<h4><a class="header" href="#history-restarts" id="history-restarts">History Restarts</a></h4>
<p>The history of a profile suddenly starts over, with a brand new starting ping.</p>
<ul>
<li>Profile begins</li>
</ul>
<p><img src="concepts/profile/images/profile-history/example-restart-1.png" alt="" /></p>
<ul>
<li>Profile restarts</li>
</ul>
<p><img src="concepts/profile/images/profile-history/example-restart-2.png" alt="" /></p>
<p>Here, we see the profile start their history normally, but then they begin a new, totally unconnected branch with a starting ping that is <strong>not</strong> the same as the original starting ping (different <code>subsession_id</code>s).</p>
<h4><a class="header" href="#history-reruns" id="history-reruns">History Reruns</a></h4>
<p><a href="https://github.com/mozilla/firefox-data-docs/issues/169">(Work in Progress)</a></p>
<h2><a class="header" href="#how-to-order-history" id="how-to-order-history">How to Order History</a></h2>
<p><a href="https://github.com/mozilla/firefox-data-docs/issues/170">(Work in Progress)</a></p>
<h1><a class="header" href="#channel-behavior" id="channel-behavior">Channel Behavior</a></h1>
<h1><a class="header" href="#telemetry-channel-behavior" id="telemetry-channel-behavior">Telemetry Channel Behavior</a></h1>
<p>In every ping there are two channels:</p>
<ul>
<li>App Update Channel</li>
<li>Normalized Channel</li>
</ul>
<h2><a class="header" href="#expected-channels" id="expected-channels">Expected Channels</a></h2>
<p>The traditional channels we expect are:</p>
<ul>
<li><code>release</code></li>
<li><code>beta</code></li>
<li><code>aurora</code> (this is <code>dev-edition</code>, and <a href="https://developer.mozilla.org/en-US/Firefox/Developer_Edition">is just a beta repack</a>)</li>
<li><code>nightly</code></li>
<li><code>esr</code></li>
</ul>
<h2><a class="header" href="#app-update-channel" id="app-update-channel">App Update Channel</a></h2>
<p>This is the channel reported by the application directly.
This could really be anything, but is usually one of the expected release channels listed above.</p>
<p>For BigQuery tables corresponding to Telemetry Ping types, such as <code>main</code>, <code>crash</code> or <code>event</code>,
the field here is called <code>app_update_channel</code> and is found in <code>metadata.uri</code>. For example:</p>
<pre><code>SELECT
  metadata.uri.app_update_channel
FROM
  telemetry.main
WHERE
  DATE(submission_timestamp) = '2019-09-01'
LIMIT
  10
</code></pre>
<h2><a class="header" href="#normalized-channel" id="normalized-channel">Normalized Channel</a></h2>
<p>This field is a normalization of the directly reported channel, and replaces unusual
and unexpected values with the string <code>Other</code>.
There are a couple of exceptions, notably that variations on <code>nightly-cck-*</code> become <code>nightly</code>.
<a href="https://github.com/mozilla/gcp-ingestion/blob/92ba503c4debc887e746d5f2ff5ee60becb8072f/ingestion-beam/src/main/java/com/mozilla/telemetry/transforms/NormalizeAttributes.java#L38">See the relevant code here</a>.</p>
<p>Normalized channel is available in the Telemetry Ping tables as a top-level field
called <code>normalized_channel</code>.
For example:</p>
<pre><code>SELECT
  normalized_channel
FROM
  telemetry.crash
WHERE
  DATE(submission_timestamp) = '2019-09-01'
LIMIT
  10
</code></pre>
<h2><a class="header" href="#censuses" id="censuses">Censuses</a></h2>
<blockquote>
<p>This section was originally included in the <a href="https://mozilla-private.report/smoot-existing-metrics/book/05_overview.html">Project Smoot existing metrics report</a>
(Mozilla internal link).</p>
</blockquote>
<p>ADI and DAU are oft-discussed censuses. This chapter discusses their history and definition.</p>
<h3><a class="header" href="#adi--active-daily-installs-blocklist-fetches" id="adi--active-daily-installs-blocklist-fetches">ADI / Active Daily Installs (blocklist fetches)</a></h3>
<p>ADI, one of Firefoxs oldest client censuses, is computed as the number
of conforming requests to the Firefox
<a href="https://wiki.mozilla.org/Blocklisting">blocklist</a> endpoint. ADI data is
available since July 13, 2008.</p>
<p>It is not possible to opt-out of the blocklist using the Firefox UI, but
users can disable the update mechanism by changing preference values.</p>
<p>A blocklist is shipped in each release and updated when Firefox notices
that more than 24 hours have elapsed since the last update.</p>
<p>The blocklist request does not contain the telemetry <code>client_id</code> or any
other persistent identifiers. Some data about the install are provided
as URI parameters:</p>
<ul>
<li>App ID</li>
<li>App version</li>
<li>Product name</li>
<li>Build ID</li>
<li>Build target</li>
<li>Locale</li>
<li>Update channel</li>
<li>OS version</li>
<li>Distribution</li>
<li>Distribution version</li>
<li>Number of pings sent by this client for this version of Firefox
(stored in the pref <code>extensions.blocklist.pingCountVersion</code>)</li>
<li>Total ping count (stored in the pref
<code>extensions.blocklist.pingCountTotal</code>)</li>
<li>Number of full days since last ping</li>
</ul>
<p>so subsets of ADI may be queried along these dimensions.</p>
<p>The blocklist is kept up-to-date locally using the <code>UpdateTimerManager</code>
facility; the update is scheduled in a <a href="https://searchfox.org/mozilla-central/rev/b36e97fc776635655e84f2048ff59f38fa8a4626/toolkit/mozapps/extensions/extensions.manifest#1">manifest</a> and performed by
<a href="https://searchfox.org/mozilla-central/rev/b36e97fc776635655e84f2048ff59f38fa8a4626/toolkit/mozapps/extensions/Blocklist.jsm#569"><code>Blocklist#notify</code></a>.</p>
<p>Upon browser startup, after a delay (30 seconds by default),
<code>UpdateTimerManager</code> checks whether any of its scheduled tasks are
ready. At each wakeup, the single most-overdue task is triggered, if one
exists. <code>UpdateTimerManager</code> then sleeps at least two minutes or until
the next task is scheduled.</p>
<p>Failures are ignored.</p>
<p>A visualization of real and detrended ADI is available at
<a href="https://strategy-and-insights.mozilla.com/dailyUsageSignals/adiDetails.html">Desktop API Details: Long-term trend and decomposition</a>.
The raw data is available in BigQuery (see an example <a href="https://sql.telemetry.mozilla.org/queries/66481">ADI query in Redash</a>).</p>
<p>Telemetry only reports whether blocklist checking is enabled or disabled
on the client; there is no data in telemetry about blocklist fetches,
age, or update failures.</p>
<h3><a class="header" href="#dau--daily-active-users" id="dau--daily-active-users">DAU / Daily Active Users</a></h3>
<p>Firefox DAU is currently computed as the number of unique <code>client_id</code>s
observed in <code>main</code> pings received on a calendar day. The DAU count
excludes users who have <a href="https://support.mozilla.org/en-US/kb/share-data-mozilla-help-improve-firefox">opted out of telemetry</a>.</p>
<p>Each <code>main</code> ping describes a single subsession of browser activity.</p>
<p>When and how a ping is sent depends on the reason the subsession ends:</p>
<div id="tbl:pingreasons">
<table style="width:99%;">
<caption>Table 1: When <code>main</code> pings are sent, and why.</caption>
<colgroup>
<col style="width: 9%" />
<col style="width: 7%" />
<col style="width: 7%" />
<col style="width: 75%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Reason</th>
<th style="text-align: left;">Trigger</th>
<th style="text-align: left;">Percent of subsessions [1]</th>
<th style="text-align: left;">Mechanism</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>shutdown</code></td>
<td style="text-align: left;">Browser is closed</td>
<td style="text-align: left;">77%</td>
<td style="text-align: left;">For Firefox 55 or later, sent by <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/internals/pingsender.html"><code>Pingsender</code></a> on browser close unless the OS is shutting down. Otherwise, sent by <a href="https://searchfox.org/mozilla-central/rev/532e4b94b9e807d157ba8e55034aef05c1196dc9/toolkit/components/telemetry/app/TelemetrySend.jsm#677">`TelemetrySendImpl.setup`</a> on the following browser launch.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>environment-change</code></td>
<td style="text-align: left;">The telemetry environment changed</td>
<td style="text-align: left;">13%</td>
<td style="text-align: left;">Sent when change is detected by <a href="https://searchfox.org/mozilla-central/rev/532e4b94b9e807d157ba8e55034aef05c1196dc9/toolkit/components/telemetry/pings/TelemetrySession.jsm#1510">`TelemetrySession._onEnvironmentChange`</a></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>daily</code></td>
<td style="text-align: left;">more than 24 hours have elapsed since the last ping was sent and the time is local midnight</td>
<td style="text-align: left;">8%</td>
<td style="text-align: left;">Sent at local midnight after a random 0-60 min delay</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>aborted-session</code></td>
<td style="text-align: left;">A session terminates uncleanly (e.g.crash or lost power)</td>
<td style="text-align: left;">3%</td>
<td style="text-align: left;">Sent by the browser on the next launch; the payload to send is <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/concepts/crashes.html">written to disk every 5 minutes</a> during an active session and removed by a clean shutdown</td>
</tr>
</tbody>
</table>
</div>
<h3><a class="header" href="#coverage-pings" id="coverage-pings">Coverage pings</a></h3>
<p>The <a href="https://firefox-source-docs.mozilla.org/toolkit/components/telemetry/telemetry/data/coverage-ping.html">coverage ping</a>
(<a href="https://blog.mozilla.org/data/2018/08/20/effectively-measuring-search-in-firefox/">announcement</a>)
is a periodic census intended to estimate telemetry opt-out rates.</p>
<p>We estimate that <a href="https://metrics.mozilla.com/%7Erharter/reports/coverage/index.html">93% of release channel
profiles</a>
have telemetry enabled (and are therefore included in DAU).</p>
<h1><a class="header" href="#engagement-metrics" id="engagement-metrics">Engagement metrics</a></h1>
<blockquote>
<p>This section was originally included in the <a href="https://mozilla-private.report/smoot-existing-metrics/book/05_overview.html">Project Smoot existing metrics report</a>
(Mozilla internal link).</p>
</blockquote>
<p>A handful of metrics have been adopted as engagement metrics, either as
censuses of the population or to describe user activity within a
session. This chapter aims to describe what those metrics are and how
theyre defined.</p>
<h2><a class="header" href="#engagement-metrics-1" id="engagement-metrics-1">Engagement metrics</a></h2>
<h3><a class="header" href="#active_ticks" id="active_ticks"><code>active_ticks</code></a></h3>
<p>The <code>active_ticks</code> probe <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1187069#c6">is
specified</a> to
increment once in every 5-second window that a user performs an action
that could interact with content or chrome, including mousing over the
window while it lacks focus. One additional tick is recorded after the
activity stops.</p>
<p>Main pings provide two measurements of <code>active_ticks</code>: a
<code>simpleMeasurement</code> and a scalar.</p>
<p>The <code>simpleMeasurement</code> was <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1106122">implemented in Firefox
37</a> before the
launch of unified telemetry, and had previously been
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=826893">implemented</a> for
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=827157">FHR</a>.</p>
<p>The <code>simpleMeasurement</code> was discovered to be resetting incorrectly,
which was <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1482466">fixed</a>
in Firefox 62.</p>
<p>The scalar (which was not affected by the same bug) was
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1376942">implemented</a> in
Firefox 56. The scalar is aggregated into <code>main_summary</code>, but should
always be identical to the <code>simpleMeasurement</code>.</p>
<h3><a class="header" href="#subsession_length" id="subsession_length"><code>subsession_length</code></a></h3>
<p><code>subsession_length</code> is the wall-clock duration of a subsession.
<code>subsession_length</code> includes time that the computer was asleep for
Windows, but not for OS X or Linux; there is a <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1205567">long-outstanding
bug</a> to include
sleep time on all platforms.</p>
<p>There is <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1205985">another
bug</a> to count only
time that the computer is not in sleep.</p>
<p><code>subsession_length</code> was first implemented with <a href="https://mail.mozilla.org/pipermail/fhr-dev/2015-January/000384.html">the advent of
subsessions</a>,
which came with unified telemetry.</p>
<h3><a class="header" href="#total_uri_count" id="total_uri_count"><code>total_uri_count</code></a></h3>
<p><code>total_uri_count</code> was
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1271313">implemented</a> for
Firefox 50.</p>
<p><code>total_uri_count</code> is intended to capture the number of distinct
navigation events a user performs. It includes changes to the URI
fragment (i.e.anchor navigation) on the page. It excludes
<code>XmlHttpRequest</code> fetches and <code>iframes</code>.</p>
<p>It works by attaching an instance of <code>URICountListener</code> as a
<code>TabsProgressListener</code> which responds to <code>onLocationChange</code> events.</p>
<p>Some filters are applied to <code>onLocationChange</code> events:</p>
<ul>
<li>Error pages are excluded.</li>
<li>Only top-level pageloads (where <code>webProgress.isTopLevel</code>,
<a href="https://searchfox.org/mozilla-central/rev/f1c7ba91fad60bfea184006f3728dd6ac48c8e56/uriloader/base/nsIWebProgress.idl#144">documented inline</a>, is true) are counted  i.e,
not navigations within a frame.</li>
<li>Tab restore events are excluded.</li>
<li>URIs visited in private browsing mode are excluded unless
<code>browser.engagement.total_uri_count.pbm</code> is true. (The pref has been
flipped on for small populations in a couple of short studies, but,
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1535169">for now</a> remains false by default.)</li>
</ul>
<h3><a class="header" href="#unfiltered_uri_count" id="unfiltered_uri_count"><code>unfiltered_uri_count</code></a></h3>
<p>The unfiltered count,
<a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1304647">implemented</a> for
Firefox 51, differs only in that it includes URIs using protocol specs
other than HTTP and HTTPS. It excludes some (but not all) <code>about:</code> pages
 the set of initial pages defined in <code>browser.js</code> are excluded, but
e.g.<code>about:config</code> and <code>about:telemetry</code> are included.</p>
<p>No applications of <code>unfiltered_uri_count</code> have been identified.</p>
<ol>
<li>Ping <code>reason</code> for <code>main</code> pings <a href="https://dbc-caf9527b-e073.cloud.databricks.com/#notebook/82297/revision/1554433978453">observed</a>
from Firefox 65 <code>release</code> channel users on February 21, 2019.</li>
</ol>
<h1><a class="header" href="#sampling-in-telemetry-data" id="sampling-in-telemetry-data">Sampling in Telemetry data</a></h1>
<p>Since the early days of Telemetry, it has been desirable to have a quick and
simple way to do analysis on a sample of the full population of Firefox
clients.</p>
<p>The mechanism for doing that is encoded in the data itself, namely the
<code>sample_id</code> field.</p>
<p>This is a field that is computed from the telemetry <code>client_id</code> using
the <a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check">CRC</a> hash function.</p>
<p>This CRC hash is then bucketed into 100 possible values from 0 to 99,
each of which represents a roughly 1% uniform sample of the <code>client_id</code> space.</p>
<p>All ping tables that contain a client id, as well as many derived datasets,
include the <code>sample_id</code> field.</p>
<p>TL;DR <code>sample_id = crc32(client_id) % 100</code></p>
<p>An example python implementation:</p>
<pre><code class="language-python"># USAGE: python cid2sid.py 859c8a32-0b73-b547-a5e7-8ef4ed9c4c2d
# Prints
#        Client ID b'859c8a32-0b73-b547-a5e7-8ef4ed9c4c2d' =&gt; Sample ID 55
import binascii
import sys

clientid = sys.argv[1].encode()

crc = binascii.crc32(clientid)
sampleid = (crc &amp; 0xFFFFFFFF) % 100
print(&quot;Client ID {} =&gt; Sample ID {}&quot;.format(clientid, sampleid))
</code></pre>
<h1><a class="header" href="#about-this-documentation" id="about-this-documentation">About this documentation</a></h1>
<h2><a class="header" href="#a-hrefmetacontributinghtmlcontributinga" id="a-hrefmetacontributinghtmlcontributinga"><a href="meta/contributing.html">Contributing</a></a></h2>
<h2><a class="header" href="#a-hrefmetastructurehtmlstructurea" id="a-hrefmetastructurehtmlstructurea"><a href="meta/structure.html">Structure</a></a></h2>
<h1><a class="header" href="#contributing" id="contributing">Contributing</a></h1>
<p>Documentation is critical to making a usable data platform.
When surveying our users,
their most common complaint has been our lack of documentation.
It's important that we improve our documentation as often as possible.</p>
<h2><a class="header" href="#bug-reports" id="bug-reports">Bug reports</a></h2>
<p>If you see an error in the documentation or want to extend a chapter, please
<a href="https://bugzilla.mozilla.org/enter_bug.cgi?assigned_to=nobody%40mozilla.org&amp;bug_file_loc=http%3A%2F%2F&amp;bug_ignored=0&amp;bug_severity=normal&amp;bug_status=NEW&amp;cf_fx_iteration=---&amp;cf_fx_points=---&amp;component=Documentation%20and%20Knowledge%20Repo%20%28RTMO%29&amp;contenttypemethod=autodetect&amp;contenttypeselection=text%2Fplain&amp;defined_groups=1&amp;flag_type-4=X&amp;flag_type-607=X&amp;flag_type-800=X&amp;flag_type-803=X&amp;flag_type-916=X&amp;form_name=enter_bug&amp;maketemplate=Remember%20values%20as%20bookmarkable%20template&amp;op_sys=Linux&amp;priority=--&amp;product=Data%20Platform%20and%20Tools&amp;rep_platform=x86_64&amp;target_milestone=---&amp;version=unspecified">file a bug</a>.</p>
<h2><a class="header" href="#getting-the-raw-documentation" id="getting-the-raw-documentation">Getting the Raw Documentation</a></h2>
<p>The documentation is intended to be read as HTML at
<a href="https://docs.telemetry.mozilla.org"><code>docs.telemetry.mozilla.org</code></a>.
However, we store the documentation in raw text files in the
<a href="https://github.com/mozilla/firefox-data-docs"><code>firefox-data-docs</code> repo</a>.
To begin contributing to the docs, fork the <code>firefox-data-docs</code> repo.</p>
<h2><a class="header" href="#building-the-documentation" id="building-the-documentation">Building the Documentation</a></h2>
<p>The documentation is rendered with <a href="https://github.com/rust-lang/mdBook">mdBook</a>.</p>
<p>To build the documentation locally, you'll need additional preprocessors:</p>
<ul>
<li><a href="https://github.com/badboy/mdbook-toc/releases">mdbook-toc</a></li>
<li><a href="https://github.com/badboy/mdbook-mermaid/releases">mdbook-mermaid</a></li>
</ul>
<p>Download releases for your system, unpack it and place the binary in a directory of your <code>$PATH</code>.</p>
<p>If you have <a href="https://www.rust-lang.org/">rustc</a> already installed, you can install a pre-compiled binary directly:</p>
<pre><code class="language-bash">curl -LSfs https://japaric.github.io/trust/install.sh | sh -s -- --git badboy/mdbook-toc
curl -LSfs https://japaric.github.io/trust/install.sh | sh -s -- --git badboy/mdbook-mermaid
</code></pre>
<p>This will place <code>mdbook-toc</code> and <code>mdbook-mermaid</code> into <code>~/.cargo/bin</code>.
Make sure this directory is in your <code>$PATH</code> or copy it to a directory of your <code>$PATH</code>.</p>
<p>You can also build and install the preprocessors:</p>
<pre><code class="language-bash">cargo install mdbook-toc
cargo install mdbook-mermaid
</code></pre>
<p>You can then serve the documentation locally with:</p>
<pre><code>mdbook serve
</code></pre>
<p>The complete documentation for the mdBook toolchain is available online at <a href="https://rust-lang.github.io/mdBook/">https://rust-lang.github.io/mdBook/</a>.
If you run into any technical limitations, let <code>@harterrt</code> or <code>@badboy</code> know.
We are happy to change the tooling to make it as much fun as possible to write.</p>
<h2><a class="header" href="#adding-a-new-article" id="adding-a-new-article">Adding a new article</a></h2>
<p>Be sure to link to your new article from <code>SUMMARY.md</code>, or mdBook will not render the file.</p>
<p>The structure of the repository is outlined in <a href="meta/./structure.html">this article</a>.</p>
<p>This documentation is under active development,
so we may already be working on the documentation you need.
Take a look at
<a href="https://bugzilla.mozilla.org/buglist.cgi?product=Data%20Platform%20and%20Tools&amp;component=Documentation%20and%20Knowledge%20Repo%20%28RTMO%29&amp;resolution=---">this bug component</a>
to check.</p>
<h2><a class="header" href="#style-guide" id="style-guide">Style Guide</a></h2>
<p>Articles should be written in Markdown.
mdBook uses the <a href="https://commonmark.org/help/">CommonMark dialect</a>.</p>
<p>Limit lines to <strong>100 characters</strong> where possible.
Try to split lines at the end of sentences,
or use <a href="http://rhodesmill.org/brandon/2012/one-sentence-per-line/">Semantic Line Breaks</a>.
This makes it easier to reorganize your thoughts later.</p>
<p>This documentation is meant to be read digitally.
Keep in mind that people read digital content much differently than other media.
Specifically, readers are going to skim your writing,
so make it easy to identify important information.</p>
<p>Use <strong>visual markup</strong> like <strong>bold text</strong>, <code>code blocks</code>, and section headers.
Avoid long paragraphs.
Short paragraphs that describe one concept each makes finding important information easier.</p>
<h2><a class="header" href="#spell-checking" id="spell-checking">Spell checking</a></h2>
<p>Articles should use proper spelling, and pull requests will be automatically checked for spelling
errors.</p>
<p>Technical articles often contain words that are not recognized by common dictionaries, if this
happens you may either put specialized terms in <code>code blocks</code>, or you may add an exception to
the <code>.spelling</code> file in the code repository.</p>
<p>For things like dataset names or field names, <code>code blocks</code> should be preferred. Things like
project names or common technical terms should be added to the <code>.spelling</code> file.</p>
<p>To run the spell checker locally,
<a href="https://www.npmjs.com/package/markdown-spellcheck">install the <code>markdown-spellcheck</code> library</a>,
then run the <code>scripts/spell_check.sh</code> script from the root of the repository.</p>
<p>You may also remove the <code>--report</code> parameter to begin an interactive fixing session. In this
case, it is highly recommended to also add the <code>--no-suggestions</code> parameter, which greatly
speeds things up.</p>
<h2><a class="header" href="#link-checking" id="link-checking">Link checking</a></h2>
<p>Any web links should be valid. A dead link might not be your fault, but you will earn a lot
of good karma by fixing a dead link!</p>
<p>To run the link checker locally, <a href="https://github.com/tcort/markdown-link-check#installation">install the <code>markdown-link-check</code> library</a>, then run the <code>scripts/link_check.sh</code> script from the root of the repository.</p>
<h2><a class="header" href="#supported-plugins" id="supported-plugins">Supported Plugins</a></h2>
<h3><a class="header" href="#mermaid" id="mermaid">Mermaid</a></h3>
<p>You may use <a href="https://mermaidjs.github.io/"><code>mermaid.js</code></a> diagrams in code blocks:</p>
<pre><code>graph LR
  you --&gt;|write|docs
  docs --&gt; profit!
</code></pre>
<p>Which will be rendered as:</p>
<pre class="mermaid">graph LR
  you -->|write|docs
  docs --> profit!
</pre>
<h2><a class="header" href="#review" id="review">Review</a></h2>
<p>Once you're happy with your contribution, please open a PR and flag <code>@harterrt</code> for review.
Please squash your changes  into meaningful commits  and follow these
<a href="https://chris.beams.io/posts/git-commit/">commit message guidelines</a>.</p>
<h2><a class="header" href="#publishing" id="publishing">Publishing</a></h2>
<p>The documentation is hosted on <a href="https://pages.github.com/">Github Pages</a>.</p>
<p>Updates to the documentation are automatically published to
<a href="https://docs.telemetry.mozilla.org"><code>docs.telemetry.mozilla.org</code></a> when changes are merged.</p>
<p>To publish to your own fork of this repo, changes need to be pushed manually.
Use the <a href="https://github.com/mozilla/firefox-data-docs/blob/master/scripts/deploy.sh">deploy script</a>
to publish new changes.</p>
<p>This script depends on
<a href="https://github.com/davisp/ghp-import"><code>ghp-import</code></a>.</p>
<p>Keep in mind that this will deploy the docs to your <code>origin</code> repo.
If you're working from a fork (which you should be),
<code>deploy.sh</code> will update the docs hosted from your fork - not the production docs.</p>
<h1><a class="header" href="#colophon" id="colophon">Colophon</a></h1>
<p>This document's structure is heavily influenced by
<a href="https://docs.djangoproject.com/en/1.11/internals/contributing/writing-documentation/">Django's Documentation Style Guide</a>.</p>
<p>You can find more context for this document in
<a href="http://blog.harterrt.com/lit-review.html">this blog post</a>.</p>
<h1><a class="header" href="#documentation-structure" id="documentation-structure">Documentation Structure</a></h1>
<p>The directory structure is meant to feel comfortable for those
familiar with the data platform:</p>
<pre><code>.
|--src
   |--datasets - contains dataset level documentation
   |--tools - contains tool level documentation
   |--concepts - contains tutorials meant to introduce a new concept to the reader
   |--cookbooks - focused code examples for reference
</code></pre>
<p>The prose documentation is meant to take the reader from beginner to expert.
To this end, the rendered documentation has an order different from the directory structure:</p>
<ul>
<li>Getting Started: Get some simple analysis completed so the user understands
the amount of work involved / what the product feels like</li>
<li>Tutorials
<ul>
<li>Data Tutorials: tutorials meant to give the reader a complete understanding
of a specific dataset. Start with a high level overview, then move on to
completely document the data including Data source, Sampling, Common Issues,
and where the reader can find the code.</li>
<li>Tools tutorials: Tutorials meant to introduce a single data tool or
analysis best practice.</li>
</ul>
</li>
<li>Cookbooks</li>
<li>Reference material - TBD</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        
        
        
        <script type="text/javascript">
            window.playpen_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        
        <script type="text/javascript" src="mermaid.min.js"></script>
        
        <script type="text/javascript" src="mermaid-init.js"></script>
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
